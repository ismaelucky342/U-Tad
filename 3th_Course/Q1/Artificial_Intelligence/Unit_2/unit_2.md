# Unidad 2

Creado: 23 de octubre de 2025 11:37

![image.png](unit_2/image.png)

# Keras

Se trata de una biblioteca de alto nivel utilizada para construir y entrenar modelos de redes neuronales profundas (recuerda por la unidad 1 que una red se considera profunda cuando tiene m√°s de una capa oculta). Facilita el desarrollo de modelos complejos con m√∫ltiples capas, dise√±adas para aprender y representar datos en varios niveles de abstracci√≥n, a trav√©s de una interfaz f√°cil de usar.

### Origen de la herramienta

Para ubicar historicamente esta herramineta nos remontamos a 2015, gracias a un investigador de google que buscaba facilitar el desarrollo del deep learning. 
El objetivo inicial de Keras fue el de permitir la creaci√≥n r√°pida de prototipos de modelos de redes neuronales, con √©nfasis en la facilidad de uso y en su modularidad.

Ha sido ampliamente adoptada por la comunidad de investigadores y desarrolladores debido a su enfoque intuitivo y a sus capacidades avanzadas, ya que su API est√° dise√±ada para ser f√°cil de entender y usar, permitiendo a los desarrolladores concentrarse en la construcci√≥n del modelo sin preocuparse por los detalles de implementaci√≥n.

Est√° organizada en m√≥dulos independientes que se pueden combinar para construir modelos complejos. Esto incluye m√≥dulos para capas neuronales, funciones de activaci√≥n, optimizadores, y funciones de p√©rdida.

### Estructura de keras

Esta herraminenta est√° dise√±ada para ser modular, flexible y facil de usar, permitiendo construir modelos de deep learning con diferentes tipos de modelos y capas. Ofrecido en dos modelos: 

- Secuencial: El modelo secuencial es una pila lineal de capas, donde cada capa tiene exactamente una entrada y una salida. Este tipo de modelo es adecuado para la mayor√≠a de los casos de uso simples, donde las capas se apilan una tras otra.
- Funcional: El modelo funcional ofrece una mayor flexibilidad y es adecuado para casos de uso m√°s complejos, como modelos con m√∫ltiples entradas y salidas, capas compartidas y conexiones residuales.

### Capas en Keras

Keras ofrece una amplia variedad de capas destinadas a la construcci√≥n de modelis de deep learning siendo las mas com√∫nes: 

- **Densas:** Conectan todas las neuronas entre capas.
- **Convolucionales:** Detectan patrones locales en datos (como im√°genes).
- **Pooling:** Reducen tama√±o y complejidad de los mapas de caracter√≠sticas.
- **Recurrentes:** Procesan secuencias recordando informaci√≥n previa.
- **Normalizaci√≥n:** Estabilizan y aceleran el entrenamiento.
- **Regularizaci√≥n:** Previenen el sobreajuste del modelo.
- **Activaci√≥n:** Introducen no linealidad en la red.

# Redes Convolucionales

**Las redes convolucionales (CNN o ConvNet)** se consideran parte de las redes neuronales artificiales avanzadas. ****Son una clase especializada de redes neuronales artificiales, especialmente
adecuadas para analizar datos con una estructura en forma de cuadr√≠cula, como im√°genes y v√≠deos.

Utilizan capas convolucionales para detectar caracter√≠sticas locales y patrones en los datos, lo que las hace extremadamente efectivas en aplicaciones de visi√≥n por ordenador, como la clasificaci√≥n de im√°genes, la segmentaci√≥n sem√°ntica y la detecci√≥n de objetos. 

Las redes convolucionales (CNN) son esenciales en visi√≥n por ordenador, ya que reconocen patrones visuales directamente desde los p√≠xeles con poco preprocesamiento. Sus **capas convolucionales** extraen autom√°ticamente caracter√≠sticas locales (bordes, texturas, etc.) mediante filtros deslizantes. 

![image.png](unit_2/image%201.png)

Las **capas de pooling**, como *MaxPooling*, reducen la dimensionalidad manteniendo la informaci√≥n m√°s relevante, y las **funciones de activaci√≥n** (principalmente *ReLU*) introducen no linealidad para modelar relaciones complejas. Finalmente, las **capas completamente conectadas** realizan la **clasificaci√≥n final**.

### Funcionamineto de una capa convolucional

Cada capa convolucional aplica peque√±os **filtros,** que son matrices de pesos, sobre la entrada. Los pesos se aprenden durante el proceso de entrenamiento de la red. Los filtros (tambi√©n llamados Kernel) se desplazan (o ‚Äòconvolucionan‚Äô) a lo largo de la imagen, multiplicando los valores del filtro por los valores de la imagen en cada posici√≥n y sumando los resultados. 

- El **mapa de caracter√≠sticas** es el resultado de la convoluci√≥n de un filtro sobre la imagen. Cada filtro detecta diferentes aspectos de la imagen, por lo que m√∫ltiples filtros se aplican en una misma capa para extraer varias caracter√≠sticas.
- El mapa de caracter√≠sticas resultante de cada convoluci√≥n se usa como entrada para las siguientes capas de la red, como otras capas convolucionales, capas de pooling (que reducen a√∫n m√°s la dimensionalidad) y finalmente capas completamente conectadas (fully connected) que son las que toman las decisiones finales (por ejemplo, clasificaci√≥n, detecci√≥n de objetos o segmentaci√≥n).

**Convolucionar** se trata del proceso mediante el que se aplica un filtro (Kernel) a una entrada para generar un mapa de caracter√≠sticas. Al aplicar la convoluci√≥n se reduce la dimensionalidad de la imagen original mientras se conserva la informaci√≥n m√°s relevante.

<aside>
üí°

*‚ÄùPermite que las capas posteriores se enfoquen en caracter√≠sticas m√°s abstractas y complejas, disminuyendo la cantidad de datos que la red necesita procesar‚Äù*

</aside>

El **stride** es el paso que da el filtro al moverse por la imagen, si el stride es 1, el filtro avanza un p√≠xel cada vez, si es 2, salta de dos en dos, haciendo la salida m√°s peque√±a.

> En una CNN para reconocer d√≠gitos (como MNIST) las primeras capas detectan **bordes**, las capas intermedias combinan esos bordes en**formas m√°s complejas** (curvas, intersecciones) y las √∫ltimas capas juntan todo para**identificar el n√∫mero completo**.
> 

![image.png](unit_2/image%202.png)

## Operaciones con matrices en las CNN

![image.png](unit_2/image%203.png)

### Conversi√≥n de la imagen a matriz

Toda imagen, ya sea en escala de grises o a color, se convierte en una **matriz de valores num√©ricos**. Cada p√≠xel se representa seg√∫n su intensidad, y en im√°genes a color se considera un conjunto de valores para rojo, verde y azul. Esta representaci√≥n permite que la red neuronal pueda ‚Äúentender‚Äù la imagen y operar matem√°ticamente sobre ella. 

> Como curiosidad, esta conversi√≥n tambi√©n facilita t√©cnicas de normalizaci√≥n, lo que ayuda al entrenamiento al mantener los valores dentro de un rango manejable.
> 

### Convoluci√≥n: detectar patrones locales

El **filtro o kernel** es una peque√±a matriz que se aplica sobre la imagen para detectar patrones espec√≠ficos, como bordes, texturas o formas. Al moverse sobre la imagen y combinar sus valores con los de la subregi√≥n que cubre, el filtro genera un **mapa de caracter√≠sticas**, que destaca las √°reas donde el patr√≥n buscado aparece con mayor intensidad.

- Por ejemplo, un filtro dise√±ado para bordes verticales resaltar√° los cambios bruscos de intensidad de izquierda a derecha.
- En redes reales, los filtros no siempre se dise√±an manualmente; la mayor√≠a se **aprenden autom√°ticamente** durante el entrenamiento, ajust√°ndose para reconocer las caracter√≠sticas m√°s √∫tiles para la tarea.

### Pooling: resumir informaci√≥n

Despu√©s de la convoluci√≥n, el mapa de caracter√≠sticas puede ser muy grande. Para **reducir su tama√±o y mantener lo m√°s importante**, se aplica un proceso llamado **pooling**, siendo el Max Pooling el m√°s com√∫n. Este proceso selecciona el valor m√°s representativo dentro de cada subregi√≥n del mapa, conservando la informaci√≥n relevante y reduciendo la carga de procesamiento. 

> Este paso tambi√©n ayuda a que la red sea m√°s **robusta frente a peque√±as variaciones o desplazamientos en la imagen**.
> 

### Flattening: preparaci√≥n para clasificaci√≥n

Una vez reducido el mapa de caracter√≠sticas, se convierte en un **vector unidimensional**, un proceso conocido como flattening. Este vector es lo que se alimenta a las **capas completamente conectadas**, donde cada neurona combina los valores de entrada con **pesos y sesgos** aprendidos.

### Predicci√≥n final

La capa de salida de la red aplica una funci√≥n de activaci√≥n, como **softmax**, para producir la **predicci√≥n final**, por ejemplo, determinar qu√© d√≠gito aparece en una imagen del conjunto MNIST. Gracias a la combinaci√≥n de convoluci√≥n, pooling y capas densas, la red es capaz de **reconocer patrones complejos** que podr√≠an ser muy dif√≠ciles de identificar con m√©todos tradicionales.

### Puntos interesantes

- Las CNN imitan parcialmente la forma en que funciona la **corteza visual** en los humanos, detectando primero caracter√≠sticas simples y luego combin√°ndolas para reconocer formas m√°s complejas.
- Los filtros iniciales suelen detectar **bordes y texturas**, mientras que las capas m√°s profundas capturan patrones abstractos y contextuales.
- Esta arquitectura ha permitido avances impresionantes en campos como **reconocimiento facial, veh√≠culos aut√≥nomos, segmentaci√≥n m√©dica** y m

## Capas Max Pooling

Con las capas Max Pooling se consiguen extraer ventanas de los mapas de caracter√≠sticas de entrada y sacar el valor m√°ximo de cada canal. Es conceptualmente similar a la convoluci√≥n, salvo que en lugar de transformar los parches locales mediante una transformaci√≥n lineal aprendida (el n√∫cleo convolucional), se transforman mediante una operaci√≥n de tensor m√°ximo codificada. 

Una gran diferencia con la convoluci√≥n es que Max Pooling se realiza normalmente con ventanas de 2x2 y stride 2, con el fin de reducir la muestra de los mapas de caracter√≠sticas en un factor de 2. Por otro lado, la convoluci√≥n se realiza normalmente con ventanas de 3x3 y sin stride (stride 1).

![image.png](unit_2/image%204.png)

### Introducci√≥n

El **algoritmo de retropropagaci√≥n** es esencial para entrenar redes neuronales, incluyendo las convolucionales (CNN). Su funci√≥n principal es **ajustar los pesos y sesgos** de la red para que las predicciones sean lo m√°s precisas posibles. En otras palabras, permite que la red ‚Äúaprenda‚Äù de los errores que comete al procesar los datos.

---

### C√≥mo funciona la retropropagaci√≥n

1. **Propagaci√≥n hacia adelante (Forward Pass)**
    - Se introduce una entrada (por ejemplo, la imagen de un d√≠gito manuscrito).
    - Las capas convolucionales aplican filtros para extraer caracter√≠sticas.
    - Las capas de pooling reducen la dimensionalidad, conservando lo m√°s importante.
    - La informaci√≥n se aplana en un vector y pasa por capas completamente conectadas.
    - La capa de salida aplica una funci√≥n de activaci√≥n (por ejemplo, softmax) para generar las **probabilidades de cada clase**.
2. **C√°lculo del error**
    - Se compara la salida de la red con la etiqueta verdadera del dato.
    - Se utiliza una **funci√≥n de p√©rdida** (como entrop√≠a cruzada) para medir la diferencia entre la predicci√≥n y la realidad.
        
        > *‚ÄúLa entrop√≠a cruzada mide **qu√© tan diferente es la predicci√≥n de la red respecto a la realidad**.‚Äù*
        > 
3. **Retropropagaci√≥n del error (Backward Pass)**
    - El error se propaga hacia atr√°s desde la capa de salida hacia las capas anteriores.
    - En cada capa se calculan los **gradientes**, que indican c√≥mo deber√≠a cambiar cada peso y sesgo para reducir el error.
    - Se aplica la **regla de la cadena** del c√°lculo diferencial para relacionar el error con cada par√°metro de la red.
4. **Actualizaci√≥n de pesos y sesgos**
    - Los gradientes se usan con un **algoritmo de optimizaci√≥n** (como descenso de gradiente estoc√°stico o Adam) para ajustar los pesos y sesgos.
    - El ajuste se realiza en la direcci√≥n que **minimiza la funci√≥n de p√©rdida**.
5. **Entrenamiento iterativo**
    - Este proceso se repite muchas veces (√©pocas) y con diferentes subconjuntos de datos (mini-batches).
    - Cada iteraci√≥n mejora la capacidad de la red para reconocer patrones y realizar predicciones m√°s precisas.

---

### Aplicaci√≥n en CNN

En el caso de una CNN que reconoce d√≠gitos manuscritos (MNIST):

- Las **capas convolucionales** extraen bordes y formas del d√≠gito.
- El **pooling** reduce el tama√±o de los mapas de caracter√≠sticas manteniendo lo m√°s relevante.
- El **vector aplanado** se pasa a capas densas que combinan los valores para clasificar el d√≠gito.
- La **retropropagaci√≥n** ajusta los filtros y pesos de todas las capas para que la red aprenda a identificar correctamente cada n√∫mero.

---

### Puntos interesantes

- La retropropagaci√≥n permite que la red **aprenda de sus errores**, ajustando millones de par√°metros de manera autom√°tica.
- Es aplicable a distintos tipos de redes, no solo CNN: recurrentes (RNN), autoencoders, generativas adversariales (GAN), entre otras.
- El proceso combina conceptos de **√°lgebra lineal, c√°lculo y optimizaci√≥n**, lo que lo hace extremadamente poderoso pero tambi√©n elegante desde el punto de vista matem√°tico.

![image.png](unit_2/image%205.png)

---

### Ventajas de las redes convolucionales (CNN)

**Extracci√≥n autom√°tica de caracter√≠sticas**

- Detectan patrones locales y globales de los datos sin necesidad de ingenier√≠a manual.
- Esto mejora la eficiencia frente a m√©todos cl√°sicos como SVM o √°rboles de decisi√≥n.

**Reducci√≥n de dimensionalidad y par√°metros**

- T√©cnicas como **pooling** y **compartici√≥n de pesos** reducen la cantidad de datos que la red necesita procesar.
- Mantienen la informaci√≥n importante, haciendo la red m√°s eficiente.

**Captura de relaciones espaciales**

- Conservan la estructura espacial de los datos, permitiendo reconocer patrones aunque cambien de posici√≥n, orientaci√≥n o escala.

**Generalizaci√≥n y robustez**

- Aprenden a identificar patrones de forma flexible, lo que mejora su capacidad de funcionar con datos nuevos o ligeramente distintos.

**Aplicaciones vers√°tiles**

- Son muy efectivas en **visi√≥n por ordenador** (reconocimiento de im√°genes, objetos y escenas).
- Tambi√©n se aplican en **procesamiento de lenguaje natural**, an√°lisis de **series temporales** o **reconocimiento del habla**.

**Flexibilidad y transferencia de aprendizaje**

- Arquitecturas preentrenadas como **VGG-16, ResNet50, Inceptionv3 o EfficientNet** permiten adaptarlas a nuevas tareas con pocos datos.

**Identificaci√≥n de patrones invariantes**

- Las capas convolucionales detectan caracter√≠sticas independientemente de cambios en posici√≥n, orientaci√≥n, escala o traslaci√≥n.

---

## **Transfer Learning**

El **aprendizaje por transferencia** (*Transfer Learning*) es una t√©cnica del **aprendizaje autom√°tico** y, especialmente, del **deep learning**, en la que un modelo previamente **preentrenado** en una tarea general se **reutiliza** (total o parcialmente) para una nueva tarea, normalmente con **menos datos** y **menor coste computacional**.

La idea central es **transferir el conocimiento** que el modelo ya ha adquirido (por ejemplo, las representaciones de caracter√≠sticas aprendidas) a otro problema relacionado.

**¬øPorqu√©?**

Entrenar redes profundas desde cero requiere:

- Grandes vol√∫menes de datos.
- Mucho tiempo de c√≥mputo.
- Riesgo de sobreajuste en conjuntos peque√±os.

El *transfer learning* soluciona esto aprovechando redes entrenadas en grandes datasets como **ImageNet**, **COCO**, o **BERT** (en NLP).

## Regularizaci√≥n de una CNN

La regularizaci√≥n es una t√©cnica utilizada para prevenir el sobreajuste (overfitting), asegurando que el modelo generalice bien en datos no vistos. Keras proporciona varias t√©cnicas de regularizaci√≥n:

- DropOut: Es una t√©cnica en la que se desactivan aleatoriamente un n√∫mero de unidades de la red durante el entrenamiento. Desconecta un 50% de las neuronas de la capa a la que est√° conectada en cada paso de entrenamiento. Esto fuerza a la red a no depender demasiado de ciertas neuronas, promoviendo as√≠ la generalizaci√≥n.
- Regularizaci√≥n L1 y L2: La regularizaci√≥n L1 agrega una penalizaci√≥n igual al valor absoluto de los coeficientes de los par√°metros, mientras que L2 agrega una penalizaci√≥n igual al cuadrado del valor de los coeficientes. Se realiza para prevenir el sobreajuste (overfitting) 
al penalizar grandes valores de los pesos en las capas de red.

## Ajuste de Hiperpar√°metros de la red

El ajuste de hiperpar√°metros implica encontrar la combinaci√≥n √≥ptima de hiperpar√°metros para mejorar el rendimiento del modelo. Algunos hiperpar√°metros comunes incluyen la tasa de aprendizaje, el tama√±o del lote y el n√∫mero de √©pocas.

- Tasa de Aprendizaje: Se puede ajustar la tasa de aprendizaje del optimizador. Keras tambi√©n proporciona callbacks para ajustar din√°micamente la tasa de aprendizaje durante el entrenamiento.
    
    ```python
    from tensorflow.keras.callbacks import LearningRateScheduler
    
    def scheduler(epoch, lr):
       if epoch < 10:
           return lr
       else:
           return lr * tf.math.exp(-0.1)
    
    callback = LearningRateScheduler(scheduler)
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                 loss='sparse_categorical_crossentropy',metrics=['accuracy'])
    model.fit(x_train, y_train, epochs=20, callbacks=[callback])
    ```
    
- Tama√±o del lote y numero de √©pocas: Se experimentar con diferentes tama√±os de lote y distintos n√∫meros de √©pocas para encontrar la combinaci√≥n que mejor funcione para tu modelo y datos.
    
    ```python
    model.fit(x_train, y_train, epochs=50, batch_size=64, validation_split=0.2)
    ```
    

### Aumento de Datos

El aumento de datos (Data Augmentation) es una t√©cnica para generar nuevas muestras de datos de entrenamiento a partir de las existentes mediante transformaciones aleatorias. Esto ayuda a mejorar la generalizaci√≥n del modelo.

```python
rom tensorflow.keras.preprocessing.image import ImageDataGenerator
datagen = ImageDataGenerator(
 rotation_range=20,
 width_shift_range=0.2,
 height_shift_range=0.2,
 shear_range=0.2,
 zoom_range=0.2,
 horizontal_flip=True,
 fill_mode='nearest')
datagen.fit(x_train)
model.fit(datagen.flow(x_train, y_train, batch_size=32),
 steps_per_epoch=len(x_train) // 32, epochs=50)
```

### **Optimizaci√≥n de modelos de una CNN**

- Early Stopping: Es una t√©cnica para detener el entrenamiento cuando el rendimiento en los datos de validaci√≥n deja de mejorar.
    
    ```python
    from tensorflow.keras.callbacks import EarlyStopping
    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
    model.fit(x_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])
    ```
    
- Batch Normalization: Normaliza las activaciones de una capa a lo largo del lote, mejorando la estabilidad y velocidad del entrenamiento.
    
    ```python
    from tensorflow.keras.layers import BatchNormalization
    
    model = Sequential([
       Flatten(input_shape=(28, 28)),
       Dense(128, activation='relu'),
       BatchNormalization(),
       Dense(10, activation='softmax')
    ])
    ```
    
- Model Checkpointing: Guardar el modelo en checkpoints durante el entrenamiento permite recuperar el mejor modelo basado en m√©tricas de validaci√≥n.
    
    ```python
    from tensorflow.keras.callbacks import ModelCheckpoint
    
    checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)
    model.fit(x_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[checkpoint])
    ```