{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================================================#\n",
    "#                                                                                                    #\n",
    "#                                                        ██╗   ██╗   ████████╗ █████╗ ██████╗        #\n",
    "#      Competición - INAR                                ██║   ██║   ╚══██╔══╝██╔══██╗██╔══██╗       #\n",
    "#                                                        ██║   ██║█████╗██║   ███████║██║  ██║       #\n",
    "#      created:        29/10/2025  -  23:00:15           ██║   ██║╚════╝██║   ██╔══██║██║  ██║       #\n",
    "#      last change:    30/10/2025  -  02:55:40           ╚██████╔╝      ██║   ██║  ██║██████╔╝       #\n",
    "#                                                         ╚═════╝       ╚═╝   ╚═╝  ╚═╝╚═════╝        #\n",
    "#                                                                                                    #\n",
    "#      Ismael Hernandez Clemente                         ismael.hernandez@live.u-tad.com             #\n",
    "#                                                                                                    #\n",
    "#      Github:                                           https://github.com/ismaelucky342            #\n",
    "#                                                                                                    #\n",
    "#====================================================================================================#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gatos vs Perretes \n",
    "\n",
    "idea de diseño: \n",
    "- **EfficientNet-B3 entrenado DESDE CERO** (sin pesos preentrenados de ImageNet)\n",
    "- **K-Fold con validación cruzada** (5 folds) para mejor generalización\n",
    "- **Entrenamiento por etapas**: primero solo la cabeza, luego fine-tuning completo\n",
    "- **Data Augmentation** con Albumentations\n",
    "- **Mixed Precision Training** para acelerar el entrenamiento\n",
    "- **Learning rate alto** (adaptado para entrenamiento desde cero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "# Importo las librerías\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch y movidas varias\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# modelos preentrenados con transfer\n",
    "import timm\n",
    "\n",
    "# Data augmentation y transformaciones\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# K-Fold validación cruzada \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# fijo todas las semillas\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Para usar las graficas de kagle\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuración Global\n",
    "**[v2.0 - 31/10/2025 03:00 AM]** - ADAPTADO para entrenamiento desde cero (sin preentrenado)\n",
    "\n",
    "Hiperparámetros ajustados para entrenar EfficientNet-B3 completamente desde cero:\n",
    "- **Epochs aumentados** (30+50 = 80 total)\n",
    "- **Learning rates 10x mayores** (pesos aleatorios necesitan más actualización)\n",
    "- **Batch size aumentado** (mejor convergencia)\n",
    "- **Weight decay reducido** (no frenar aprendizaje inicial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entorno detectado: LOCAL\n",
      "Ruta base del dataset: /home/nirmata/Descargas/u-tad-dogs-vs-cats-2025\n",
      "\n",
      "Configuración cargada:\n",
      "   train_dir: /home/nirmata/Descargas/u-tad-dogs-vs-cats-2025/train/train\n",
      "   test_dir: /home/nirmata/Descargas/u-tad-dogs-vs-cats-2025/test/test\n",
      "   supplementary_dir: /home/nirmata/Descargas/u-tad-dogs-vs-cats-2025/supplementary_data/supplementary_data\n",
      "   model_name: efficientnet_b3\n",
      "   img_size: 300\n",
      "   num_classes: 2\n",
      "   batch_size: 32\n",
      "   num_folds: 5\n",
      "   epochs_stage1: 5\n",
      "   epochs_stage2: 15\n",
      "   lr_stage1: 0.001\n",
      "   lr_stage2: 0.0001\n",
      "   weight_decay: 0.01\n",
      "   label_smoothing: 0.1\n",
      "   num_workers: 2\n",
      "   seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Configuración de parámetros y rutas\n",
    "# Detecto automáticamente si estamos en Kaggle o en local\n",
    "import os\n",
    "\n",
    "if os.path.exists('/kaggle/input'):\n",
    "    # Estamos en Kaggle\n",
    "    BASE_PATH = '/kaggle/input/u-tad-dogs-vs-cats-2025'\n",
    "    print(\"Entorno detectado: KAGGLE\")\n",
    "else:\n",
    "    # Estamos en local\n",
    "    BASE_PATH = '/home/nirmata/Descargas/u-tad-dogs-vs-cats-2025'\n",
    "    print(\"Entorno detectado: LOCAL\")\n",
    "\n",
    "print(f\"Ruta base del dataset: {BASE_PATH}\\n\")\n",
    "\n",
    "CONFIG = {\n",
    "    'train_dir': os.path.join(BASE_PATH, 'train/train'),\n",
    "    'test_dir': os.path.join(BASE_PATH, 'test/test'),\n",
    "    'supplementary_dir': os.path.join(BASE_PATH, 'supplementary_data/supplementary_data'),\n",
    "    \n",
    "    'model_name': 'efficientnet_b3',\n",
    "    'img_size': 224,  # Reducido para entrenar más rápido\n",
    "    'num_classes': 2,\n",
    "    \n",
    "    'batch_size': 64,  # Aumentado para mejor convergencia\n",
    "    'num_folds': 5,\n",
    "    'epochs_stage1': 30,  # Aumentado significativamente (sin pesos preentrenados)\n",
    "    'epochs_stage2': 50,  # Aumentado para fine-tuning completo\n",
    "    'lr_stage1': 1e-2,    # 10x mayor (pesos aleatorios necesitan más actualización)\n",
    "    'lr_stage2': 1e-3,    # 10x mayor\n",
    "    'weight_decay': 1e-4, # Reducido para no frenar el aprendizaje inicial\n",
    "    'label_smoothing': 0.1,\n",
    "    \n",
    "    'num_workers': 2,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "print(\"Configuración cargada:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DIAGNOSTICO DE ESTRUCTURA DEL DATASET\n",
      "============================================================\n",
      "\n",
      "[OK] Ruta base encontrada: /home/nirmata/Descargas/u-tad-dogs-vs-cats-2025\n",
      "\n",
      "Contenido de la ruta base:\n",
      "  [DIR]  test/\n",
      "  [DIR]  train/\n",
      "  [DIR]  supplementary_data/\n",
      "  [FILE] sample_submission.csv\n",
      "\n",
      "Verificando train_dir: /home/nirmata/Descargas/u-tad-dogs-vs-cats-2025/train/train\n",
      "  [OK] Directorio existe\n",
      "  Contenido: ['Dog', 'Cat']\n",
      "    Dog/: 12500 imágenes\n",
      "    Cat/: 12500 imágenes\n",
      "\n",
      "Verificando test_dir: /home/nirmata/Descargas/u-tad-dogs-vs-cats-2025/test/test\n",
      "  [OK] Directorio existe\n",
      "  Total de imágenes de test: 1067\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DIAGNÓSTICO: Verificar estructura del dataset\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DIAGNOSTICO DE ESTRUCTURA DEL DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verifico la ruta base\n",
    "if os.path.exists(BASE_PATH):\n",
    "    print(f\"\\n[OK] Ruta base encontrada: {BASE_PATH}\")\n",
    "    \n",
    "    # Listo contenido principal\n",
    "    print(f\"\\nContenido de la ruta base:\")\n",
    "    for item in os.listdir(BASE_PATH):\n",
    "        item_path = os.path.join(BASE_PATH, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"  [DIR]  {item}/\")\n",
    "        else:\n",
    "            print(f\"  [FILE] {item}\")\n",
    "    \n",
    "    # Verifico directorio de entrenamiento\n",
    "    print(f\"\\nVerificando train_dir: {CONFIG['train_dir']}\")\n",
    "    if os.path.exists(CONFIG['train_dir']):\n",
    "        print(f\"  [OK] Directorio existe\")\n",
    "        train_contents = os.listdir(CONFIG['train_dir'])\n",
    "        print(f\"  Contenido: {train_contents}\")\n",
    "        \n",
    "        # Si hay subcarpetas, cuento imágenes\n",
    "        for subdir in train_contents:\n",
    "            subdir_path = os.path.join(CONFIG['train_dir'], subdir)\n",
    "            if os.path.isdir(subdir_path):\n",
    "                jpg_count = len([f for f in os.listdir(subdir_path) if f.endswith('.jpg')])\n",
    "                print(f\"    {subdir}/: {jpg_count} imágenes\")\n",
    "    else:\n",
    "        print(f\"  [ERROR] Directorio no existe\")\n",
    "    \n",
    "    # Verifico directorio de test\n",
    "    print(f\"\\nVerificando test_dir: {CONFIG['test_dir']}\")\n",
    "    if os.path.exists(CONFIG['test_dir']):\n",
    "        print(f\"  [OK] Directorio existe\")\n",
    "        test_count = len([f for f in os.listdir(CONFIG['test_dir']) if f.endswith('.jpg')])\n",
    "        print(f\"  Total de imágenes de test: {test_count}\")\n",
    "    else:\n",
    "        print(f\"  [ERROR] Directorio no existe\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\n[ERROR] Ruta base no encontrada: {BASE_PATH}\")\n",
    "    print(\"\\nSoluciones:\")\n",
    "    if os.path.exists('/kaggle/input'):\n",
    "        print(\"  - En Kaggle: Agrega el dataset como input\")\n",
    "    else:\n",
    "        print(\"  - En local: Descarga el dataset y actualiza BASE_PATH\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del Dataset\n",
    "\n",
    "Creo un dataset personalizado de PyTorch y preparo los datos para validación cruzada K-Fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CARGANDO DATOS DE ENTRENAMIENTO\n",
      "============================================================\n",
      "Leyendo imágenes desde: /home/nirmata/Descargas/u-tad-dogs-vs-cats-2025/train/train\n",
      "   Estructura detectada: Subcarpetas Cat/ y Dog/\n",
      "   Cat/: 12500 imágenes (gato)\n",
      "   Dog/: 12500 imágenes (perro)\n",
      "\n",
      "[OK] Datos cargados correctamente:\n",
      "   Total de imágenes: 25000\n",
      "   Gatos (label=0): 12500\n",
      "   Perros (label=1): 12500\n",
      "   Forma de train_paths: (25000,)\n",
      "   Forma de train_labels: (25000,)\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset personalizado\n",
    "class DogsVsCatsDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transforms=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# Preparo los datos de entrenamiento\n",
    "def prepare_data(train_dir):\n",
    "    \"\"\"\n",
    "    Carga las rutas de las imágenes y sus etiquetas desde el directorio de entrenamiento.\n",
    "    Soporta dos estructuras:\n",
    "    1. Imágenes directamente en train_dir (cat.123.jpg, dog.456.jpg)\n",
    "    2. Imágenes en subcarpetas Cat/ y Dog/\n",
    "    \n",
    "    Args:\n",
    "        train_dir: Ruta al directorio con las imágenes de entrenamiento\n",
    "        \n",
    "    Returns:\n",
    "        image_paths: Array numpy con las rutas completas a las imágenes\n",
    "        labels: Array numpy con las etiquetas (0=gato, 1=perro)\n",
    "    \"\"\"\n",
    "    # Verifico que el directorio existe\n",
    "    if not os.path.exists(train_dir):\n",
    "        raise FileNotFoundError(\n",
    "            f\"ERROR: El directorio de entrenamiento no existe: {train_dir}\\n\"\n",
    "            f\"   Por favor, verifica que:\\n\"\n",
    "            f\"   1. Estás ejecutando en Kaggle (si usas paths de Kaggle)\\n\"\n",
    "            f\"   2. O actualiza CONFIG['train_dir'] con la ruta local correcta\\n\"\n",
    "            f\"   3. O descarga el dataset en la ubicación esperada\"\n",
    "        )\n",
    "    \n",
    "    print(f\"Leyendo imágenes desde: {train_dir}\")\n",
    "    \n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    # Listo todos los archivos del directorio\n",
    "    all_files = os.listdir(train_dir)\n",
    "    \n",
    "    # Verifico si hay subcarpetas Cat/ y Dog/\n",
    "    has_subdirs = any(item in all_files for item in ['Cat', 'Dog', 'cat', 'dog'])\n",
    "    \n",
    "    if has_subdirs:\n",
    "        print(\"   Estructura detectada: Subcarpetas Cat/ y Dog/\")\n",
    "        \n",
    "        # Busco en subcarpetas\n",
    "        for subdir in ['Cat', 'Dog', 'cat', 'dog']:\n",
    "            subdir_path = os.path.join(train_dir, subdir)\n",
    "            if not os.path.exists(subdir_path):\n",
    "                continue\n",
    "            \n",
    "            # Determino la etiqueta según el nombre de la subcarpeta\n",
    "            label = 0 if subdir.lower() == 'cat' else 1\n",
    "            class_name = \"gato\" if label == 0 else \"perro\"\n",
    "            \n",
    "            # Listo las imágenes en la subcarpeta\n",
    "            jpg_files = [f for f in os.listdir(subdir_path) if f.endswith('.jpg')]\n",
    "            \n",
    "            print(f\"   {subdir}/: {len(jpg_files)} imágenes ({class_name})\")\n",
    "            \n",
    "            for filename in jpg_files:\n",
    "                filepath = os.path.join(subdir_path, filename)\n",
    "                image_paths.append(filepath)\n",
    "                labels.append(label)\n",
    "    \n",
    "    else:\n",
    "        print(\"   Estructura detectada: Imágenes directas (cat.*.jpg, dog.*.jpg)\")\n",
    "        \n",
    "        # Busco imágenes directamente en el directorio\n",
    "        jpg_files = [f for f in all_files if f.endswith('.jpg')]\n",
    "        print(f\"   Archivos .jpg encontrados: {len(jpg_files)}\")\n",
    "        \n",
    "        for filename in jpg_files:\n",
    "            filepath = os.path.join(train_dir, filename)\n",
    "            image_paths.append(filepath)\n",
    "            \n",
    "            # Etiqueto según el nombre del archivo\n",
    "            if filename.startswith('cat'):\n",
    "                label = 0\n",
    "            elif filename.startswith('dog'):\n",
    "                label = 1\n",
    "            else:\n",
    "                print(f\"   [!] Archivo ignorado (nombre no reconocido): {filename}\")\n",
    "                continue\n",
    "            \n",
    "            labels.append(label)\n",
    "    \n",
    "    # Verifico que se encontraron imágenes\n",
    "    if len(image_paths) == 0:\n",
    "        raise ValueError(\n",
    "            f\"ERROR: No se encontraron imágenes .jpg válidas en: {train_dir}\\n\"\n",
    "            f\"   Contenido encontrado: {all_files}\\n\"\n",
    "            f\"   Verifica que el dataset está descargado correctamente\"\n",
    "        )\n",
    "    \n",
    "    # Convierto a arrays numpy\n",
    "    image_paths = np.array(image_paths)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "# Cargo los datos\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CARGANDO DATOS DE ENTRENAMIENTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_paths, train_labels = prepare_data(CONFIG['train_dir'])\n",
    "\n",
    "print(f\"\\n[OK] Datos cargados correctamente:\")\n",
    "print(f\"   Total de imágenes: {len(train_paths)}\")\n",
    "print(f\"   Gatos (label=0): {(train_labels == 0).sum()}\")\n",
    "print(f\"   Perros (label=1): {(train_labels == 1).sum()}\")\n",
    "print(f\"   Forma de train_paths: {train_paths.shape}\")\n",
    "print(f\"   Forma de train_labels: {train_labels.shape}\")\n",
    "print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones y Data Augmentation\n",
    "**[v1.5 - 30/10/2025 02:20 AM]** - Augmentation mejorado con ShiftScaleRotate\n",
    "\n",
    "Defino las transformaciones de entrenamiento con augmentation y las de validación/test sin augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "1 validation error for InitSchema\nsize\n  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...': 1.0, 'strict': False}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/University/U-Tad/3th_Course/Q1/Artificial_Intelligence/Unit_3/AEC1/.venv/lib/python3.13/site-packages/albumentations/core/validation.py:67\u001b[39m, in \u001b[36mValidatedTransformMeta._validate_parameters\u001b[39m\u001b[34m(schema_cls, full_kwargs, param_names, strict)\u001b[39m\n\u001b[32m     66\u001b[39m schema_kwargs[\u001b[33m\"\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m\"\u001b[39m] = strict\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m config = \u001b[43mschema_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mschema_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m validated_kwargs = config.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/University/U-Tad/3th_Course/Q1/Artificial_Intelligence/Unit_3/AEC1/.venv/lib/python3.13/site-packages/pydantic/main.py:250\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    249\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for InitSchema\nsize\n  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...': 1.0, 'strict': False}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Transformaciones de entrenamiento con augmentation\u001b[39;00m\n\u001b[32m      2\u001b[39m train_transforms = A.Compose([\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mA\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRandomResizedCrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimg_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimg_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m      4\u001b[39m     A.HorizontalFlip(p=\u001b[32m0.5\u001b[39m),\n\u001b[32m      5\u001b[39m     A.RandomBrightnessContrast(brightness_limit=\u001b[32m0.2\u001b[39m, contrast_limit=\u001b[32m0.2\u001b[39m, p=\u001b[32m0.5\u001b[39m),\n\u001b[32m      6\u001b[39m     A.ShiftScaleRotate(shift_limit=\u001b[32m0.1\u001b[39m, scale_limit=\u001b[32m0.1\u001b[39m, rotate_limit=\u001b[32m15\u001b[39m, p=\u001b[32m0.5\u001b[39m),\n\u001b[32m      7\u001b[39m     A.Normalize(mean=[\u001b[32m0.485\u001b[39m, \u001b[32m0.456\u001b[39m, \u001b[32m0.406\u001b[39m], std=[\u001b[32m0.229\u001b[39m, \u001b[32m0.224\u001b[39m, \u001b[32m0.225\u001b[39m]),\n\u001b[32m      8\u001b[39m     ToTensorV2()\n\u001b[32m      9\u001b[39m ])\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Transformaciones de validación/test sin augmentation\u001b[39;00m\n\u001b[32m     12\u001b[39m val_transforms = A.Compose([\n\u001b[32m     13\u001b[39m     A.Resize(height=CONFIG[\u001b[33m'\u001b[39m\u001b[33mimg_size\u001b[39m\u001b[33m'\u001b[39m], width=CONFIG[\u001b[33m'\u001b[39m\u001b[33mimg_size\u001b[39m\u001b[33m'\u001b[39m]),\n\u001b[32m     14\u001b[39m     A.Normalize(mean=[\u001b[32m0.485\u001b[39m, \u001b[32m0.456\u001b[39m, \u001b[32m0.406\u001b[39m], std=[\u001b[32m0.229\u001b[39m, \u001b[32m0.224\u001b[39m, \u001b[32m0.225\u001b[39m]),\n\u001b[32m     15\u001b[39m     ToTensorV2()\n\u001b[32m     16\u001b[39m ])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/University/U-Tad/3th_Course/Q1/Artificial_Intelligence/Unit_3/AEC1/.venv/lib/python3.13/site-packages/albumentations/core/validation.py:105\u001b[39m, in \u001b[36mValidatedTransformMeta.__new__.<locals>.custom_init\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcustom_init\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    103\u001b[39m     full_kwargs, param_names, strict = \u001b[38;5;28mcls\u001b[39m._process_init_parameters(original_init, args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     validated_kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_parameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdct\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mInitSchema\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfull_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparam_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_default_values(signature(original_init).parameters)\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# Store and check invalid args\u001b[39;00m\n\u001b[32m    113\u001b[39m     invalid_args = [name_arg \u001b[38;5;28;01mfor\u001b[39;00m name_arg \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01mif\u001b[39;00m name_arg \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m param_names \u001b[38;5;129;01mand\u001b[39;00m name_arg != \u001b[33m\"\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/University/U-Tad/3th_Course/Q1/Artificial_Intelligence/Unit_3/AEC1/.venv/lib/python3.13/site-packages/albumentations/core/validation.py:71\u001b[39m, in \u001b[36mValidatedTransformMeta._validate_parameters\u001b[39m\u001b[34m(schema_cls, full_kwargs, param_names, strict)\u001b[39m\n\u001b[32m     69\u001b[39m     validated_kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m strict:\n",
      "\u001b[31mValueError\u001b[39m: 1 validation error for InitSchema\nsize\n  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...': 1.0, 'strict': False}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing"
     ]
    }
   ],
   "source": [
    "# Transformaciones de entrenamiento con augmentation\n",
    "train_transforms = A.Compose([\n",
    "    A.RandomResizedCrop(height=CONFIG['img_size'], width=CONFIG['img_size'], scale=(0.8, 1.0)),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Transformaciones de validación/test sin augmentation\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(height=CONFIG['img_size'], width=CONFIG['img_size']),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "print(\"Transformaciones definidas\")\n",
    "print(f\"   - Train: RandomCrop, HorizontalFlip, Brightness/Contrast, Rotation\")\n",
    "print(f\"   - Val/Test: Solo resize y normalización\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo con EfficientNet-B3 (ENTRENADO DESDE CERO)\n",
    "**[v2.0 - 31/10/2025 03:00 AM]** - CRÍTICO: Cambiado a entrenamiento desde cero (sin pesos preentrenados)\n",
    "\n",
    "⚠️ **IMPORTANTE**: Este modelo se entrena completamente desde cero, sin usar pesos de ImageNet.\n",
    "Todos los parámetros se inicializan aleatoriamente y se aprenden durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo modelo con transfer learning (PERO SIN PESOS PREENTRENADOS)\n",
    "def create_model(model_name, num_classes, pretrained=False):  # CAMBIADO A FALSE\n",
    "    model = timm.create_model(model_name, pretrained=pretrained, num_classes=num_classes)\n",
    "    print(f\"   [INFO] Modelo creado DESDE CERO (pretrained={pretrained})\")\n",
    "    print(f\"   [INFO] Todos los pesos inicializados aleatoriamente\")\n",
    "    return model\n",
    "\n",
    "# Congelo el backbone para etapa 1\n",
    "def freeze_backbone(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'classifier' not in name:\n",
    "            param.requires_grad = False\n",
    "    return model\n",
    "\n",
    "# Descongelo todo para etapa 2\n",
    "def unfreeze_backbone(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    return model\n",
    "\n",
    "model = create_model(CONFIG['model_name'], CONFIG['num_classes'], pretrained=False)  # CAMBIADO A FALSE\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Modelo creado: {CONFIG['model_name']}\")\n",
    "print(f\"   - Parámetros totales: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"   - Parámetros entrenables: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de Entrenamiento y Validación\n",
    "**[v1.3 - 30/10/2025 00:45 AM]** - Añadido Mixed Precision Training (AMP)\n",
    "\n",
    "Implemento las funciones para entrenar y validar el modelo con mixed precision training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de entrenamiento con mixed precision\n",
    "def train_epoch(model, dataloader, criterion, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Función de validación\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "print(\"Funciones de entrenamiento y validación definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento con K-Fold Cross-Validation\n",
    "\n",
    "commits Hechos:\n",
    "\n",
    "**[v1.1 - 30/10/2025 00:10 AM]** - Implementado K-Fold (5 folds)  \n",
    "**[v1.2 - 30/10/2025 00:30 AM]** - Añadido Early Stopping y Label Smoothing\n",
    "\n",
    "Entreno el modelo con 5 folds y 2 etapas por fold:\n",
    "1. **Etapa 1**: Solo entreno la cabeza con el backbone congelado\n",
    "2. **Etapa 2**: Fine-tuning completo descongelando todo el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VERIFICACIÓN PRE-ENTRENAMIENTO\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VERIFICACION DE DATOS ANTES DEL ENTRENAMIENTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Verifico que las variables existen y no están vacías\n",
    "print(\"\\n[1] Verificando variables train_paths y train_labels:\")\n",
    "try:\n",
    "    print(f\"   [OK] train_paths existe: {type(train_paths)}\")\n",
    "    print(f\"   [OK] train_labels existe: {type(train_labels)}\")\n",
    "    print(f\"   [OK] Número de muestras: {len(train_paths)}\")\n",
    "    print(f\"   [OK] Tipos correctos: {train_paths.dtype}, {train_labels.dtype}\")\n",
    "except NameError as e:\n",
    "    print(f\"   [ERROR] Variable no definida - {e}\")\n",
    "    raise\n",
    "\n",
    "# 2. Verifico que las longitudes coinciden\n",
    "print(\"\\n[2] Verificando que las listas son paralelas:\")\n",
    "if len(train_paths) == len(train_labels):\n",
    "    print(f\"   [OK] Longitudes coinciden: {len(train_paths)} == {len(train_labels)}\")\n",
    "else:\n",
    "    raise ValueError(f\"   [ERROR] Longitudes no coinciden: {len(train_paths)} != {len(train_labels)}\")\n",
    "\n",
    "# 3. Verifico distribución de clases\n",
    "print(\"\\n[3] Verificando distribución de clases:\")\n",
    "unique_labels, counts = np.unique(train_labels, return_counts=True)\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    class_name = \"Gato\" if label == 0 else \"Perro\"\n",
    "    percentage = (count / len(train_labels)) * 100\n",
    "    print(f\"   Clase {label} ({class_name}): {count} muestras ({percentage:.2f}%)\")\n",
    "\n",
    "# 4. Verifico que las rutas de archivos existen\n",
    "print(\"\\n[4] Verificando existencia de archivos (muestreo de 5):\")\n",
    "sample_indices = np.random.choice(len(train_paths), size=min(5, len(train_paths)), replace=False)\n",
    "for idx in sample_indices:\n",
    "    path = train_paths[idx]\n",
    "    exists = os.path.exists(path)\n",
    "    label = train_labels[idx]\n",
    "    status = \"[OK]\" if exists else \"[ERROR]\"\n",
    "    print(f\"   {status} {os.path.basename(path)} (label={label})\")\n",
    "\n",
    "# 5. Verifico que puedo cargar una imagen de muestra\n",
    "print(\"\\n[5] Probando carga de una imagen de muestra:\")\n",
    "try:\n",
    "    test_img_path = train_paths[0]\n",
    "    test_img = Image.open(test_img_path).convert('RGB')\n",
    "    test_img_array = np.array(test_img)\n",
    "    print(f\"   [OK] Imagen cargada correctamente\")\n",
    "    print(f\"   Dimensiones: {test_img_array.shape}\")\n",
    "    print(f\"   Rango de valores: [{test_img_array.min()}, {test_img_array.max()}]\")\n",
    "except Exception as e:\n",
    "    print(f\"   [ERROR] al cargar imagen: {e}\")\n",
    "    raise\n",
    "\n",
    "# 6. Verifico compatibilidad con StratifiedKFold\n",
    "print(\"\\n[6] Verificando compatibilidad con StratifiedKFold:\")\n",
    "try:\n",
    "    test_skf = StratifiedKFold(n_splits=CONFIG['num_folds'], shuffle=True, random_state=CONFIG['seed'])\n",
    "    splits = list(test_skf.split(train_paths, train_labels))\n",
    "    print(f\"   [OK] StratifiedKFold generó {len(splits)} splits correctamente\")\n",
    "    print(f\"   Tamaños de los splits:\")\n",
    "    for i, (train_idx, val_idx) in enumerate(splits[:3]):  # Muestro solo los primeros 3\n",
    "        print(f\"      Fold {i+1}: Train={len(train_idx)}, Val={len(val_idx)}\")\n",
    "except Exception as e:\n",
    "    print(f\"   [ERROR] en StratifiedKFold: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"[OK] TODAS LAS VERIFICACIONES PASADAS - LISTO PARA ENTRENAR\")\n",
    "print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=CONFIG['num_folds'], shuffle=True, random_state=CONFIG['seed'])\n",
    "\n",
    "fold_models = []\n",
    "fold_metrics = []\n",
    "\n",
    "print(f\"Iniciando entrenamiento con {CONFIG['num_folds']} folds\\n\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_paths, train_labels)):\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"FOLD {fold + 1}/{CONFIG['num_folds']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    fold_train_paths = train_paths[train_idx]\n",
    "    fold_train_labels = train_labels[train_idx]\n",
    "    fold_val_paths = train_paths[val_idx]\n",
    "    fold_val_labels = train_labels[val_idx]\n",
    "    \n",
    "    train_dataset = DogsVsCatsDataset(fold_train_paths, fold_train_labels, transforms=train_transforms)\n",
    "    val_dataset = DogsVsCatsDataset(fold_val_paths, fold_val_labels, transforms=val_transforms)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], \n",
    "                             shuffle=True, num_workers=CONFIG['num_workers'], pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], \n",
    "                           shuffle=False, num_workers=CONFIG['num_workers'], pin_memory=True)\n",
    "    \n",
    "    model = create_model(CONFIG['model_name'], CONFIG['num_classes'], pretrained=False)  # DESDE CERO\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # ETAPA 1: entreno solo la cabeza\n",
    "    print(f\"\\nEtapa 1: Entrenando solo la cabeza ({CONFIG['epochs_stage1']} epochs)\")\n",
    "    model = freeze_backbone(model)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=CONFIG['label_smoothing'])\n",
    "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "                           lr=CONFIG['lr_stage1'], weight_decay=CONFIG['weight_decay'])\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(CONFIG['epochs_stage1']):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scaler, device)\n",
    "        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{CONFIG['epochs_stage1']} - \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "    \n",
    "    # ETAPA 2: fine-tuning completo\n",
    "    print(f\"\\nEtapa 2: Fine-tuning completo ({CONFIG['epochs_stage2']} epochs)\")\n",
    "    model = unfreeze_backbone(model)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['lr_stage2'], \n",
    "                           weight_decay=CONFIG['weight_decay'])\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    patience_limit = 5\n",
    "    \n",
    "    for epoch in range(CONFIG['epochs_stage2']):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scaler, device)\n",
    "        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{CONFIG['epochs_stage2']} - \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "            print(f\"   -> Nuevo mejor modelo (Val Acc: {val_acc:.2f}%)\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= patience_limit:\n",
    "            print(f\"   -> Early stopping en epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    fold_models.append(model)\n",
    "    fold_metrics.append({\n",
    "        'fold': fold + 1,\n",
    "        'best_val_acc': best_val_acc,\n",
    "        'val_loss': val_loss\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nFold {fold + 1} completado - Mejor Val Acc: {best_val_acc:.2f}%\\n\")\n",
    "\n",
    "# Resumen de todos los folds\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"RESUMEN DE ENTRENAMIENTO\")\n",
    "print(f\"{'='*60}\")\n",
    "for metric in fold_metrics:\n",
    "    print(f\"Fold {metric['fold']}: Val Acc = {metric['best_val_acc']:.2f}%\")\n",
    "\n",
    "avg_val_acc = np.mean([m['best_val_acc'] for m in fold_metrics])\n",
    "print(f\"\\nAccuracy promedio en validación: {avg_val_acc:.2f}%\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencia en Test Set\n",
    "\n",
    "Cargo las imágenes de test y genero predicciones promediando los 5 modelos de los folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset de test\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_dir, transforms=None):\n",
    "        self.test_dir = test_dir\n",
    "        self.transforms = transforms\n",
    "        self.image_files = sorted([f for f in os.listdir(test_dir) if f.endswith('.jpg')])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.test_dir, img_name)\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        \n",
    "        img_id = int(img_name.split('.')[0])\n",
    "        return image, img_id\n",
    "\n",
    "test_dataset = TestDataset(CONFIG['test_dir'], transforms=val_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], \n",
    "                         shuffle=False, num_workers=CONFIG['num_workers'], pin_memory=True)\n",
    "\n",
    "print(f\"Dataset de test cargado: {len(test_dataset)} imágenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero predicciones promediando los 5 folds\n",
    "print(\"Generando predicciones...\")\n",
    "\n",
    "all_predictions = []\n",
    "all_ids = []\n",
    "\n",
    "for model in fold_models:\n",
    "    model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, img_ids in test_loader:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        fold_preds = []\n",
    "        for model in fold_models:\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            fold_preds.append(probs.cpu().numpy())\n",
    "        \n",
    "        avg_probs = np.mean(fold_preds, axis=0)\n",
    "        all_predictions.extend(avg_probs)\n",
    "        all_ids.extend(img_ids.numpy())\n",
    "\n",
    "print(f\"Predicciones generadas: {len(all_predictions)} imágenes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación del archivo Submission\n",
    "\n",
    "Creo el archivo `submission.csv` con las predicciones finales para subir a Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el submission\n",
    "# Convierto las probabilidades a etiquetas binarias (0=gato, 1=perro)\n",
    "binary_predictions = (np.array(all_predictions) > 0.5).astype(int)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': all_ids,\n",
    "    'label': binary_predictions\n",
    "})\n",
    "\n",
    "submission_df = submission_df.sort_values('id').reset_index(drop=True)\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Archivo submission.csv generado correctamente\")\n",
    "print(f\"\\nPrimeras predicciones:\")\n",
    "print(submission_df.head(10))\n",
    "print(f\"\\nDistribución de predicciones:\")\n",
    "print(f\"   - Gatos (label=0): {(submission_df['label'] == 0).sum()}\")\n",
    "print(f\"   - Perros (label=1): {(submission_df['label'] == 1).sum()}\")\n",
    "print(f\"\\nTotal de predicciones: {len(submission_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de Predicciones (mi bonus)\n",
    "\n",
    "Muestro algunas imágenes del test set con sus predicciones para verificar visualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizo predicciones aleatorias\n",
    "def visualize_predictions(num_images=9):\n",
    "    random_indices = np.random.choice(len(submission_df), size=num_images, replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, idx in enumerate(random_indices):\n",
    "        img_id = submission_df.iloc[idx]['id']\n",
    "        prediction = submission_df.iloc[idx]['label']\n",
    "        \n",
    "        img_path = os.path.join(CONFIG['test_dir'], f\"{img_id}.jpg\")\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        predicted_class = \"Perro\" if prediction > 0.5 else \"Gato\"\n",
    "        confidence = prediction if prediction > 0.5 else 1 - prediction\n",
    "        \n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f\"ID: {img_id}\\n{predicted_class} ({confidence*100:.1f}%)\", \n",
    "                         fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(num_images=9)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13710467,
     "sourceId": 114912,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
