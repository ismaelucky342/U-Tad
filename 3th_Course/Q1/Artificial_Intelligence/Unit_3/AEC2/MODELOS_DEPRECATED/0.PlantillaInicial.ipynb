{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":86515,"databundleVersionId":9809442,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### This is a minimal working \"starter\" notebook for the [[U-Tad] Dogs vs. Cats 2025](https://www.kaggle.com/competitions/u-tad-dogs-vs-cats-2025) competition.\nClick on **Copy & Edit** to copy this notebook to your account and start working.","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom tensorflow import data as tf_data\nimport keras\n\nseed = 42\nkeras.utils.set_random_seed(seed)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Read in the training data","metadata":{}},{"cell_type":"code","source":"image_size = (256, 256)\n\n# when working with 20_000 files for training this\n# will lead to exactly 160 mini-batches per epoch\nbatch_size = 125\n\n# https://keras.io/api/data_loading/image/#imagedatasetfromdirectory-function\ntrain_ds, val_ds = keras.utils.image_dataset_from_directory(\n    #\"PetImages\",\n    \"/kaggle/input/u-tad-dogs-vs-cats-2025/train/train\",\n    validation_split=0.2,\n    subset=\"both\",\n    seed=seed,\n    image_size=image_size,\n    batch_size=batch_size,\n    labels=\"inferred\",\n    label_mode=\"categorical\",\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### A basic sequential CNN model","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\n\ninput_shape = image_size + (3,)\n\nmodel = Sequential()\nmodel.add(keras.Input(shape=input_shape))\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(2, activation='softmax'))\n\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Compile and train (fit)","metadata":{}},{"cell_type":"code","source":"%%time\n\nmodel.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.001,\n                                                 momentum=0.0),\n                                                 loss='categorical_crossentropy',\n                                                 metrics=['accuracy'])\n\nepochs = 12\n\nhistory = model.fit(train_ds,\n                    validation_data = val_ds,\n                    epochs = epochs,)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Plot the learning curves","metadata":{}},{"cell_type":"code","source":"logs = pd.DataFrame(history.history)\n\nplt.figure(figsize=(14, 4))\nplt.subplot(1, 2, 1)\nplt.plot(logs.loc[1:,\"loss\"], lw=2, label='training loss')\nplt.plot(logs.loc[1:,\"val_loss\"], lw=2, label='validation loss')\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.subplot(1, 2, 2)\nplt.plot(logs.loc[1:,\"accuracy\"], lw=2, label='training accuracy')\nplt.plot(logs.loc[1:,\"val_accuracy\"], lw=2, label='validation accuracy')\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend(loc='lower right')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Save the trained model","metadata":{}},{"cell_type":"code","source":"model.save(\"model.keras\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Evaluate model performance using the `supplementary_data`","metadata":{}},{"cell_type":"code","source":"supplementary_ds = keras.utils.image_dataset_from_directory(\n    #\"PetImages\",\n    \"/kaggle/input/u-tad-dogs-vs-cats-2025/supplementary_data/supplementary_data\",\n    image_size=image_size,\n    batch_size=batch_size,\n    labels=\"inferred\",\n    label_mode=\"categorical\",\n)\n\nmodel.evaluate(supplementary_ds,\n               return_dict=True,\n               verbose=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Create predictions for all of the test images\n(Do not modify this section)","metadata":{}},{"cell_type":"code","source":"%%time\n\nfolder_path = \"/kaggle/input/u-tad-dogs-vs-cats-2025/test/test\"\n\npredictions_dict = {}\n\nfor img in os.listdir(folder_path):\n    img = os.path.join(folder_path, img)\n    \n    # save the image name\n    file_name = img.split('/')[-1]\n    file_no_extension = file_name.split('.')[0]\n    \n    img = keras.utils.load_img(img, target_size=image_size)\n    img_array = keras.utils.img_to_array(img)\n    img_array = keras.ops.expand_dims(img_array, 0)\n    prediction = model.predict(img_array, verbose=None)\n    label = np.argmax(prediction)\n\n    # save the predictions to a dictionary\n    predictions_dict[int(file_no_extension)] = label","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Save your predictions to a competition submission file","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame(predictions_dict.items(), columns=[\"id\", \"label\"]).sort_values(by='id', ascending=True)\nsubmission.to_csv('submission.csv',index=False)\n\n# print numbers of each class label\nsubmission[\"label\"].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}