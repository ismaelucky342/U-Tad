{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "#====================================================================================================#\n",
    "#                                                                                                    #\n",
    "#                                                        ██╗   ██╗   ████████╗ █████╗ ██████╗        #\n",
    "#      Competición - INAR                                ██║   ██║   ╚══██╔══╝██╔══██╗██╔══██╗       #\n",
    "#                                                        ██║   ██║█████╗██║   ███████║██║  ██║       #\n",
    "#      created:        29/10/2025  -  23:00:15           ██║   ██║╚════╝██║   ██╔══██║██║  ██║       #\n",
    "#      last change:    06/11/2025  -  23:55:40           ╚██████╔╝      ██║   ██║  ██║██████╔╝       #\n",
    "#                                                         ╚═════╝       ╚═╝   ╚═╝  ╚═╝╚═════╝        #\n",
    "#                                                                                                    #\n",
    "#      Ismael Hernandez Clemente                         ismael.hernandez@live.u-tad.com             #\n",
    "#                                                                                                    #\n",
    "#      Github:                                           https://github.com/ismaelucky342            #\n",
    "#                                                                                                    #\n",
    "#====================================================================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competición Perretes y Gatos\n",
    "\n",
    "## Iteración 5 - Fine-tuning VGG16\n",
    "\n",
    "**Situación actual**: Iteración 5 con Transfer Learning consiguió 0.86380 (posición #7).\n",
    "\n",
    "**Pasos que voy a hacer con Fine-tuning**:\n",
    "- VGG16 pre-entrenado en ImageNet (14M imágenes)\n",
    "- Descongelar las últimas 4 capas convolucionales (block5)\n",
    "- Learning rate MUY bajo (1e-5) para no romper pesos pre-entrenados\n",
    "- Solo 10 épocas adicionales con ajuste fino\n",
    "- Objetivo: +2-4% score → 0.88-0.90\n",
    "\n",
    "**kaggle score**: 0.89552, lo cual mejora respecto al anterior -> siguiente planteamiento aplicar esemble con 3 modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Importo las librerías necesarias para trabajar con el modelo y los datos\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import data as tf_data\n",
    "import keras\n",
    "\n",
    "# Establezco una semilla aleatoria para que los resultados sean reproducibles\n",
    "seed = 42\n",
    "keras.utils.set_random_seed(seed)\n",
    "\n",
    "# Rutas de datos - cambia solo el nombre del dataset si es diferente\n",
    "DATASET_NAME = \"u-tad-dogs-vs-cats-2025\"\n",
    "TRAIN_PATH = f\"/kaggle/input/{DATASET_NAME}/train/train\"\n",
    "TEST_PATH = f\"/kaggle/input/{DATASET_NAME}/test/test\"\n",
    "SUPP_PATH = f\"/kaggle/input/{DATASET_NAME}/supplementary_data/supplementary_data\"\n",
    "\n",
    "print(\"Versión de Keras:\", keras.__version__)\n",
    "print(\"Rutas configuradas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y Preparación de los Datos\n",
    "\n",
    "Cargo las imágenes del conjunto de entrenamiento y las divido automáticamente en dos partes:\n",
    "- **80% para entrenamiento**: El modelo aprende de estas imágenes\n",
    "- **20% para validación**: Evalúo el rendimiento en cada época sin que el modelo las haya visto\n",
    "\n",
    "Esta división me permite detectar si el modelo está memorizando (overfitting) en lugar de\n",
    "aprender patrones generalizables. Todas las imágenes se redimensionan a **224x224 píxeles**,\n",
    "que es el tamaño de entrada estándar requerido por VGG16.\n",
    "\n",
    "El modo `binary` es crucial para clasificación de 2 clases, ya que genera etiquetas 0/1\n",
    "en lugar de vectores one-hot, lo que simplifica la salida y evita problemas de calibración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tamaño de imagen - 224x224 para VGG16\n",
    "image_size = (224, 224)\n",
    "\n",
    "# Batch size\n",
    "batch_size = 125\n",
    "\n",
    "# Cargo las imágenes del directorio de entrenamiento\n",
    "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=seed,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",  # Cambio a binary\n",
    ")\n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {len(train_ds)} batches\")\n",
    "print(f\"Tamaño del conjunto de validación: {len(val_ds)} batches\")\n",
    "print(f\"Total imágenes de entrenamiento aproximadas: {len(train_ds) * batch_size}\")\n",
    "print(f\"Total imágenes de validación aproximadas: {len(val_ds) * batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation (Aumento de Datos)\n",
    "\n",
    "Aplico transformaciones aleatorias a las imágenes **solo durante el entrenamiento** para\n",
    "hacer el modelo más robusto y evitar que memorice. Estas transformaciones simulan variaciones\n",
    "naturales que puede encontrar el modelo en datos reales:\n",
    "\n",
    "- **RandomFlip horizontal**: Voltea la imagen (perros/gatos pueden estar orientados de cualquier forma)\n",
    "- **RandomRotation (±36°)**: Rotaciones suaves que no distorsionan la imagen\n",
    "- **RandomZoom (±10%)**: Acerca o aleja la imagen ligeramente\n",
    "- **RandomTranslation (±10%)**: Desplaza la imagen horizontal y verticalmente\n",
    "\n",
    "He configurado transformaciones **conservadoras** (valores bajos) porque VGG16 ya conoce\n",
    "características generales de millones de imágenes. No necesito augmentation agresivo como\n",
    "en un modelo entrenado desde cero, solo variaciones sutiles para mejorar la generalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secuencia de transformaciones aleatorias aplicadas solo durante entrenamiento\n",
    "# Más conservador para Transfer Learning\n",
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.RandomFlip(\"horizontal\"),\n",
    "    keras.layers.RandomRotation(0.1),  # ±36° suficiente\n",
    "    keras.layers.RandomZoom(0.1),      # ±10% sin distorsión\n",
    "    keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "print(\"Data Augmentation configurado (modo conservador para Transfer Learning)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción del Modelo - Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.applications import VGG16\n",
    "\n",
    "# Forma de entrada: 224x224 con 3 canales RGB (requerido por VGG16)\n",
    "input_shape = image_size + (3,)\n",
    "\n",
    "# Cargo VGG16 pre-entrenado sin la parte superior (sin clasificación)\n",
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=input_shape,\n",
    "    pooling='avg'  # Global Average Pooling\n",
    ")\n",
    "\n",
    "# congelo todas las capas de VGG16 - no las voy a entrenar\n",
    "base_model.trainable = False\n",
    "\n",
    "# Construyo el modelo completo\n",
    "model = Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    data_augmentation,  # Augmentation solo en entrenamiento\n",
    "    base_model,         # VGG16 congelado\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Salida binaria\n",
    "], name='VGG16_Transfer_Learning')\n",
    "\n",
    "print(f\"Modelo Transfer Learning creado\")\n",
    "print(f\"Capas VGG16 congeladas: {len(base_model.layers)}\")\n",
    "print(f\"Solo entrenaremos: Dense(256) + Dropout + Dense(1)\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilación y Entrenamiento - Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),  # LR bajo para Transfer Learning\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "epochs = 15  # Transfer Learning converge rápido\n",
    "\n",
    "# ReduceLROnPlateau: reduce el learning rate si se estanca\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Configuración Transfer Learning VGG16:\")\n",
    "print(f\"Épocas: {epochs}\")\n",
    "print(f\"Optimizer: Adam (lr=0.0001)\")\n",
    "print(f\"Modelo base: VGG16 ImageNet (congelado)\")\n",
    "print(f\"Entrenamos: Solo 2 capas Dense\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"Entrenamiento completado en {len(history.history['loss'])} épocas\")\n",
    "print(f\"Val Accuracy final: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Val Precision final: {history.history['val_precision'][-1]:.4f}\")\n",
    "print(f\"Val Recall final: {history.history['val_recall'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de las Curvas de Aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "logs = pd.DataFrame(history.history)\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "# Gráfico de pérdida\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(logs.loc[1:, \"loss\"], lw=2, label='Pérdida en entrenamiento')\n",
    "plt.plot(logs.loc[1:, \"val_loss\"], lw=2, label='Pérdida en validación')\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Pérdida\")\n",
    "plt.title(\"Evolución de la Pérdida\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico de precisión\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(logs.loc[1:, \"accuracy\"], lw=2, label='Precisión en entrenamiento')\n",
    "plt.plot(logs.loc[1:, \"val_accuracy\"], lw=2, label='Precisión en validación')\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.title(\"Evolución de la Precisión\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTADOS FINALES:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Precisión final en entrenamiento: {logs['accuracy'].iloc[-1]:.4f}\")\n",
    "print(f\"Precisión final en validación: {logs['val_accuracy'].iloc[-1]:.4f}\")\n",
    "print(f\"Pérdida final en entrenamiento: {logs['loss'].iloc[-1]:.4f}\")\n",
    "print(f\"Pérdida final en validación: {logs['val_loss'].iloc[-1]:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardado del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save(\"model.keras\")\n",
    "print(\"Modelo guardado como 'model.keras'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación con Datos Suplementarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "supplementary_ds = keras.utils.image_dataset_from_directory(\n",
    "    SUPP_PATH,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",  # Binary consistente\n",
    ")\n",
    "\n",
    "print(\"Evaluando con datos suplementarios...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "results = model.evaluate(supplementary_ds, return_dict=True, verbose=1)\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"\\nRESULTADOS EN DATOS SUPLEMENTARIOS:\")\n",
    "print(f\"Precisión: {results['accuracy']:.4f}\")\n",
    "print(f\"Pérdida: {results['loss']:.4f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de Predicciones para Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictions_dict = {}\n",
    "\n",
    "print(f\"Generando predicciones para {len(os.listdir(TEST_PATH))} imágenes del conjunto de test...\")\n",
    "print(\"Usando umbral 0.5 para clasificación binaria (probabilidad >= 0.5 → Dog, < 0.5 → Cat)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Itero sobre todas las imágenes del directorio de test\n",
    "for img in os.listdir(TEST_PATH):\n",
    "    img_path = os.path.join(TEST_PATH, img)\n",
    "    file_name = img_path.split('/')[-1]\n",
    "    file_no_extension = file_name.split('.')[0]  # ID numérico de la imagen\n",
    "    \n",
    "    # Cargo la imagen y la preparo para el modelo\n",
    "    img_loaded = keras.utils.load_img(img_path, target_size=image_size)\n",
    "    img_array = keras.utils.img_to_array(img_loaded)\n",
    "    img_array = keras.ops.expand_dims(img_array, 0)  # Añado dimensión de batch\n",
    "    \n",
    "    # Predigo probabilidad con el modelo fine-tuned\n",
    "    # Salida sigmoid: valor entre 0 (Cat) y 1 (Dog)\n",
    "    prediction = model.predict(img_array, verbose=0)[0][0]\n",
    "    \n",
    "    # Conversión explícita a clase binaria\n",
    "    label = 1 if prediction >= 0.5 else 0\n",
    "    \n",
    "    predictions_dict[int(file_no_extension)] = label\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"Predicciones completadas: {len(predictions_dict)} imágenes procesadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del Archivo de Submission para Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el DataFrame con las predicciones y lo ordeno por ID\n",
    "submission = pd.DataFrame(predictions_dict.items(), columns=[\"id\", \"label\"])\n",
    "submission = submission.sort_values(by='id', ascending=True)\n",
    "\n",
    "# Guardo el archivo CSV para Kaggle\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ARCHIVO DE SUBMISSION CREADO: submission.csv\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Estadísticas de las predicciones\n",
    "print(\"\\nDISTRIBUCION DE PREDICCIONES:\")\n",
    "print(\"-\" * 70)\n",
    "print(submission[\"label\"].value_counts())\n",
    "print()\n",
    "print(f\"Clase 0 (Cat): {(submission['label'] == 0).sum():4d} imágenes ({100*(submission['label'] == 0).sum()/len(submission):5.1f}%)\")\n",
    "print(f\"Clase 1 (Dog): {(submission['label'] == 1).sum():4d} imágenes ({100*(submission['label'] == 1).sum()/len(submission):5.1f}%)\")\n",
    "print(f\"Total:         {len(submission):4d} imágenes\")\n",
    "\n",
    "# Muestro ejemplos de predicciones\n",
    "print(\"\\nPRIMERAS 10 PREDICCIONES:\")\n",
    "print(submission.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nULTIMAS 10 PREDICCIONES:\")\n",
    "print(submission.tail(10).to_string(index=False))\n",
    "\n",
    "# detectar si todas las predicciones son de una sola clase\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if (submission['label'] == 0).sum() == len(submission) or (submission['label'] == 1).sum() == len(submission):\n",
    "    print(\"ALERTA: TODAS LAS PREDICCIONES SON DE UNA SOLA CLASE\")\n",
    "    print(\"El modelo está completamente sesgado. NO enviar a Kaggle.\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"VERIFICACION EXITOSA\")\n",
    "    print(\"  - Distribucion de clases balanceada\")\n",
    "    print(\"  - Archivo listo para enviar a Kaggle\")\n",
    "    print(\"  - Mejora esperada respecto a Iter 5: +2-4% (0.88-0.90)\")\n",
    "    print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9809442,
     "sourceId": 86515,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
