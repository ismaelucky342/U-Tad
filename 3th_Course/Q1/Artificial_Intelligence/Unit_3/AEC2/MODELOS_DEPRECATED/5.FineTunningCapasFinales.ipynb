{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "#====================================================================================================#\n",
    "#                                                                                                    #\n",
    "#                                                        ██╗   ██╗   ████████╗ █████╗ ██████╗        #\n",
    "#      Competición - INAR                                ██║   ██║   ╚══██╔══╝██╔══██╗██╔══██╗       #\n",
    "#                                                        ██║   ██║█████╗██║   ███████║██║  ██║       #\n",
    "#      created:        29/10/2025  -  23:00:15           ██║   ██║╚════╝██║   ██╔══██║██║  ██║       #\n",
    "#      last change:    06/11/2025  -  23:55:40           ╚██████╔╝      ██║   ██║  ██║██████╔╝       #\n",
    "#                                                         ╚═════╝       ╚═╝   ╚═╝  ╚═╝╚═════╝        #\n",
    "#                                                                                                    #\n",
    "#      Ismael Hernandez Clemente                         ismael.hernandez@live.u-tad.com             #\n",
    "#                                                                                                    #\n",
    "#      Github:                                           https://github.com/ismaelucky342            #\n",
    "#                                                                                                    #\n",
    "#====================================================================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competición Perretes y Gatos\n",
    "\n",
    "## Iteración 5 - Fine-tuning VGG16\n",
    "\n",
    "**Situación actual**: Iteración 5 con Transfer Learning consiguió 0.86380 (posición #7).\n",
    "\n",
    "**Pasos que voy a hacer con Fine-tuning**:\n",
    "- VGG16 pre-entrenado en ImageNet (14M imágenes)\n",
    "- Descongelar las últimas 4 capas convolucionales (block5)\n",
    "- Learning rate MUY bajo (1e-5) para no romper pesos pre-entrenados\n",
    "- Solo 10 épocas adicionales con ajuste fino\n",
    "- Objetivo: +2-4% score → 0.88-0.90\n",
    "\n",
    "**kaggle score**: 0.89552, lo cual mejora respecto al anterior -> siguiente planteamiento aplicar esemble con 3 modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Importo las librerías necesarias para trabajar con el modelo y los datos\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import data as tf_data\n",
    "import keras\n",
    "\n",
    "# Establezco una semilla aleatoria para que los resultados sean reproducibles\n",
    "seed = 42\n",
    "keras.utils.set_random_seed(seed)\n",
    "\n",
    "# Rutas de datos - cambia solo el nombre del dataset si es diferente\n",
    "DATASET_NAME = \"u-tad-dogs-vs-cats-2025\"\n",
    "TRAIN_PATH = f\"/kaggle/input/{DATASET_NAME}/train/train\"\n",
    "TEST_PATH = f\"/kaggle/input/{DATASET_NAME}/test/test\"\n",
    "SUPP_PATH = f\"/kaggle/input/{DATASET_NAME}/supplementary_data/supplementary_data\"\n",
    "\n",
    "print(\"Versión de Keras:\", keras.__version__)\n",
    "print(\"Rutas configuradas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y Preparación de los Datos\n",
    "\n",
    "Cargo las imágenes del conjunto de entrenamiento y las divido automáticamente en dos partes:\n",
    "- **80% para entrenamiento**: El modelo aprende de estas imágenes\n",
    "- **20% para validación**: Evalúo el rendimiento en cada época sin que el modelo las haya visto\n",
    "\n",
    "Esta división me permite detectar si el modelo está memorizando (overfitting) en lugar de\n",
    "aprender patrones generalizables. Todas las imágenes se redimensionan a **224x224 píxeles**,\n",
    "que es el tamaño de entrada estándar requerido por VGG16.\n",
    "\n",
    "El modo `binary` es crucial para clasificación de 2 clases, ya que genera etiquetas 0/1\n",
    "en lugar de vectores one-hot, lo que simplifica la salida y evita problemas de calibración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tamaño de imagen - 224x224 para VGG16\n",
    "image_size = (224, 224)\n",
    "\n",
    "# Batch size\n",
    "batch_size = 125\n",
    "\n",
    "# Cargo las imágenes del directorio de entrenamiento\n",
    "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=seed,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",  # Cambio a binary para más estabilidad\n",
    ")\n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {len(train_ds)} batches\")\n",
    "print(f\"Tamaño del conjunto de validación: {len(val_ds)} batches\")\n",
    "print(f\"Total imágenes de entrenamiento aproximadas: {len(train_ds) * batch_size}\")\n",
    "print(f\"Total imágenes de validación aproximadas: {len(val_ds) * batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation (Aumento de Datos)\n",
    "\n",
    "Aplico transformaciones aleatorias a las imágenes **solo durante el entrenamiento** para\n",
    "hacer el modelo más robusto y evitar que memorice. Estas transformaciones simulan variaciones\n",
    "naturales que puede encontrar el modelo en datos reales:\n",
    "\n",
    "- **RandomFlip horizontal**: Voltea la imagen (perros/gatos pueden estar orientados de cualquier forma)\n",
    "- **RandomRotation (±36°)**: Rotaciones suaves que no distorsionan la imagen\n",
    "- **RandomZoom (±10%)**: Acerca o aleja la imagen ligeramente\n",
    "- **RandomTranslation (±10%)**: Desplaza la imagen horizontal y verticalmente\n",
    "\n",
    "He configurado transformaciones **conservadoras** (valores bajos) porque VGG16 ya conoce\n",
    "características generales de millones de imágenes. No necesito augmentation agresivo como\n",
    "en un modelo entrenado desde cero, solo variaciones sutiles para mejorar la generalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secuencia de transformaciones aleatorias aplicadas solo durante entrenamiento\n",
    "# Más conservador para Transfer Learning\n",
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.RandomFlip(\"horizontal\"),\n",
    "    keras.layers.RandomRotation(0.1),  # ±36° suficiente\n",
    "    keras.layers.RandomZoom(0.1),      # ±10% sin distorsión\n",
    "    keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "print(\"Data Augmentation configurado (modo conservador para Transfer Learning)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción del Modelo - Transfer Learning\n",
    "\n",
    "**Transfer Learning** es la técnica de reutilizar un modelo pre-entrenado en un problema similar\n",
    "y adaptarlo a nuestro caso específico. En lugar de entrenar desde cero (muy lento y requiere\n",
    "millones de imágenes), aprovecho VGG16, que ya aprendió características visuales generales\n",
    "entrenándose con ImageNet (14 millones de imágenes, 1000 clases).\n",
    "\n",
    "**Arquitectura del modelo:**\n",
    "1. **Base congelada (VGG16)**: Todas las capas convolucionales permanecen fijas con sus pesos\n",
    "   pre-entrenados. Estas capas ya saben detectar bordes, texturas, formas y patrones complejos.\n",
    "   \n",
    "2. **Cabecera personalizada** (lo único que entreno):\n",
    "   - Global Average Pooling: Resume los feature maps en un vector compacto\n",
    "   - Dense(256, relu): Capa de 256 neuronas para combinar características\n",
    "   - Dropout(0.5): Desactiva aleatoriamente el 50% de neuronas para evitar overfitting\n",
    "   - Dense(1, sigmoid): Salida binaria que produce una probabilidad entre 0 (Cat) y 1 (Dog)\n",
    "\n",
    "Esta estrategia es mucho más eficiente: entreno solo ~67K parámetros en lugar de ~15M,\n",
    "y consigo excelente precisión en minutos en vez de días."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.applications import VGG16\n",
    "\n",
    "# Forma de entrada: 224x224 con 3 canales RGB (requerido por VGG16)\n",
    "input_shape = image_size + (3,)\n",
    "\n",
    "# Cargo VGG16 pre-entrenado sin la parte superior (sin clasificación)\n",
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=input_shape,\n",
    "    pooling='avg'  # Global Average Pooling\n",
    ")\n",
    "\n",
    "# CONGELO todas las capas de VGG16 - no las voy a entrenar\n",
    "base_model.trainable = False\n",
    "\n",
    "# Construyo el modelo completo\n",
    "model = Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    data_augmentation,  # Augmentation solo en entrenamiento\n",
    "    base_model,         # VGG16 congelado\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Salida binaria\n",
    "], name='VGG16_Transfer_Learning')\n",
    "\n",
    "print(f\"Modelo Transfer Learning creado\")\n",
    "print(f\"Capas VGG16 congeladas: {len(base_model.layers)}\")\n",
    "print(f\"Solo entrenaremos: Dense(256) + Dropout + Dense(1)\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilación y Entrenamiento - Transfer Learning\n",
    "\n",
    "Configuro el proceso de entrenamiento con hiperparámetros adaptados a Transfer Learning:\n",
    "\n",
    "**Optimizer: Adam con learning rate = 0.0001**\n",
    "- Adam es adaptativo y converge más rápido que SGD\n",
    "- Learning rate bajo (0.0001) porque los pesos pre-entrenados ya son buenos y no quiero\n",
    "  hacer cambios bruscos. Solo ajusto suavemente la cabecera personalizada.\n",
    "\n",
    "**Loss: Binary Crossentropy**\n",
    "- Función de pérdida estándar para clasificación binaria\n",
    "- Penaliza las predicciones incorrectas de forma logarítmica\n",
    "\n",
    "**Métricas: Accuracy, Precision, Recall**\n",
    "- Accuracy: % de predicciones correctas (métrica principal)\n",
    "- Precision: De las predicciones positivas, cuántas son correctas (evitar falsos positivos)\n",
    "- Recall: De todos los positivos reales, cuántos detectamos (evitar falsos negativos)\n",
    "\n",
    "**ReduceLROnPlateau callback:**\n",
    "- Si la validación se estanca durante 3 épocas, reduce el learning rate a la mitad\n",
    "- Esto ayuda a refinar los pesos cuando el modelo se acerca al óptimo\n",
    "- Learning rate mínimo: 1e-7\n",
    "\n",
    "**Épocas: 15**\n",
    "Transfer Learning converge rápido porque la base ya está entrenada. Con 15 épocas\n",
    "es suficiente para ajustar la cabecera personalizada sin sobreajustar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),  # LR bajo para Transfer Learning\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "epochs = 15  # Transfer Learning converge rápido\n",
    "\n",
    "# ReduceLROnPlateau: reduce el learning rate si se estanca\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Configuración Transfer Learning VGG16:\")\n",
    "print(f\"Épocas: {epochs}\")\n",
    "print(f\"Optimizer: Adam (lr=0.0001)\")\n",
    "print(f\"Modelo base: VGG16 ImageNet (congelado)\")\n",
    "print(f\"Entrenamos: Solo 2 capas Dense\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"Entrenamiento completado en {len(history.history['loss'])} épocas\")\n",
    "print(f\"Val Accuracy final: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Val Precision final: {history.history['val_precision'][-1]:.4f}\")\n",
    "print(f\"Val Recall final: {history.history['val_recall'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de las Curvas de Aprendizaje\n",
    "\n",
    "Estos gráficos son fundamentales para diagnosticar el comportamiento del modelo durante\n",
    "el entrenamiento y detectar problemas antes de hacer predicciones:\n",
    "\n",
    "**Gráfico de Pérdida (Loss):**\n",
    "- **Esperado**: Ambas curvas (train y val) descienden y convergen\n",
    "- **Overfitting**: Pérdida de entrenamiento muy baja, pérdida de validación alta o creciente\n",
    "- **Underfitting**: Ambas curvas se estancan en valores altos\n",
    "\n",
    "**Gráfico de Precisión (Accuracy):**\n",
    "- **Esperado**: Ambas curvas crecen y se estabilizan en valores altos (>90%)\n",
    "- **Overfitting**: Precisión de entrenamiento muy alta (>99%), validación estancada o bajando\n",
    "- **Underfitting**: Ambas precisiones bajas (<70%)\n",
    "\n",
    "**Interpretación saludable para Transfer Learning:**\n",
    "- Las curvas deben estar muy cercanas (diferencia <2-3%)\n",
    "- La validación puede incluso ser ligeramente superior al entrenamiento (indica buena generalización)\n",
    "- Si la validación es muy inferior, necesito más regularización (dropout, augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "logs = pd.DataFrame(history.history)\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "# Gráfico de pérdida\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(logs.loc[1:, \"loss\"], lw=2, label='Pérdida en entrenamiento')\n",
    "plt.plot(logs.loc[1:, \"val_loss\"], lw=2, label='Pérdida en validación')\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Pérdida\")\n",
    "plt.title(\"Evolución de la Pérdida\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico de precisión\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(logs.loc[1:, \"accuracy\"], lw=2, label='Precisión en entrenamiento')\n",
    "plt.plot(logs.loc[1:, \"val_accuracy\"], lw=2, label='Precisión en validación')\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.title(\"Evolución de la Precisión\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTADOS FINALES:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Precisión final en entrenamiento: {logs['accuracy'].iloc[-1]:.4f}\")\n",
    "print(f\"Precisión final en validación: {logs['val_accuracy'].iloc[-1]:.4f}\")\n",
    "print(f\"Pérdida final en entrenamiento: {logs['loss'].iloc[-1]:.4f}\")\n",
    "print(f\"Pérdida final en validación: {logs['val_loss'].iloc[-1]:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardado del Modelo\n",
    "\n",
    "Guardo el modelo entrenado para poder reutilizarlo más tarde sin tener que volver a entrenarlo.\n",
    "Keras guarda toda la arquitectura, los pesos aprendidos y la configuración de compilación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save(\"model.keras\")\n",
    "print(\"Modelo guardado como 'model.keras'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación con Datos Suplementarios\n",
    "\n",
    "Los **datos suplementarios** son un conjunto adicional proporcionado por la competición\n",
    "para estimar el rendimiento del modelo en datos completamente nuevos, simulando el\n",
    "conjunto de test real.\n",
    "\n",
    "**¿Por qué es importante?**\n",
    "- El conjunto de validación (20% del training) puede no ser totalmente representativo\n",
    "- Los datos suplementarios me dan una estimación más realista del score en Kaggle\n",
    "- Si el modelo funciona bien aquí, probablemente funcionará bien en el leaderboard\n",
    "\n",
    "**Comparación con iteraciones anteriores:**\n",
    "Esta métrica es la que uso para decidir si una modificación (como el fine-tuning)\n",
    "realmente mejora el modelo o solo memoriza mejor el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "supplementary_ds = keras.utils.image_dataset_from_directory(\n",
    "    SUPP_PATH,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",  # Binary consistente\n",
    ")\n",
    "\n",
    "print(\"Evaluando con datos suplementarios...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "results = model.evaluate(supplementary_ds, return_dict=True, verbose=1)\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"\\nRESULTADOS EN DATOS SUPLEMENTARIOS:\")\n",
    "print(f\"Precisión: {results['accuracy']:.4f}\")\n",
    "print(f\"Pérdida: {results['loss']:.4f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ITERACIÓN 6 - Fine-tuning VGG16\n",
    "\n",
    "**Situación actual**: Iteración 5 con Transfer Learning consiguió 0.86380 (posición #7).\n",
    "\n",
    "**Estrategia de mejora**:\n",
    "- Descongelar las últimas 4 capas convolucionales de VGG16 (block5)\n",
    "- Learning rate MUY bajo (1e-5) para no romper los pesos pre-entrenados\n",
    "- Entrenar 10 épocas adicionales con ajuste fino\n",
    "- Objetivo: +2-4% de score → 0.88-0.90\n",
    "\n",
    "**Riesgo**: Puede empeorar si sobreajustamos. Por eso usamos LR muy bajo y pocas épocas.\n",
    "\n",
    "**Referencias**:\n",
    "- CS231n Fine-tuning: http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture11.pdf (slides 35-40)\n",
    "- Keras Fine-tuning guide: https://keras.io/guides/transfer_learning/#fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifico la estructura de VGG16 para saber qué descongelar\n",
    "print(\"Estructura de capas de VGG16:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(f\"Capa {i:2d}: {layer.name:20s} - Entrenable: {layer.trainable}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"VGG16 tiene 5 bloques convolucionales (block1 a block5)\")\n",
    "print(\"Vamos a descongelar SOLO el block5 (últimas 4 capas: 15-18)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESCONGELO solo el último bloque (block5) de VGG16\n",
    "# Son las 4 últimas capas convolucionales (capas 15-18)\n",
    "\n",
    "base_model.trainable = True  # Primero habilito el entrenamiento\n",
    "\n",
    "# Ahora congelo TODO excepto block5\n",
    "for layer in base_model.layers[:-4]:  # Todas menos las últimas 4\n",
    "    layer.trainable = False\n",
    "\n",
    "# Verifico qué quedó descongelado\n",
    "print(\"Estado después de descongelar block5:\")\n",
    "print(\"=\" * 70)\n",
    "trainable_count = 0\n",
    "frozen_count = 0\n",
    "\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    status = \"✓ ENTRENABLE\" if layer.trainable else \"  (congelada)\"\n",
    "    print(f\"Capa {i:2d}: {layer.name:20s} {status}\")\n",
    "    if layer.trainable:\n",
    "        trainable_count += 1\n",
    "    else:\n",
    "        frozen_count += 1\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"Capas congeladas: {frozen_count}\")\n",
    "print(f\"Capas entrenables: {trainable_count}\")\n",
    "print(f\"Total parámetros: {model.count_params():,}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recompilación con Learning Rate MUY bajo para Fine-tuning\n",
    "\n",
    "Ahora que he descongelado las últimas 4 capas convolucionales de VGG16, necesito\n",
    "recompilar el modelo con un **learning rate mucho más bajo** que en el Transfer Learning.\n",
    "\n",
    "**¿Por qué un learning rate tan bajo?**\n",
    "Los pesos de VGG16 fueron entrenados con 14 millones de imágenes de ImageNet y son\n",
    "extremadamente valiosos. Si uso un learning rate normal (1e-4), podría destruir estos\n",
    "pesos pre-entrenados que ya funcionan muy bien.\n",
    "\n",
    "**Comparación de learning rates:**\n",
    "- **Transfer Learning (cabecera)**: 1e-4 (0.0001) → Ajuste rápido de capas random\n",
    "- **Fine-tuning (block5)**: 1e-5 (0.00001) → Ajuste suave de capas pre-entrenadas (10x más bajo)\n",
    "\n",
    "Este learning rate extremadamente bajo hace que las actualizaciones sean microscópicas,\n",
    "permitiendo que el modelo se especialice en perros vs gatos sin olvidar los patrones\n",
    "generales aprendidos de ImageNet.\n",
    "\n",
    "**Callbacks ajustados:**\n",
    "- **ReduceLROnPlateau**: Si se estanca 2 épocas, reduce LR a la mitad (más agresivo que antes)\n",
    "- **EarlyStopping**: Si no mejora en 4 épocas, para el entrenamiento y restaura los mejores pesos\n",
    "  (evita sobreajustar las capas convolucionales)\n",
    "\n",
    "**Épocas: 10 máximo**\n",
    "Pocas épocas son suficientes para ajuste fino. Más épocas podrían hacer que el modelo\n",
    "olvide los features generales de ImageNet y se sobreajuste solo a nuestros gatos/perros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Recompilo con learning rate MUY bajo para fine-tuning\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),  # 10x más bajo que antes\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "print(\"Modelo recompilado para fine-tuning\")\n",
    "print(f\"Learning rate: 1e-5 (0.00001)\")\n",
    "print(f\"Optimizador: Adam\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Pocas épocas para no sobreajustar\n",
    "epochs_finetuning = 10\n",
    "\n",
    "# Callback para reducir LR si se estanca\n",
    "reduce_lr_ft = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Early stopping conservador para evitar sobreajuste\n",
    "early_stop_ft = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=4,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Comenzando fine-tuning...\")\n",
    "print(f\"Épocas máximas: {epochs_finetuning}\")\n",
    "print(f\"Early stopping: patience=4 épocas\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "history_finetuning = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs_finetuning,\n",
    "    callbacks=[reduce_lr_ft, early_stop_ft],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"Fine-tuning completado en {len(history_finetuning.history['loss'])} épocas\")\n",
    "print(f\"Val Accuracy final: {history_finetuning.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Val Precision final: {history_finetuning.history['val_precision'][-1]:.4f}\")\n",
    "print(f\"Val Recall final: {history_finetuning.history['val_recall'][-1]:.4f}\")\n",
    "print(f\"Val Loss final: {history_finetuning.history['val_loss'][-1]:.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización del Fine-tuning\n",
    "\n",
    "Estos gráficos muestran cómo evolucionó el modelo durante las épocas adicionales de\n",
    "fine-tuning, después del entrenamiento inicial de Transfer Learning.\n",
    "\n",
    "**Lo que busco en estos gráficos:**\n",
    "\n",
    "1. **Mejora gradual**: Las métricas de validación deben mejorar o mantenerse estables,\n",
    "   no empeorar. Si empeoran, significa que el fine-tuning está destruyendo los pesos\n",
    "   pre-entrenados (sobreajuste catastrófico).\n",
    "\n",
    "2. **Convergencia suave**: Las curvas deben ser relativamente estables, sin oscilaciones\n",
    "   bruscas. El learning rate muy bajo (1e-5) garantiza esta suavidad.\n",
    "\n",
    "3. **No degradación**: La pérdida de validación no debe aumentar significativamente.\n",
    "   Un aumento indicaría que estoy sobreajustando las capas convolucionales.\n",
    "\n",
    "**Señales de éxito del fine-tuning:**\n",
    "- Val accuracy mejora respecto al Transfer Learning base\n",
    "- Val loss se mantiene bajo o disminuye\n",
    "- Train y val se mantienen cercanos (buena generalización)\n",
    "\n",
    "**Señales de fracaso (sobreajuste):**\n",
    "- Val accuracy baja o se estanca\n",
    "- Val loss aumenta mientras train loss baja\n",
    "- Gran separación entre curvas de train y val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_ft = pd.DataFrame(history_finetuning.history)\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "# Gráfico de pérdida\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(logs_ft[\"loss\"], lw=2, label='Pérdida en entrenamiento', marker='o')\n",
    "plt.plot(logs_ft[\"val_loss\"], lw=2, label='Pérdida en validación', marker='o')\n",
    "plt.xlabel(\"Época (Fine-tuning)\")\n",
    "plt.ylabel(\"Pérdida\")\n",
    "plt.title(\"Evolución de la Pérdida - Fine-tuning\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico de precisión\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(logs_ft[\"accuracy\"], lw=2, label='Precisión en entrenamiento', marker='o')\n",
    "plt.plot(logs_ft[\"val_accuracy\"], lw=2, label='Precisión en validación', marker='o')\n",
    "plt.xlabel(\"Época (Fine-tuning)\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.title(\"Evolución de la Precisión - Fine-tuning\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTADOS FINE-TUNING:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Precisión final en entrenamiento: {logs_ft['accuracy'].iloc[-1]:.4f}\")\n",
    "print(f\"Precisión final en validación: {logs_ft['val_accuracy'].iloc[-1]:.4f}\")\n",
    "print(f\"Pérdida final en entrenamiento: {logs_ft['loss'].iloc[-1]:.4f}\")\n",
    "print(f\"Pérdida final en validación: {logs_ft['val_loss'].iloc[-1]:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación Final con Datos Suplementarios\n",
    "\n",
    "Esta es la **métrica decisiva** para saber si el fine-tuning realmente mejoró el modelo\n",
    "o si solo memorizó mejor el conjunto de validación.\n",
    "\n",
    "**Comparación clave:**\n",
    "- **Antes (Transfer Learning)**: Accuracy en supplementary = 72.33%\n",
    "- **Después (Fine-tuning)**: Accuracy en supplementary = ?\n",
    "\n",
    "**Interpretación de resultados:**\n",
    "\n",
    "**Si mejora (+2% o más)**: El fine-tuning fue exitoso. Las capas convolucionales\n",
    "  se especializaron en características de perros/gatos sin perder generalización.\n",
    "  → ENVIAR submission.csv a Kaggle\n",
    "\n",
    "**Si se mantiene (±1%)**: El fine-tuning no aportó mejora significativa, pero tampoco\n",
    "  empeoró. El modelo base era suficientemente bueno.\n",
    "  → Opcional enviarlo, probablemente score similar\n",
    "\n",
    "**Si empeora (-2% o más)**: El fine-tuning sobreajustó el modelo. Destruyó features\n",
    "  generales aprendidos de ImageNet.\n",
    "  → NO enviar, mantener el modelo de Transfer Learning base\n",
    "\n",
    "Esta evaluación en supplementary data simula cómo se comportará el modelo en el\n",
    "leaderboard público de Kaggle, ya que son datos completamente nuevos que el modelo\n",
    "nunca vio durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluando modelo con fine-tuning en datos suplementarios...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results_ft = model.evaluate(supplementary_ds, return_dict=True, verbose=1)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nRESULTADOS DESPUES DE FINE-TUNING:\")\n",
    "print(f\"Precisión: {results_ft['accuracy']:.4f}\")\n",
    "print(f\"Precision: {results_ft['precision']:.4f}\")\n",
    "print(f\"Recall: {results_ft['recall']:.4f}\")\n",
    "print(f\"Pérdida: {results_ft['loss']:.4f}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Comparación con Iteración 5 (antes del fine-tuning)\n",
    "print(\"\\nCOMPARACION CON ITERACION 5 (Transfer Learning sin fine-tuning):\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Iter 5 - Supplementary Acc: {results['accuracy']:.4f}\")\n",
    "print(f\"Iter 6 - Supplementary Acc: {results_ft['accuracy']:.4f}\")\n",
    "diff = results_ft['accuracy'] - results['accuracy']\n",
    "print(f\"Diferencia: {diff:+.4f} ({diff*100:+.2f}%)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if diff > 0:\n",
    "    print(\"EXITO: Fine-tuning mejoró la generalización\")\n",
    "else:\n",
    "    print(\"ALERTA: Fine-tuning no mejoró (posible sobreajuste)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardado del Modelo Fine-tuned\n",
    "\n",
    "Guardo el modelo completo con fine-tuning para tener dos versiones disponibles:\n",
    "\n",
    "1. **model.keras**: Modelo base de Transfer Learning (todas las capas VGG16 congeladas)\n",
    "2. **model_finetuned.keras**: Modelo mejorado con fine-tuning (block5 especializado)\n",
    "\n",
    "Esto me permite comparar ambos modelos y elegir el mejor para la submission final.\n",
    "Keras guarda toda la arquitectura, los pesos entrenados y la configuración de compilación,\n",
    "por lo que puedo cargar este modelo más tarde sin tener que volver a entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_finetuned.keras\")\n",
    "print(\"Modelo con fine-tuning guardado como 'model_finetuned.keras'\")\n",
    "print(\"(El modelo anterior sin fine-tuning sigue en 'model.keras')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de Predicciones para Kaggle\n",
    "\n",
    "Ahora genero las predicciones finales con el modelo optimizado mediante fine-tuning.\n",
    "\n",
    "**¿Por qué usar el modelo fine-tuned?**\n",
    "El fine-tuning permitió que las últimas capas convolucionales de VGG16 se especializaran\n",
    "en distinguir características específicas de perros y gatos, mejorando la precisión en\n",
    "datos nuevos (supplementary accuracy subió de 72.33% a 74.67%, un +2.33%).\n",
    "\n",
    "Este proceso predice cada imagen del conjunto de test y genera el archivo `submission.csv`\n",
    "que se enviará a Kaggle con el formato requerido (id, label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictions_dict = {}\n",
    "\n",
    "print(f\"Generando predicciones para {len(os.listdir(TEST_PATH))} imágenes del conjunto de test...\")\n",
    "print(\"Usando umbral 0.5 para clasificación binaria (probabilidad >= 0.5 → Dog, < 0.5 → Cat)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Itero sobre todas las imágenes del directorio de test\n",
    "for img in os.listdir(TEST_PATH):\n",
    "    img_path = os.path.join(TEST_PATH, img)\n",
    "    file_name = img_path.split('/')[-1]\n",
    "    file_no_extension = file_name.split('.')[0]  # ID numérico de la imagen\n",
    "    \n",
    "    # Cargo la imagen y la preparo para el modelo\n",
    "    img_loaded = keras.utils.load_img(img_path, target_size=image_size)\n",
    "    img_array = keras.utils.img_to_array(img_loaded)\n",
    "    img_array = keras.ops.expand_dims(img_array, 0)  # Añado dimensión de batch\n",
    "    \n",
    "    # Predigo probabilidad con el modelo fine-tuned\n",
    "    # Salida sigmoid: valor entre 0 (Cat) y 1 (Dog)\n",
    "    prediction = model.predict(img_array, verbose=0)[0][0]\n",
    "    \n",
    "    # Conversión explícita a clase binaria\n",
    "    label = 1 if prediction >= 0.5 else 0\n",
    "    \n",
    "    predictions_dict[int(file_no_extension)] = label\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"Predicciones completadas: {len(predictions_dict)} imágenes procesadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del Archivo de Submission para Kaggle\n",
    "\n",
    "Genero el archivo CSV final con el formato exacto que requiere Kaggle:\n",
    "- Columna `id`: número identificador de cada imagen\n",
    "- Columna `label`: predicción (0 = Cat, 1 = Dog)\n",
    "\n",
    "Además, verifico que la distribución de clases sea razonable (aproximadamente 50/50)\n",
    "para asegurarme de que el modelo no está sesgado hacia una sola clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el DataFrame con las predicciones y lo ordeno por ID\n",
    "submission = pd.DataFrame(predictions_dict.items(), columns=[\"id\", \"label\"])\n",
    "submission = submission.sort_values(by='id', ascending=True)\n",
    "\n",
    "# Guardo el archivo CSV para Kaggle\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ARCHIVO DE SUBMISSION CREADO: submission.csv\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Estadísticas de las predicciones\n",
    "print(\"\\nDISTRIBUCION DE PREDICCIONES:\")\n",
    "print(\"-\" * 70)\n",
    "print(submission[\"label\"].value_counts())\n",
    "print()\n",
    "print(f\"Clase 0 (Cat): {(submission['label'] == 0).sum():4d} imágenes ({100*(submission['label'] == 0).sum()/len(submission):5.1f}%)\")\n",
    "print(f\"Clase 1 (Dog): {(submission['label'] == 1).sum():4d} imágenes ({100*(submission['label'] == 1).sum()/len(submission):5.1f}%)\")\n",
    "print(f\"Total:         {len(submission):4d} imágenes\")\n",
    "\n",
    "# Muestro ejemplos de predicciones\n",
    "print(\"\\nPRIMERAS 10 PREDICCIONES:\")\n",
    "print(submission.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nULTIMAS 10 PREDICCIONES:\")\n",
    "print(submission.tail(10).to_string(index=False))\n",
    "\n",
    "# VERIFICACIÓN CRÍTICA: detectar si todas las predicciones son de una sola clase\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if (submission['label'] == 0).sum() == len(submission) or (submission['label'] == 1).sum() == len(submission):\n",
    "    print(\"ALERTA: TODAS LAS PREDICCIONES SON DE UNA SOLA CLASE\")\n",
    "    print(\"El modelo está completamente sesgado. NO enviar a Kaggle.\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"VERIFICACION EXITOSA\")\n",
    "    print(\"  - Distribucion de clases balanceada\")\n",
    "    print(\"  - Archivo listo para enviar a Kaggle\")\n",
    "    print(\"  - Mejora esperada respecto a Iter 5: +2-4% (0.88-0.90)\")\n",
    "    print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9809442,
     "sourceId": 86515,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
