{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee3d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================================================#\n",
    "#                                                                                                    #\n",
    "#                                                        ██╗   ██╗   ████████╗ █████╗ ██████╗        #\n",
    "#      Competición - INAR                                ██║   ██║   ╚══██╔══╝██╔══██╗██╔══██╗       #\n",
    "#                                                        ██║   ██║█████╗██║   ███████║██║  ██║       #\n",
    "#      created:        07/11/2025  -  05:00:00           ██║   ██║╚════╝██║   ██╔══██║██║  ██║       #\n",
    "#      last change:    10/11/2025  -  11:34:43           ╚██████╔╝      ██║   ██║  ██║██████╔╝       #\n",
    "#                                                         ╚═════╝       ╚═╝   ╚═╝  ╚═╝╚═════╝        #\n",
    "#                                                                                                    #\n",
    "#      Ismael Hernandez Clemente                         ismael.hernandez@live.u-tad.com             #\n",
    "#                                                                                                    #\n",
    "#      Github:                                           https://github.com/ismaelucky342            #\n",
    "#                                                                                                    #\n",
    "#====================================================================================================# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4be98b",
   "metadata": {},
   "source": [
    "# Competición Perretes y Gatos\n",
    "\n",
    "## Iteración 8 - EfficientNetB7 Optimizado\n",
    "\n",
    "Entrenamiento reducido un 50% de 4 a 2 horas, pero el score ha sido exactamente el mismo.\n",
    "\n",
    "**kaggle score**: 0.94962, llegados a este punto lo mejor es bajar a B3 y optimizarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf74799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from tensorflow import data as tf_data\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.applications import EfficientNetB7 \n",
    "\n",
    "seed = 42\n",
    "keras.utils.set_random_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Rutas dataset\n",
    "DATASET_NAME = \"u-tad-dogs-vs-cats-2025\"\n",
    "TRAIN_PATH = f\"/kaggle/input/{DATASET_NAME}/train/train\"\n",
    "TEST_PATH = f\"/kaggle/input/{DATASET_NAME}/test/test\"\n",
    "SUPP_PATH = f\"/kaggle/input/{DATASET_NAME}/supplementary_data/supplementary_data\"\n",
    "\n",
    "print(\"Keras:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3018cee3",
   "metadata": {},
   "source": [
    "## Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46884011",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "N_FINE_TUNE_LAYERS = 20\n",
    "EPOCHS_TL = 12\n",
    "EPOCHS_FT = 8\n",
    "DROPOUT_RATE = 0.5\n",
    "LABEL_SMOOTHING = 0.1\n",
    "MIXUP_ALPHA = 0.2     \n",
    "\n",
    "print(f\"Modelo: EfficientNetB7 OPTIMIZED + ADVANCED\")\n",
    "print(f\"Resolución: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Dropout: {DROPOUT_RATE}\")\n",
    "print(f\"Label Smoothing: {LABEL_SMOOTHING}\")\n",
    "print(f\"Mixup Alpha: {MIXUP_ALPHA}\")\n",
    "print(f\"Fine-tune layers: {N_FINE_TUNE_LAYERS}\")\n",
    "print(f\"Épocas TL: {EPOCHS_TL}\")\n",
    "print(f\"Épocas FT: {EPOCHS_FT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31569acc",
   "metadata": {},
   "source": [
    "## Carga de Datos\n",
    "\n",
    "Todo igual q antes, pero con batch_size=16 para que q entre B7 en memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9353c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    color_mode='rgb',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    shuffle=True,\n",
    "    seed=seed,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    interpolation='bilinear',\n",
    ")\n",
    "\n",
    "validation_dataset = keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    color_mode='rgb',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    shuffle=True,\n",
    "    seed=seed,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    interpolation='bilinear',\n",
    ")\n",
    "\n",
    "test_dataset = keras.utils.image_dataset_from_directory(\n",
    "    TEST_PATH,\n",
    "    labels=None,\n",
    "    label_mode=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    shuffle=False,\n",
    "    seed=seed,\n",
    "    interpolation='bilinear',\n",
    ")\n",
    "\n",
    "supplementary_dataset = keras.utils.image_dataset_from_directory(\n",
    "    SUPP_PATH,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    color_mode='rgb',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    shuffle=False,\n",
    "    seed=seed,\n",
    "    interpolation='bilinear',\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_dataset)}\")\n",
    "print(f\"Validation batches: {len(validation_dataset)}\")\n",
    "print(f\"Test batches: {len(test_dataset)}\")\n",
    "print(f\"Supplementary batches: {len(supplementary_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db278a00",
   "metadata": {},
   "source": [
    "## Mixup Augmentation\n",
    "\n",
    "Técnica avanzada que mezcla imágenes y labels para mejor generalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b92ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_batch(images, labels, alpha=0.2):\n",
    "    \"\"\"Mixup: mezcla pares de imágenes dentro del mismo batch\"\"\"\n",
    "    batch_size = images.shape[0]\n",
    "    \n",
    "    # Sample lambda from Beta distribution\n",
    "    lam = np.random.beta(alpha, alpha, batch_size)\n",
    "    lam = np.maximum(lam, 1 - lam)  # Ensure lam >= 0.5\n",
    "    lam = lam.reshape(batch_size, 1, 1, 1)\n",
    "    \n",
    "    # Shuffle indices\n",
    "    indices = np.random.permutation(batch_size)\n",
    "    \n",
    "    # Mix images and labels\n",
    "    mixed_images = lam * images + (1 - lam) * images[indices]\n",
    "    mixed_labels = lam.squeeze() * labels + (1 - lam.squeeze()) * labels[indices]\n",
    "    \n",
    "    return mixed_images, mixed_labels\n",
    "\n",
    "print(\"Mixup function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660b3f64",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Mismo q antes \n",
    "- Flip horizontal + vertical\n",
    "- Rotation ±20%\n",
    "- Zoom ±20%\n",
    "- Translation ±15%\n",
    "- Contrast ±20%\n",
    "- Brightness ±20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39017ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation SOLO para training\n",
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    keras.layers.RandomRotation(0.15),\n",
    "    keras.layers.RandomZoom(0.15),\n",
    "    keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "    keras.layers.RandomContrast(0.15),\n",
    "    keras.layers.RandomBrightness(0.15),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "# CRÍTICO: Augmentation SOLO en train, NO en validation\n",
    "train_dataset_augmented = train_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "\n",
    "# Aplicar Mixup con probabilidad 0.3 (no siempre, para no perder diversidad)\n",
    "def apply_mixup_random(images, labels):\n",
    "    if np.random.random() < 0.3:\n",
    "        return mixup_batch(images, labels, MIXUP_ALPHA)\n",
    "    return images, labels\n",
    "\n",
    "train_dataset_augmented = train_dataset_augmented.map(\n",
    "    lambda x, y: apply_mixup_random(x, y),\n",
    "    num_parallel_calls=tf_data.AUTOTUNE\n",
    ")\n",
    "\n",
    "print(\"Augmentation + Mixup aplicado SOLO a training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb11abd",
   "metadata": {},
   "source": [
    "## EfficientNetB7 - Construcción\n",
    "\n",
    "**EfficientNetB7 stats:**\n",
    "- 66M parámetros (B3 tiene 12M)\n",
    "- Top-1 Accuracy ImageNet: **84.3%** (B3: 81.6%)\n",
    "- Resolución nativa: 600x600 (aguanta perfectamente 384x384)\n",
    "- MÁS LENTO pero MÁS PRECISO\n",
    "\n",
    "Arquitectura:\n",
    "- EfficientNetB7 base (congelado)\n",
    "- BatchNormalization\n",
    "- Dense(512) + Dropout(0.6)\n",
    "- BatchNormalization\n",
    "- Dense(256) + Dropout(0.6)\n",
    "- Dense(1, sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f44d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo EfficientNetB7 pre-entrenado\n",
    "efficientnet_base = EfficientNetB7(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "# Congelo todo inicialmente\n",
    "for layer in efficientnet_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Construyo modelo con B7\n",
    "efficientnet_model = Sequential([\n",
    "    efficientnet_base,\n",
    "    keras.layers.BatchNormalization(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(DROPOUT_RATE),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(DROPOUT_RATE),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilar con AdamW y Label Smoothing\n",
    "efficientnet_model.compile(\n",
    "    optimizer=keras.optimizers.AdamW(\n",
    "        learning_rate=1e-3,\n",
    "        weight_decay=1e-4  # Regularización adicional\n",
    "    ),\n",
    "    loss=keras.losses.BinaryCrossentropy(\n",
    "        label_smoothing=LABEL_SMOOTHING  # 0.1: Evita overconfidence\n",
    "    ),\n",
    "    metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "efficientnet_model.summary()\n",
    "print(f\"EfficientNetB7 layers: {len(efficientnet_base.layers)}\")\n",
    "print(f\"Trainable layers: {sum([layer.trainable for layer in efficientnet_base.layers])}/{len(efficientnet_base.layers)}\")\n",
    "print(f\"Total parameters: {efficientnet_model.count_params():,}\")\n",
    "print(f\"Optimizer: AdamW (weight_decay={1e-4})\")\n",
    "print(f\"Loss: BinaryCrossentropy (label_smoothing={LABEL_SMOOTHING})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fb736c",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "\n",
    "Entreno solo las capas Dense q añadí, con EfficientNetB7 congelado.\n",
    "\n",
    "**15 épocas** con early stopping (patience=5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7360cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning con EfficientNetB7\n",
    "print(\"Starting Transfer Learning...\")\n",
    "\n",
    "efficientnet_history_tl = efficientnet_model.fit(\n",
    "    train_dataset_augmented,\n",
    "    epochs=EPOCHS_TL,\n",
    "    validation_data=validation_dataset,  # SIN augmentation\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=4,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=2,\n",
    "            min_lr=1e-7\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            'best_model_tl.keras',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max'\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Transfer Learning completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96e0e53",
   "metadata": {},
   "source": [
    "## Visualización TL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9ed645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficos Transfer Learning (robustos a nombres de métricas)\n",
    "try:\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(efficientnet_history_tl.history.get('loss', []), label='Train')\n",
    "    plt.plot(efficientnet_history_tl.history.get('val_loss', []), label='Validation')\n",
    "    plt.title('Loss - Transfer Learning B7')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(efficientnet_history_tl.history.get('accuracy', []), label='Train')\n",
    "    plt.plot(efficientnet_history_tl.history.get('val_accuracy', []), label='Validation')\n",
    "    plt.title('Accuracy - Transfer Learning B7')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Detect keys for precision/recall (Keras names may vary)\n",
    "    precision_key = next((k for k in ['precision_1', 'precision'] if k in efficientnet_history_tl.history), None)\n",
    "    recall_key = next((k for k in ['recall_1', 'recall'] if k in efficientnet_history_tl.history), None)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    if precision_key and recall_key:\n",
    "        plt.plot(efficientnet_history_tl.history[precision_key], label='Precision')\n",
    "        plt.plot(efficientnet_history_tl.history[recall_key], label='Recall')\n",
    "    else:\n",
    "        plt.plot([], [], label='Precision (n/a)')\n",
    "        plt.plot([], [], label='Recall (n/a)')\n",
    "\n",
    "    plt.title('Precision & Recall - Transfer Learning B7')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Plotting failed ({e}). Continuing...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60241282",
   "metadata": {},
   "source": [
    "## Evaluación Supplementary (post-TL)\n",
    "\n",
    "Veo cómo va ANTES del fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ffb37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating on supplementary dataset (post-TL)...\")\n",
    "\n",
    "efficientnet_supp_results_tl = efficientnet_model.evaluate(supplementary_dataset, verbose=1)\n",
    "efficientnet_supp_accuracy_tl = efficientnet_supp_results_tl[1]\n",
    "\n",
    "print(f\"Supplementary Accuracy (TL): {efficientnet_supp_accuracy_tl:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2a43b7",
   "metadata": {},
   "source": [
    "## Fine-tuning - DESCONGELAR 20 CAPAS\n",
    "\n",
    "Ahora descongelo las **últimas 20 capas** de B7 (optimizado).\n",
    "\n",
    "LR MUY bajo (5e-6) para que no romper lo pre-entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67319151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descongelo últimas capas de B7\n",
    "print(f\"Unfreezing last {N_FINE_TUNE_LAYERS} layers...\")\n",
    "\n",
    "for layer in efficientnet_base.layers[-N_FINE_TUNE_LAYERS:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompilo con AdamW y LR MUY bajo\n",
    "efficientnet_model.compile(\n",
    "    optimizer=keras.optimizers.AdamW(\n",
    "        learning_rate=5e-6,\n",
    "        weight_decay=5e-5  # Menor weight decay en fine-tuning\n",
    "    ),\n",
    "    loss=keras.losses.BinaryCrossentropy(\n",
    "        label_smoothing=LABEL_SMOOTHING\n",
    "    ),\n",
    "    metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "trainable_count = sum([layer.trainable for layer in efficientnet_base.layers])\n",
    "print(f\"Trainable layers: {trainable_count}/{len(efficientnet_base.layers)}\")\n",
    "print(f\"Optimizer: AdamW (lr=5e-6, weight_decay=5e-5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4252f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning con B7\n",
    "print(\"Starting Fine-tuning...\")\n",
    "\n",
    "efficientnet_history_ft = efficientnet_model.fit(\n",
    "    train_dataset_augmented,\n",
    "    epochs=EPOCHS_FT,\n",
    "    validation_data=validation_dataset,  # SIN augmentation\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=2,\n",
    "            min_lr=1e-8\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            'best_model_ft.keras',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max'\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dc30c7",
   "metadata": {},
   "source": [
    "## Visualización Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f0e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(efficientnet_history_ft.history.get('loss', []), label='Train')\n",
    "    plt.plot(efficientnet_history_ft.history.get('val_loss', []), label='Validation')\n",
    "    plt.title('Loss - Fine-tuning B7')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(efficientnet_history_ft.history.get('accuracy', []), label='Train')\n",
    "    plt.plot(efficientnet_history_ft.history.get('val_accuracy', []), label='Validation')\n",
    "    plt.title('Accuracy - Fine-tuning B7')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Detect keys for precision/recall (Keras names may vary)\n",
    "    precision_key_ft = next((k for k in ['precision_1', 'precision'] if k in efficientnet_history_ft.history), None)\n",
    "    recall_key_ft = next((k for k in ['recall_1', 'recall'] if k in efficientnet_history_ft.history), None)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    if precision_key_ft and recall_key_ft:\n",
    "        plt.plot(efficientnet_history_ft.history[precision_key_ft], label='Precision')\n",
    "        plt.plot(efficientnet_history_ft.history[recall_key_ft], label='Recall')\n",
    "    else:\n",
    "        plt.plot([], [], label='Precision (n/a)')\n",
    "        plt.plot([], [], label='Recall (n/a)')\n",
    "\n",
    "    plt.title('Precision & Recall - Fine-tuning B7')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Plotting failed ({e}). Continuing...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76da909",
   "metadata": {},
   "source": [
    "## Predicciones Finales (SIN TTA)\n",
    "\n",
    "TTA eliminado para acelerar y evitar ruido. El modelo B7 no lo necesita es muy grande"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75810c60",
   "metadata": {},
   "source": [
    "## Evaluación Final Supplementary (post-FT)\n",
    "\n",
    "Evaluación final en supplementary dataset SIN augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dbebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating on supplementary dataset (post-FT, NO augmentation)...\")\n",
    "\n",
    "efficientnet_supp_results_ft = efficientnet_model.evaluate(supplementary_dataset, verbose=1)\n",
    "efficientnet_supp_accuracy_ft = efficientnet_supp_results_ft[1]\n",
    "\n",
    "print(f\"Supplementary Accuracy (FT): {efficientnet_supp_accuracy_ft:.4f}\")\n",
    "print(f\"Expected Kaggle score: ~{efficientnet_supp_accuracy_ft + 0.01:.4f} - {efficientnet_supp_accuracy_ft + 0.03:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce5a08d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d85e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model: EfficientNetB7\")\n",
    "print(f\"Resolution: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(\"Generating predictions (NO TTA for speed)...\")\n",
    "\n",
    "predictions = efficientnet_model.predict(test_dataset, verbose=1)\n",
    "\n",
    "print(f\"Total predictions: {len(predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6859934d",
   "metadata": {},
   "source": [
    "## Generación Submission Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7d3b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero submission.csv\n",
    "test_filenames = test_dataset.file_paths\n",
    "ids = [int(os.path.splitext(os.path.basename(f))[0]) for f in test_filenames]\n",
    "\n",
    "predictions_binary = (predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'label': predictions_binary\n",
    "})\n",
    "\n",
    "submission_df = submission_df.sort_values('id')\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"Submission saved to submission.csv\")\n",
    "print(submission_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
