{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "037b4396",
   "metadata": {},
   "source": [
    "# Iteración 4 - BugFix Binary Classification\n",
    "\n",
    "Aquí arreglo el bug cambiando de categorical a binary. Ahora sí funciona bien el Transfer Learning con VGG16.\n",
    "\n",
    "**Arquitectura**: VGG16 (congelado) + Dense(256) + Dropout(0.5) + Dense(1, sigmoid)\n",
    "\n",
    "**Kaggle Score**: ~0.75-0.78 (mejora considerable al arreglar el bug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51c011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports básicos\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import data as tf_data\n",
    "import keras\n",
    "\n",
    "seed = 42\n",
    "keras.utils.set_random_seed(seed)\n",
    "\n",
    "DATASET_NAME = \"u-tad-dogs-vs-cats-2025\"\n",
    "TRAIN_PATH = f\"/kaggle/input/{DATASET_NAME}/train/train\"\n",
    "TEST_PATH = f\"/kaggle/input/{DATASET_NAME}/test/test\"\n",
    "SUPP_PATH = f\"/kaggle/input/{DATASET_NAME}/supplementary_data/supplementary_data\"\n",
    "\n",
    "print(\"Versión de Keras:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1451e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora sí cargo en modo binary (BUG ARREGLADO)\n",
    "image_size = (224, 224)\n",
    "batch_size = 125\n",
    "\n",
    "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=seed,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",  # ARREGLADO: ahora binary\n",
    ")\n",
    "\n",
    "print(f\"Training batches: {len(train_ds)}\")\n",
    "print(f\"Validation batches: {len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a504c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation igual que antes\n",
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.RandomFlip(\"horizontal\"),\n",
    "    keras.layers.RandomRotation(0.1),\n",
    "    keras.layers.RandomZoom(0.1),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "print(\"Data Augmentation configurado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ffb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 igual pero ahora con salida sigmoid(1) para binary\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.applications import VGG16\n",
    "\n",
    "input_shape = image_size + (3,)\n",
    "\n",
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=input_shape,\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "# Ahora con Dense(1, sigmoid) para binary classification\n",
    "model = Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    data_augmentation,\n",
    "    base_model,\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # ARREGLADO: sigmoid para binary\n",
    "], name='VGG16_Transfer_Learning_Binary')\n",
    "\n",
    "print(f\"Capas VGG16 congeladas: {len(base_model.layers)}\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b88a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilo con binary_crossentropy\n",
    "%%time\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',  # ARREGLADO: binary_crossentropy\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "epochs = 15\n",
    "\n",
    "print(f\"Épocas: {epochs}\")\n",
    "print(f\"Optimizer: Adam (lr=0.0001)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"Val Accuracy final: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Val Precision final: {history.history['val_precision'][-1]:.4f}\")\n",
    "print(f\"Val Recall final: {history.history['val_recall'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87602ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinto las curvas\n",
    "logs = pd.DataFrame(history.history)\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(logs.loc[1:, \"loss\"], lw=2, label='Pérdida en entrenamiento')\n",
    "plt.plot(logs.loc[1:, \"val_loss\"], lw=2, label='Pérdida en validación')\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Pérdida\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(logs.loc[1:, \"accuracy\"], lw=2, label='Precisión en entrenamiento')\n",
    "plt.plot(logs.loc[1:, \"val_accuracy\"], lw=2, label='Precisión en validación')\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPrecisión final en entrenamiento: {logs['accuracy'].iloc[-1]:.4f}\")\n",
    "print(f\"Precisión final en validación: {logs['val_accuracy'].iloc[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e571c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardo el modelo\n",
    "model.save(\"model.keras\")\n",
    "print(\"Modelo guardado como 'model.keras'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bd6be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalúo con supplementary en modo binary\n",
    "supplementary_ds = keras.utils.image_dataset_from_directory(\n",
    "    SUPP_PATH,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    ")\n",
    "\n",
    "print(\"Evaluando con datos suplementarios...\")\n",
    "results = model.evaluate(supplementary_ds, return_dict=True, verbose=1)\n",
    "\n",
    "print(f\"\\nSupplementary Accuracy: {results['accuracy']:.4f}\")\n",
    "print(f\"Supplementary Precision: {results['precision']:.4f}\")\n",
    "print(f\"Supplementary Recall: {results['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ccd7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero predicciones usando threshold 0.5 para sigmoid\n",
    "%%time\n",
    "\n",
    "predictions_dict = {}\n",
    "\n",
    "print(f\"Generando predicciones para {len(os.listdir(TEST_PATH))} imágenes...\")\n",
    "\n",
    "for img in os.listdir(TEST_PATH):\n",
    "    img_path = os.path.join(TEST_PATH, img)\n",
    "    file_name = img_path.split('/')[-1]\n",
    "    file_no_extension = file_name.split('.')[0]\n",
    "    \n",
    "    img_loaded = keras.utils.load_img(img_path, target_size=image_size)\n",
    "    img_array = keras.utils.img_to_array(img_loaded)\n",
    "    img_array = keras.ops.expand_dims(img_array, 0)\n",
    "    \n",
    "    prediction = model.predict(img_array, verbose=0)[0][0]\n",
    "    label = 1 if prediction >= 0.5 else 0  # Threshold explícito\n",
    "    \n",
    "    predictions_dict[int(file_no_extension)] = label\n",
    "\n",
    "print(f\"Predicciones completadas: {len(predictions_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd44747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo submission (ahora debería funcionar mucho mejor)\n",
    "submission = pd.DataFrame(predictions_dict.items(), columns=[\"id\", \"label\"])\n",
    "submission = submission.sort_values(by='id', ascending=True)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Archivo de submission creado\")\n",
    "print(\"\\nDistribución de predicciones:\")\n",
    "print(submission[\"label\"].value_counts())\n",
    "print(f\"\\nClase 0 (Cat): {(submission['label'] == 0).sum()} imágenes\")\n",
    "print(f\"Clase 1 (Dog): {(submission['label'] == 1).sum()} imágenes\")\n",
    "print(f\"\\nTotal: {len(submission)} imágenes\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
