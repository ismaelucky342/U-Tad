{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8be8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================================================#\n",
    "#                                                                                                    #\n",
    "#                                                        ██╗   ██╗   ████████╗ █████╗ ██████╗        #\n",
    "#      Competición - INAR                                ██║   ██║   ╚══██╔══╝██╔══██╗██╔══██╗       #\n",
    "#                                                        ██║   ██║█████╗██║   ███████║██║  ██║       #\n",
    "#      created:        29/10/2025  -  23:00:15           ██║   ██║╚════╝██║   ██╔══██║██║  ██║       #\n",
    "#      last change:    05/11/2025  -  02:55:40           ╚██████╔╝      ██║   ██║  ██║██████╔╝       #\n",
    "#                                                         ╚═════╝       ╚═╝   ╚═╝  ╚═╝╚═════╝        #\n",
    "#                                                                                                    #\n",
    "#      Ismael Hernandez Clemente                         ismael.hernandez@live.u-tad.com             #\n",
    "#                                                                                                    #\n",
    "#      Github:                                           https://github.com/ismaelucky342            #\n",
    "#                                                                                                    #\n",
    "#====================================================================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98f28bf",
   "metadata": {},
   "source": [
    "# Iteración 4 - Transfer Learning VGG16 \n",
    "\n",
    "Transfer Learning con VGG16 pre-entrenado en ImageNet y fix binario. Todas las capas convolucionales congeladas, solo entrenamos cabecera personalizada.\n",
    "\n",
    "**Arquitectura**: VGG16 (congelado) + Dense(256) + Dropout(0.5) + Dense(1, sigmoid)\n",
    "\n",
    "**Kaggle Score**: 0.86380 (Posición #7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117f115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports básicos y configuración de rutas\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import data as tf_data\n",
    "import keras\n",
    "\n",
    "seed = 42\n",
    "keras.utils.set_random_seed(seed)\n",
    "\n",
    "DATASET_NAME = \"u-tad-dogs-vs-cats-2025\"\n",
    "TRAIN_PATH = f\"/kaggle/input/{DATASET_NAME}/train/train\"\n",
    "TEST_PATH = f\"/kaggle/input/{DATASET_NAME}/test/test\"\n",
    "SUPP_PATH = f\"/kaggle/input/{DATASET_NAME}/supplementary_data/supplementary_data\"\n",
    "\n",
    "print(\"Versión de Keras:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec71f35",
   "metadata": {},
   "source": [
    "## Carga y Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22347d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo datos en modo binary con split 80/20 y tamaño VGG16\n",
    "image_size = (224, 224)  # VGG16 requiere 224x224\n",
    "batch_size = 125\n",
    "\n",
    "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=seed,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",  # Binary para 2 clases\n",
    ")\n",
    "\n",
    "print(f\"Training batches: {len(train_ds)}\")\n",
    "print(f\"Validation batches: {len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2705b29",
   "metadata": {},
   "source": [
    "## Data Augmentation mas \"conservador\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2680a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation conservador para no distorsionar mucho\n",
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.RandomFlip(\"horizontal\"),\n",
    "    keras.layers.RandomRotation(0.1),\n",
    "    keras.layers.RandomZoom(0.1),\n",
    "    keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "print(\"Data Augmentation configurado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c182641b",
   "metadata": {},
   "source": [
    "## Construcción del Modelo Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c95018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo VGG16 pre-entrenado y congelo todas las capas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.applications import VGG16\n",
    "\n",
    "input_shape = image_size + (3,)\n",
    "\n",
    "# VGG16 pre-entrenado sin clasificación\n",
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=input_shape,\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "# Congelo todas las capas de VGG16\n",
    "base_model.trainable = False\n",
    "\n",
    "# Modelo completo con mi cabecera personalizada\n",
    "model = Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    data_augmentation,\n",
    "    base_model,\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "], name='VGG16_Transfer_Learning')\n",
    "\n",
    "print(f\"Capas VGG16 congeladas: {len(base_model.layers)}\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a25a59",
   "metadata": {},
   "source": [
    "## Compilación y Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c262d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilo con Adam lr bajo y añado ReduceLROnPlateau\n",
    "%%time\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "epochs = 15\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"Épocas: {epochs}\")\n",
    "print(f\"Optimizer: Adam (lr=0.0001)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"Val Accuracy final: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Val Precision final: {history.history['val_precision'][-1]:.4f}\")\n",
    "print(f\"Val Recall final: {history.history['val_recall'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ea4801",
   "metadata": {},
   "source": [
    "## Visualización de Curvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44b5efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinto las curvas de entrenamiento para ver si hay overfitting\n",
    "logs = pd.DataFrame(history.history)\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(logs.loc[1:, \"loss\"], lw=2, label='Pérdida en entrenamiento')\n",
    "plt.plot(logs.loc[1:, \"val_loss\"], lw=2, label='Pérdida en validación')\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Pérdida\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(logs.loc[1:, \"accuracy\"], lw=2, label='Precisión en entrenamiento')\n",
    "plt.plot(logs.loc[1:, \"val_accuracy\"], lw=2, label='Precisión en validación')\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPrecisión final en entrenamiento: {logs['accuracy'].iloc[-1]:.4f}\")\n",
    "print(f\"Precisión final en validación: {logs['val_accuracy'].iloc[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd38751",
   "metadata": {},
   "source": [
    "## Guardado del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dde846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardo el modelo entrenado\n",
    "model.save(\"model.keras\")\n",
    "print(\"Modelo guardado como 'model.keras'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4a99f6",
   "metadata": {},
   "source": [
    "## Evaluación con Datos Suplementarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45438cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalúo con supplementary para tener métrica más realista\n",
    "supplementary_ds = keras.utils.image_dataset_from_directory(\n",
    "    SUPP_PATH,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    ")\n",
    "\n",
    "print(\"Evaluando con datos suplementarios...\")\n",
    "results = model.evaluate(supplementary_ds, return_dict=True, verbose=1)\n",
    "\n",
    "print(f\"\\nSupplementary Accuracy: {results['accuracy']:.4f}\")\n",
    "print(f\"Supplementary Precision: {results['precision']:.4f}\")\n",
    "print(f\"Supplementary Recall: {results['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59498e6f",
   "metadata": {},
   "source": [
    "## Generación de Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a066c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero predicciones imagen por imagen para el test\n",
    "%%time\n",
    "\n",
    "predictions_dict = {}\n",
    "\n",
    "print(f\"Generando predicciones para {len(os.listdir(TEST_PATH))} imágenes...\")\n",
    "\n",
    "for img in os.listdir(TEST_PATH):\n",
    "    img_path = os.path.join(TEST_PATH, img)\n",
    "    file_name = img_path.split('/')[-1]\n",
    "    file_no_extension = file_name.split('.')[0]\n",
    "    \n",
    "    img_loaded = keras.utils.load_img(img_path, target_size=image_size)\n",
    "    img_array = keras.utils.img_to_array(img_loaded)\n",
    "    img_array = keras.ops.expand_dims(img_array, 0)\n",
    "    \n",
    "    prediction = model.predict(img_array, verbose=0)[0][0]\n",
    "    label = 1 if prediction >= 0.5 else 0\n",
    "    \n",
    "    predictions_dict[int(file_no_extension)] = label\n",
    "\n",
    "print(f\"Predicciones completadas: {len(predictions_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c2b924",
   "metadata": {},
   "source": [
    "## Creación del Archivo de Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a0abdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el CSV de submission y verifico que esté bien\n",
    "submission = pd.DataFrame(predictions_dict.items(), columns=[\"id\", \"label\"])\n",
    "submission = submission.sort_values(by='id', ascending=True)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ARCHIVO DE SUBMISSION CREADO\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nDistribución de predicciones:\")\n",
    "print(submission[\"label\"].value_counts())\n",
    "print(f\"\\nClase 0 (Cat): {(submission['label'] == 0).sum()} imágenes\")\n",
    "print(f\"Clase 1 (Dog): {(submission['label'] == 1).sum()} imágenes\")\n",
    "print(f\"Total: {len(submission)} imágenes\")\n",
    "\n",
    "if (submission['label'] == 0).sum() == len(submission) or (submission['label'] == 1).sum() == len(submission):\n",
    "    print(\"\\nALERTA: Todas las predicciones son de una sola clase\")\n",
    "else:\n",
    "    print(\"\\nDistribución OK - Listo para enviar\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
