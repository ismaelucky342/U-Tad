{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "#====================================================================================================#\n",
    "#                                                                                                    #\n",
    "#                                                        ██╗   ██╗   ████████╗ █████╗ ██████╗        #\n",
    "#      Competición - INAR                                ██║   ██║   ╚══██╔══╝██╔══██╗██╔══██╗       #\n",
    "#                                                        ██║   ██║█████╗██║   ███████║██║  ██║       #\n",
    "#      created:        29/10/2025  -  23:00:15           ██║   ██║╚════╝██║   ██╔══██║██║  ██║       #\n",
    "#      last change:    05/11/2025  -  02:55:40           ╚██████╔╝      ██║   ██║  ██║██████╔╝       #\n",
    "#                                                         ╚═════╝       ╚═╝   ╚═╝  ╚═╝╚═════╝        #\n",
    "#                                                                                                    #\n",
    "#      Ismael Hernandez Clemente                         ismael.hernandez@live.u-tad.com             #\n",
    "#                                                                                                    #\n",
    "#      Github:                                           https://github.com/ismaelucky342            #\n",
    "#                                                                                                    #\n",
    "#====================================================================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competición Perretes y Gatos\n",
    "\n",
    "## Iteración 5 - Transfer Learning VGG16\n",
    "\n",
    "**Problema anterior**: CNN desde cero se estancó en 0.72 validation accuracy.\n",
    "\n",
    "**Solución Transfer Learning**:\n",
    "- VGG16 pre-entrenado en ImageNet (14M imágenes)\n",
    "- Todas las capas convolucionales CONGELADAS\n",
    "- Solo entrenamos 2 capas Dense (256 → 1)\n",
    "- Learning rate bajo (0.0001) para fine-tuning\n",
    "- 15 épocas (converge rápido)\n",
    "\n",
    "**Objetivo**: Score >0.82 en Kaggle (3 submissions restantes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Importo las librerías necesarias para trabajar con el modelo y los datos\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import data as tf_data\n",
    "import keras\n",
    "\n",
    "# Establezco una semilla aleatoria para que los resultados sean reproducibles\n",
    "seed = 42\n",
    "keras.utils.set_random_seed(seed)\n",
    "\n",
    "# Rutas de datos - cambia solo el nombre del dataset si es diferente\n",
    "DATASET_NAME = \"u-tad-dogs-vs-cats-2025\"\n",
    "TRAIN_PATH = f\"/kaggle/input/{DATASET_NAME}/train/train\"\n",
    "TEST_PATH = f\"/kaggle/input/{DATASET_NAME}/test/test\"\n",
    "SUPP_PATH = f\"/kaggle/input/{DATASET_NAME}/supplementary_data/supplementary_data\"\n",
    "\n",
    "print(\"Versión de Keras:\", keras.__version__)\n",
    "print(\"Rutas configuradas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y Preparación de los Datos\n",
    "\n",
    "Aquí cargo las imágenes de entrenamiento y las divido en conjunto de entrenamiento y validación.\n",
    "He decidido usar un 80% para entrenar y un 20% para validar, que es una proporción bastante estándar.\n",
    "Las imágenes las redimensiono a 256x256 píxeles para que todas tengan el mismo tamaño y el modelo\n",
    "pueda procesarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tamaño de imagen - 224x224 para VGG16\n",
    "image_size = (224, 224)\n",
    "\n",
    "# Batch size\n",
    "batch_size = 125\n",
    "\n",
    "# Cargo las imágenes del directorio de entrenamiento\n",
    "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=seed,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",  # Cambio a binary para más estabilidad\n",
    ")\n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {len(train_ds)} batches\")\n",
    "print(f\"Tamaño del conjunto de validación: {len(val_ds)} batches\")\n",
    "print(f\"Total imágenes de entrenamiento aproximadas: {len(train_ds) * batch_size}\")\n",
    "print(f\"Total imágenes de validación aproximadas: {len(val_ds) * batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Defino transformaciones aleatorias más conservadoras para Transfer Learning.\n",
    "VGG16 ya conoce características generales, así que no necesito tanto augmentation\n",
    "como con un modelo desde cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secuencia de transformaciones aleatorias aplicadas solo durante entrenamiento\n",
    "# Más conservador para Transfer Learning\n",
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.RandomFlip(\"horizontal\"),\n",
    "    keras.layers.RandomRotation(0.1),  # ±36° suficiente\n",
    "    keras.layers.RandomZoom(0.1),      # ±10% sin distorsión\n",
    "    keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "print(\"Data Augmentation configurado (modo conservador para Transfer Learning)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción del Modelo Transfer Learning\n",
    "\n",
    "Uso VGG16 pre-entrenado en ImageNet como base. Es un modelo que ya aprendió características\n",
    "generales de millones de imágenes, así que solo necesito ajustar las últimas capas para\n",
    "que aprenda a diferenciar perros de gatos. Esto es mucho más rápido y efectivo que entrenar\n",
    "desde cero.\n",
    "\n",
    "Congelo todas las capas convolucionales de VGG16 y solo entreno una cabecera personalizada\n",
    "simple: una capa densa de 256 neuronas con dropout y la salida binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.applications import VGG16\n",
    "\n",
    "# Forma de entrada: 224x224 con 3 canales RGB (requerido por VGG16)\n",
    "input_shape = image_size + (3,)\n",
    "\n",
    "# Cargo VGG16 pre-entrenado sin la parte superior (sin clasificación)\n",
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=input_shape,\n",
    "    pooling='avg'  # Global Average Pooling\n",
    ")\n",
    "\n",
    "# CONGELO todas las capas de VGG16 - no las voy a entrenar\n",
    "base_model.trainable = False\n",
    "\n",
    "# Construyo el modelo completo\n",
    "model = Sequential([\n",
    "    keras.Input(shape=input_shape),\n",
    "    data_augmentation,  # Augmentation solo en entrenamiento\n",
    "    base_model,         # VGG16 congelado\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Salida binaria\n",
    "], name='VGG16_Transfer_Learning')\n",
    "\n",
    "print(f\"Modelo Transfer Learning creado\")\n",
    "print(f\"Capas VGG16 congeladas: {len(base_model.layers)}\")\n",
    "print(f\"Solo entrenaremos: Dense(256) + Dropout + Dense(1)\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilación y Entrenamiento del Modelo Transfer Learning\n",
    "\n",
    "Configuro el entrenamiento con learning rate bajo (0.0001) porque estamos ajustando un modelo\n",
    "ya entrenado, no necesitamos cambios tan grandes. Transfer Learning converge más rápido que\n",
    "entrenar desde cero, así que con 15 épocas debería ser suficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),  # LR bajo para Transfer Learning\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "epochs = 15  # Transfer Learning converge rápido\n",
    "\n",
    "# ReduceLROnPlateau: reduce el learning rate si se estanca\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Configuración Transfer Learning VGG16:\")\n",
    "print(f\"Épocas: {epochs}\")\n",
    "print(f\"Optimizer: Adam (lr=0.0001)\")\n",
    "print(f\"Modelo base: VGG16 ImageNet (congelado)\")\n",
    "print(f\"Entrenamos: Solo 2 capas Dense\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"Entrenamiento completado en {len(history.history['loss'])} épocas\")\n",
    "print(f\"Val Accuracy final: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"Val Precision final: {history.history['val_precision'][-1]:.4f}\")\n",
    "print(f\"Val Recall final: {history.history['val_recall'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de las Curvas de Aprendizaje\n",
    "\n",
    "Aquí genero gráficos para ver cómo ha evolucionado el modelo durante el entrenamiento.\n",
    "Es fundamental para detectar si hay overfitting (el modelo memoriza en vez de aprender) o\n",
    "underfitting (el modelo no aprende lo suficiente).\n",
    "\n",
    "Si las curvas de entrenamiento y validación se separan mucho, significa overfitting.\n",
    "Si ambas se quedan estancadas en valores altos de pérdida, es underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "logs = pd.DataFrame(history.history)\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "# Gráfico de pérdida\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(logs.loc[1:, \"loss\"], lw=2, label='Pérdida en entrenamiento')\n",
    "plt.plot(logs.loc[1:, \"val_loss\"], lw=2, label='Pérdida en validación')\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Pérdida\")\n",
    "plt.title(\"Evolución de la Pérdida\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico de precisión\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(logs.loc[1:, \"accuracy\"], lw=2, label='Precisión en entrenamiento')\n",
    "plt.plot(logs.loc[1:, \"val_accuracy\"], lw=2, label='Precisión en validación')\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.title(\"Evolución de la Precisión\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTADOS FINALES:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Precisión final en entrenamiento: {logs['accuracy'].iloc[-1]:.4f}\")\n",
    "print(f\"Precisión final en validación: {logs['val_accuracy'].iloc[-1]:.4f}\")\n",
    "print(f\"Pérdida final en entrenamiento: {logs['loss'].iloc[-1]:.4f}\")\n",
    "print(f\"Pérdida final en validación: {logs['val_loss'].iloc[-1]:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardado del Modelo\n",
    "\n",
    "Guardo el modelo entrenado para poder reutilizarlo más tarde sin tener que volver a entrenarlo.\n",
    "Keras guarda toda la arquitectura, los pesos aprendidos y la configuración de compilación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save(\"model.keras\")\n",
    "print(\"Modelo guardado como 'model.keras'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación con Datos Suplementarios\n",
    "\n",
    "Ahora evalúo el modelo con el conjunto de datos suplementarios que proporciona la competición.\n",
    "Esto me da una idea más realista de cómo se comportará el modelo con datos completamente nuevos\n",
    "que no ha visto nunca durante el entrenamiento ni la validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "supplementary_ds = keras.utils.image_dataset_from_directory(\n",
    "    SUPP_PATH,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",  # Binary consistente\n",
    ")\n",
    "\n",
    "print(\"Evaluando con datos suplementarios...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "results = model.evaluate(supplementary_ds, return_dict=True, verbose=1)\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"\\nRESULTADOS EN DATOS SUPLEMENTARIOS:\")\n",
    "print(f\"Precisión: {results['accuracy']:.4f}\")\n",
    "print(f\"Pérdida: {results['loss']:.4f}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de Predicciones para el Conjunto de Test\n",
    "\n",
    "Aquí genero las predicciones para todas las imágenes del conjunto de test.\n",
    "Este es el conjunto que voy a usar para generar mi submission en la competición.\n",
    "Es importante no modificar esta sección para mantener el formato correcto de submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictions_dict = {}\n",
    "\n",
    "print(f\"Generando predicciones para {len(os.listdir(TEST_PATH))} imágenes...\")\n",
    "print(\"Usando umbral 0.5 para clasificación binaria...\")\n",
    "\n",
    "for img in os.listdir(TEST_PATH):\n",
    "    img_path = os.path.join(TEST_PATH, img)\n",
    "    file_name = img_path.split('/')[-1]\n",
    "    file_no_extension = file_name.split('.')[0]\n",
    "    \n",
    "    img_loaded = keras.utils.load_img(img_path, target_size=image_size)\n",
    "    img_array = keras.utils.img_to_array(img_loaded)\n",
    "    img_array = keras.ops.expand_dims(img_array, 0)\n",
    "    \n",
    "    # Predice probabilidad (salida sigmoid entre 0 y 1)\n",
    "    prediction = model.predict(img_array, verbose=0)[0][0]\n",
    "    \n",
    "    # Conversión EXPLÍCITA con umbral 0.5\n",
    "    label = 1 if prediction >= 0.5 else 0\n",
    "    \n",
    "    predictions_dict[int(file_no_extension)] = label\n",
    "\n",
    "print(f\"Predicciones generadas para {len(predictions_dict)} imágenes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del Archivo de Submission\n",
    "\n",
    "Finalmente, creo el archivo CSV con el formato requerido por la competición para enviar mis predicciones.\n",
    "Verifico también que la distribución de clases sea razonable (no quiero que todas sean de una sola clase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(predictions_dict.items(), columns=[\"id\", \"label\"])\n",
    "submission = submission.sort_values(by='id', ascending=True)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ARCHIVO DE SUBMISSION CREADO\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nDistribución de predicciones:\")\n",
    "print(submission[\"label\"].value_counts())\n",
    "print(f\"\\nClase 0 (Cat): {(submission['label'] == 0).sum()} imágenes ({100*(submission['label'] == 0).sum()/len(submission):.1f}%)\")\n",
    "print(f\"Clase 1 (Dog): {(submission['label'] == 1).sum()} imágenes ({100*(submission['label'] == 1).sum()/len(submission):.1f}%)\")\n",
    "print(f\"Total: {len(submission)} imágenes\")\n",
    "print(\"\\nPrimeras filas:\")\n",
    "print(submission.head(10))\n",
    "print(\"\\nÚltimas filas:\")\n",
    "print(submission.tail(10))\n",
    "\n",
    "# VERIFICACIÓN CRÍTICA\n",
    "if (submission['label'] == 0).sum() == len(submission) or (submission['label'] == 1).sum() == len(submission):\n",
    "    print(\"\\n\" + \"!\"*60)\n",
    "    print(\"ALERTA: TODAS LAS PREDICCIONES SON DE UNA SOLA CLASE\")\n",
    "    print(\"Revisar el modelo antes de enviar a Kaggle\")\n",
    "    print(\"!\"*60)\n",
    "else:\n",
    "    print(\"\\n✓ Distribución de clases OK - Listo para enviar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Análisis de Resultados - Iteración 4 (Bug Fix)\n",
    "\n",
    "### Cambios respecto a Iteración 3\n",
    "\n",
    "**CORRECCIONES CRÍTICAS:**\n",
    "1. **Label mode**: categorical → binary (más estable para 2 clases)\n",
    "2. **Capa de salida**: softmax(2) → sigmoid(1)\n",
    "3. **Loss function**: categorical_crossentropy → binary_crossentropy\n",
    "4. **Predicciones**: np.argmax() → umbral explícito 0.5\n",
    "5. **Verificación**: alertas si todas las predicciones son una sola clase\n",
    "\n",
    "**OPTIMIZACIONES:**\n",
    "1. **Optimizer**: RMSprop → Adam (convergencia más estable)\n",
    "2. **Learning rate**: 0.001 → 0.0005 (más conservador)\n",
    "3. **Épocas**: 25 → 20 (fijas, sin early stopping)\n",
    "4. **Early stopping**: ELIMINADO (era demasiado agresivo)\n",
    "\n",
    "### Hipótesis del Bug\n",
    "\n",
    "El problema en Iteración 3 (score 0.58768) fue:\n",
    "- Salida categorical con softmax puede dar probabilidades muy cercanas\n",
    "- np.argmax() puede sesgar hacia una clase si el modelo no está bien calibrado\n",
    "- Early stopping paró en época 15, posiblemente demasiado temprano\n",
    "\n",
    "### Objetivos\n",
    "\n",
    "- Validation accuracy: >0.82\n",
    "- Supplementary accuracy: >0.75\n",
    "- Distribución balanceada de predicciones (40-60% cada clase)\n",
    "- Kaggle score: >0.75 (recuperación)\n",
    "\n",
    "Documentación completa en ITERACIONES.md"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9809442,
     "sourceId": 86515,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
