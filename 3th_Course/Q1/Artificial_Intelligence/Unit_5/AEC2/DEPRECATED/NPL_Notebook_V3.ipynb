{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be81f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4190c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "import sys\n",
    "try:\n",
    "    import google.protobuf\n",
    "    if hasattr(google.protobuf, '__version__'):\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b705b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Embedding, LSTM, Bidirectional, Dense, Dropout, \n",
    "    GlobalMaxPooling1D, Conv1D, SpatialDropout1D\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "tf.random.set_seed(seed)\n",
    "keras.utils.set_random_seed(seed)\n",
    "pd.set_option('display.max_rows', 36)\n",
    "pd.set_option(\"display.max_colwidth\", 150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef09c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 10000\n",
    "MAX_LEN = 200\n",
    "EMBEDDING_DIM = 100\n",
    "LSTM_UNITS = 64           ",
    "DENSE_UNITS = 32          ",
    "DROPOUT_RATE = 0.7        ",
    "SPATIAL_DROPOUT = 0.4     ",
    "L2_REG = 5e-4             ",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "VALIDATION_SPLIT = 0.2\n",
    "LEARNING_RATE = 5e-4      ",
    "CLIPNORM = 1.0            ",
    "estimated_params_v3 = (\n",
    "    MAX_WORDS * EMBEDDING_DIM +\n",
    "    4 * LSTM_UNITS * (EMBEDDING_DIM + LSTM_UNITS + 1) * 2 +\n",
    "    (LSTM_UNITS * 2) * DENSE_UNITS + DENSE_UNITS +\n",
    "    DENSE_UNITS + 1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43721cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/train.csv\", index_col=\"row_id\")\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ec7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text_length'] = train['text'].apply(lambda x: len(str(x).split()))\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(train['text_length'], bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribución de Longitud de Textos')\n",
    "plt.xlabel('Número de palabras')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.axvline(train['text_length'].mean(), color='red', linestyle='--', label=f'Media: {train[\"text_length\"].mean():.1f}')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(data=train, x='spam_label', y='text_length')\n",
    "plt.title('Longitud por Clase')\n",
    "plt.xlabel('Clase (0=Not SPAM, 1=SPAM)')\n",
    "plt.ylabel('Número de palabras')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb58216",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = train['text'].values\n",
    "y_train = train['spam_label'].values\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train_text)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_text)\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_pad, y_train, \n",
    "    test_size=VALIDATION_SPLIT, \n",
    "    random_state=seed,\n",
    "    stratify=y_train\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c9f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_v3():\n",
    "    model = Sequential([\n",
    "        Embedding(\n",
    "            input_dim=MAX_WORDS,\n",
    "            output_dim=EMBEDDING_DIM,\n",
    "            input_length=MAX_LEN,\n",
    "            name='embedding'\n",
    "        ),\n",
    "        SpatialDropout1D(SPATIAL_DROPOUT),\n",
    "        Bidirectional(\n",
    "            LSTM(\n",
    "                LSTM_UNITS, \n",
    "                return_sequences=True,\n",
    "                kernel_regularizer=l2(L2_REG),\n",
    "                recurrent_regularizer=l2(L2_REG),\n",
    "                bias_regularizer=l2(L2_REG)     ",
    "            ), \n",
    "            name='bidirectional_lstm'\n",
    "        ),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dense(\n",
    "            DENSE_UNITS, \n",
    "            activation='relu',\n",
    "            kernel_regularizer=l2(L2_REG),\n",
    "            bias_regularizer=l2(L2_REG),        ",
    "            name='dense_1'\n",
    "        ),\n",
    "        Dropout(DROPOUT_RATE),\n",
    "        Dense(1, activation='sigmoid', name='output')\n",
    "    ], name='spam_classifier_v3_shock_therapy')\n",
    "    return model\n",
    "model = build_model_v3()\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=1e-4,\n",
    "    clipnorm=CLIPNORM  ",
    ")\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc')\n",
    "    ]\n",
    ")\n",
    "model.build(input_shape=(None, MAX_LEN))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e80b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=2,  ",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_spam_model_v3.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=1,  ",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "history = model.fit(\n",
    "    X_train_final, y_train_final,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f719b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict(X_val)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "mcc_score = matthews_corrcoef(y_val, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', \n",
    "            xticklabels=['Not SPAM', 'SPAM'],\n",
    "            yticklabels=['Not SPAM', 'SPAM'])\n",
    "plt.title(f'Confusion Matrix V3 - Shock Therapy (MCC: {mcc_score:.4f})')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c69f998",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "final_train_acc = history.history['accuracy'][-1]\n",
    "final_val_acc = history.history['val_accuracy'][-1]\n",
    "overfitting_delta = abs(final_val_loss - final_train_loss)\n",
    "v1_data = {'train_loss': 0.0055, 'val_loss': 0.1895, 'mcc': 0.8665, 'params': 1251009}\n",
    "v2_data = {'train_loss': 0.0411, 'val_loss': 0.2075, 'mcc': 0.8885, 'params': 1160609}\n",
    "v3_data = {\n",
    "    'train_loss': final_train_loss, \n",
    "    'val_loss': final_val_loss, \n",
    "    'mcc': mcc_score,\n",
    "    'params': model.count_params()\n",
    "}\n",
    "v1_delta = abs(v1_data['val_loss'] - v1_data['train_loss'])\n",
    "v2_delta = abs(v2_data['val_loss'] - v2_data['train_loss'])\n",
    "v3_delta = overfitting_delta\n",
    "success_v3 = [\n",
    "    (\"Overfitting Delta < 0.08\", v3_delta < 0.08),\n",
    "    (\"MCC >= 0.87\", v3_data['mcc'] >= 0.87),\n",
    "    (\"Val Loss < 0.14\", v3_data['val_loss'] < 0.14),\n",
    "    (\"Train Loss > 0.05\", v3_data['train_loss'] > 0.05),\n",
    "    (\"Mejora vs V2\", v3_delta < v2_delta)\n",
    "]\n",
    "for criterion, success in success_v3:\n",
    "    status = \"OK\" if success else \"FAIL\"\n",
    "total_success = sum([s for _, s in success_v3])\n",
    "if total_success >= 4:\n",
    "elif total_success >= 3:\n",
    "else:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daed813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history, title_prefix=\"\"):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    axes[0, 0].plot(history.history['loss'], label='Train Loss', linewidth=2, color='red')\n",
    "    axes[0, 0].plot(history.history['val_loss'], label='Val Loss', linewidth=2, color='darkred')\n",
    "    axes[0, 0].set_title(f'{title_prefix} Loss', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 1].plot(history.history['accuracy'], label='Train Acc', linewidth=2, color='red')\n",
    "    axes[0, 1].plot(history.history['val_accuracy'], label='Val Acc', linewidth=2, color='darkred')\n",
    "    axes[0, 1].set_title(f'{title_prefix} Accuracy', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[1, 0].plot(history.history['precision'], label='Train Prec', linewidth=2, color='red')\n",
    "    axes[1, 0].plot(history.history['val_precision'], label='Val Prec', linewidth=2, color='darkred')\n",
    "    axes[1, 0].set_title(f'{title_prefix} Precision', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Precision')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 1].plot(history.history['recall'], label='Train Recall', linewidth=2, color='red')\n",
    "    axes[1, 1].plot(history.history['val_recall'], label='Val Recall', linewidth=2, color='darkred')\n",
    "    axes[1, 1].set_title(f'{title_prefix} Recall', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Recall')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_learning_curves(history, title_prefix=\"V3 Shock Therapy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443772fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/test.csv\", index_col=\"row_id\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b772fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_text = test['text'].values\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_text)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "y_pred_proba_test = model.predict(X_test_pad, batch_size=BATCH_SIZE)\n",
    "y_pred_test = (y_pred_proba_test > 0.5).astype(int).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73547050",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/sample_submission.csv\")\n",
    "submission[\"spam_label\"] = y_pred_test\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    'Métrica': [\n",
    "        'Validation MCC',\n",
    "        'Train Loss',\n",
    "        'Val Loss',\n",
    "        'Overfitting Delta',\n",
    "        'Train Accuracy',\n",
    "        'Val Accuracy',\n",
    "        'Total Parameters',\n",
    "        'Training Epochs'\n",
    "    ],\n",
    "    'V1 Baseline': [\n",
    "        '0.8665',\n",
    "        '0.0055',\n",
    "        '0.1895',\n",
    "        '0.1840',\n",
    "        '99.91%',\n",
    "        '95.77%',\n",
    "        '1,251,009',\n",
    "        '8'\n",
    "    ],\n",
    "    'V2 Moderate': [\n",
    "        '0.8885',\n",
    "        '0.0411',\n",
    "        '0.2075',\n",
    "        '0.1663',\n",
    "        '99.56%',\n",
    "        '95.07%',\n",
    "        '1,160,609',\n",
    "        '6'\n",
    "    ],\n",
    "    'V3 Shock': [\n",
    "        f'{mcc_score:.4f}',\n",
    "        f'{final_train_loss:.4f}',\n",
    "        f'{final_val_loss:.4f}',\n",
    "        f'{overfitting_delta:.4f}',\n",
    "        f'{final_train_acc:.2%}',\n",
    "        f'{final_val_acc:.2%}',\n",
    "        f'{model.count_params():,}',\n",
    "        f'{len(history.history[\"loss\"])}'\n",
    "    ]\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}