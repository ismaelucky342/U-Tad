{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046fc328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5f252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  \n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import (\n",
    "    Embedding, Dense, Dropout, LSTM, Bidirectional, \n",
    "    Conv1D, GlobalMaxPooling1D, Concatenate, Input, SpatialDropout1D  \n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "tf.random.set_seed(seed)\n",
    "keras.utils.set_random_seed(seed)\n",
    "from sklearn.metrics import matthews_corrcoef, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_rows', 36)\n",
    "pd.set_option(\"display.max_colwidth\", 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492ae89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 50000  \n",
    "MAX_LEN = 200  \n",
    "EMBEDDING_DIM = 128  \n",
    "CNN_FILTERS = 128  \n",
    "CNN_KERNEL_SIZES = [2, 3, 4, 5]  \n",
    "LSTM_UNITS = 96  \n",
    "DENSE_UNITS = 64  \n",
    "SPATIAL_DROPOUT = 0.3  \n",
    "DROPOUT = 0.5  \n",
    "L2_REG = 1e-4  \n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 1e-3  \n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50924ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/train.csv\", index_col=\"row_id\")\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train['text'])\n",
    "X_train_seq = tokenizer.texts_to_sequences(train['text'])\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "y_train = train['spam_label'].values\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_pad, y_train, test_size=VALIDATION_SPLIT, random_state=seed, stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca4cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_lstm_model():\n",
    "    \"\"\"\n",
    "    Modelo hibrido CNN + LSTM\n",
    "    La arquitectura:\n",
    "    1. Input + Embedding + SpatialDropout\n",
    "    2. RAMA CNN: Varios Conv1D con diferentes kernel_sizes (para capturar n-gramas de diferentes tamaÃ±os)\n",
    "    3. RAMA LSTM: Bi-LSTM para capturar contexto secuencial\n",
    "    4. Concateno las features de CNN y LSTM\n",
    "    5. Clasificador Dense con dropout\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(MAX_LEN,))\n",
    "    x = Embedding(\n",
    "        input_dim=MAX_WORDS,\n",
    "        output_dim=EMBEDDING_DIM,\n",
    "        input_length=MAX_LEN\n",
    "    )(inputs)\n",
    "    x = SpatialDropout1D(SPATIAL_DROPOUT)(x)  \n",
    "    cnn_outputs = []\n",
    "    for kernel_size in CNN_KERNEL_SIZES:\n",
    "        conv = Conv1D(\n",
    "            filters=CNN_FILTERS,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='relu',\n",
    "            kernel_regularizer=l2(L2_REG),\n",
    "            padding='same'\n",
    "        )(x)\n",
    "        pool = GlobalMaxPooling1D()(conv)\n",
    "        cnn_outputs.append(pool)\n",
    "    lstm_out = Bidirectional(\n",
    "        LSTM(\n",
    "            LSTM_UNITS,\n",
    "            kernel_regularizer=l2(L2_REG),\n",
    "            recurrent_regularizer=l2(L2_REG),\n",
    "            dropout=0.3,\n",
    "            recurrent_dropout=0.3\n",
    "        )\n",
    "    )(x)\n",
    "    concatenated = Concatenate()(cnn_outputs + [lstm_out])\n",
    "    dense = Dense(\n",
    "        DENSE_UNITS,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=l2(L2_REG)\n",
    "    )(concatenated)\n",
    "    dense = Dropout(DROPOUT)(dense)\n",
    "    outputs = Dense(1, activation='sigmoid')(dense)\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='CNN_LSTM_Hybrid_V5')\n",
    "    return model\n",
    "model = build_cnn_lstm_model()\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.AUC()]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1d9eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint('best_cnn_lstm_model.keras', monitor='val_loss', save_best_only=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "history = model.fit(\n",
    "    X_train_final, y_train_final,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beb9d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict(X_val, batch_size=BATCH_SIZE, verbose=0)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "mcc_score = matthews_corrcoef(y_val, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f'CNN+LSTM Hybrid (MCC: {mcc_score:.4f})')\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36f3fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/test.csv\", index_col=\"row_id\")\n",
    "X_test_seq = tokenizer.texts_to_sequences(test['text'])\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "y_pred_test = model.predict(X_test_pad, batch_size=BATCH_SIZE, verbose=0)\n",
    "y_pred_test = (y_pred_test > 0.5).astype(int).flatten()\n",
    "submission = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/sample_submission.csv\")\n",
    "submission[\"spam_label\"] = y_pred_test\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}