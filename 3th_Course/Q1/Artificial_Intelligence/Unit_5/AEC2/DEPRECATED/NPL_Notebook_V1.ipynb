{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T06:06:07.216455Z",
     "iopub.status.busy": "2025-11-04T06:06:07.21624Z",
     "iopub.status.idle": "2025-11-04T06:06:10.796746Z",
     "shell.execute_reply": "2025-11-04T06:06:10.795976Z",
     "shell.execute_reply.started": "2025-11-04T06:06:07.216437Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'  ",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import pandas as pd  ",
    "import numpy as np  ",
    "import matplotlib.pyplot as plt  ",
    "import seaborn as sns  ",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Embedding, LSTM, Bidirectional, Dense, Dropout, \n",
    "    GlobalMaxPooling1D, Conv1D, SpatialDropout1D\n",
    ")\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "tf.random.set_seed(seed)\n",
    "keras.utils.set_random_seed(seed)\n",
    "from sklearn.metrics import matthews_corrcoef, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_rows', 36)\n",
    "pd.set_option(\"display.max_colwidth\", 150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 10000  ",
    "MAX_LEN = 200  ",
    "EMBEDDING_DIM = 100  ",
    "LSTM_UNITS = 128  ",
    "DENSE_UNITS = 64  ",
    "DROPOUT_RATE = 0.5  ",
    "SPATIAL_DROPOUT = 0.2  ",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50  ",
    "VALIDATION_SPLIT = 0.2\n",
    "LEARNING_RATE = 1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T06:06:10.799421Z",
     "iopub.status.busy": "2025-11-04T06:06:10.798848Z",
     "iopub.status.idle": "2025-11-04T06:06:10.983318Z",
     "shell.execute_reply": "2025-11-04T06:06:10.982344Z",
     "shell.execute_reply.started": "2025-11-04T06:06:10.799391Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/train.csv\", index_col=\"row_id\")\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text_length'] = train['text'].apply(lambda x: len(str(x).split()))\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(train['text_length'], bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribución de Longitud de Textos')\n",
    "plt.xlabel('Número de palabras')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.axvline(train['text_length'].mean(), color='red', linestyle='--', label=f'Media: {train[\"text_length\"].mean():.1f}')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.subplot(1, 3, 2)\n",
    "train.groupby('spam_label')['text_length'].hist(bins=30, alpha=0.7, label=['Not SPAM', 'SPAM'])\n",
    "plt.title('Longitud por Clase')\n",
    "plt.xlabel('Número de palabras')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(data=train, x='spam_label', y='text_length')\n",
    "plt.title('Boxplot Longitud por Clase')\n",
    "plt.xlabel('Clase (0=Not SPAM, 1=SPAM)')\n",
    "plt.ylabel('Número de palabras')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_text = train['text'].values\n",
    "y_train = train['spam_label'].values\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")  ",
    "tokenizer.fit_on_texts(X_train_text)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_text)\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_pad, y_train, \n",
    "    test_size=VALIDATION_SPLIT, \n",
    "    random_state=seed,\n",
    "    stratify=y_train  ",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential([\n",
    "        Embedding(\n",
    "            input_dim=MAX_WORDS,\n",
    "            output_dim=EMBEDDING_DIM,\n",
    "            input_length=MAX_LEN,\n",
    "            name='embedding'\n",
    "        ),\n",
    "        SpatialDropout1D(SPATIAL_DROPOUT),\n",
    "        Bidirectional(LSTM(LSTM_UNITS, return_sequences=True), name='bidirectional_lstm'),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dense(DENSE_UNITS, activation='relu', name='dense_1'),\n",
    "        Dropout(DROPOUT_RATE),  ",
    "        Dense(1, activation='sigmoid', name='output')\n",
    "    ], name='spam_classifier_v1')\n",
    "    return model\n",
    "model = build_model()\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.AdamW(learning_rate=LEARNING_RATE, weight_decay=1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc')\n",
    "    ]\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,  ",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_spam_model.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,  ",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,  ",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "history = model.fit(\n",
    "    X_train_final, y_train_final,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,  ",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict(X_val)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "mcc_score = matthews_corrcoef(y_val, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Not SPAM', 'SPAM'],\n",
    "            yticklabels=['Not SPAM', 'SPAM'])\n",
    "plt.title(f'Confusion Matrix (MCC: {mcc_score:.4f})')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history, title_prefix=\"\"):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    axes[0, 0].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "    axes[0, 0].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    axes[0, 0].set_title(f'{title_prefix} Loss', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 1].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    axes[0, 1].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "    axes[0, 1].set_title(f'{title_prefix} Accuracy', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[1, 0].plot(history.history['precision'], label='Train Precision', linewidth=2)\n",
    "    axes[1, 0].plot(history.history['val_precision'], label='Val Precision', linewidth=2)\n",
    "    axes[1, 0].set_title(f'{title_prefix} Precision', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Precision')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 1].plot(history.history['recall'], label='Train Recall', linewidth=2)\n",
    "    axes[1, 1].plot(history.history['val_recall'], label='Val Recall', linewidth=2)\n",
    "    axes[1, 1].set_title(f'{title_prefix} Recall', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Recall')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_learning_curves(history, title_prefix=\"Model\")\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "final_train_acc = history.history['accuracy'][-1]\n",
    "final_val_acc = history.history['val_accuracy'][-1]\n",
    "if abs(final_val_loss - final_train_loss) < 0.1:\n",
    "elif final_val_loss > final_train_loss:\n",
    "else:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T06:06:10.984694Z",
     "iopub.status.busy": "2025-11-04T06:06:10.984434Z",
     "iopub.status.idle": "2025-11-04T06:06:11.115096Z",
     "shell.execute_reply": "2025-11-04T06:06:11.11422Z",
     "shell.execute_reply.started": "2025-11-04T06:06:10.984674Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/test.csv\", index_col=\"row_id\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T06:06:11.116879Z",
     "iopub.status.busy": "2025-11-04T06:06:11.116104Z",
     "iopub.status.idle": "2025-11-04T06:06:11.1208Z",
     "shell.execute_reply": "2025-11-04T06:06:11.119841Z",
     "shell.execute_reply.started": "2025-11-04T06:06:11.116849Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_test_text = test['text'].values\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_text)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "y_pred_proba_test = model.predict(X_test_pad, batch_size=BATCH_SIZE)\n",
    "y_pred_test = (y_pred_proba_test > 0.5).astype(int).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T06:06:11.122392Z",
     "iopub.status.busy": "2025-11-04T06:06:11.121642Z",
     "iopub.status.idle": "2025-11-04T06:06:11.156547Z",
     "shell.execute_reply": "2025-11-04T06:06:11.155676Z",
     "shell.execute_reply.started": "2025-11-04T06:06:11.122365Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/sample_submission.csv\")\n",
    "submission[\"spam_label\"] = y_pred_test\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T06:06:11.157716Z",
     "iopub.status.busy": "2025-11-04T06:06:11.15742Z",
     "iopub.status.idle": "2025-11-04T06:06:11.164994Z",
     "shell.execute_reply": "2025-11-04T06:06:11.164202Z",
     "shell.execute_reply.started": "2025-11-04T06:06:11.157696Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_summary = pd.DataFrame({\n",
    "    'Métrica': ['MCC', 'Accuracy', 'Precision', 'Recall', 'Loss'],\n",
    "    'Training': [\n",
    "        'N/A',  ",
    "        f\"{history.history['accuracy'][-1]:.4f}\",\n",
    "        f\"{history.history['precision'][-1]:.4f}\",\n",
    "        f\"{history.history['recall'][-1]:.4f}\",\n",
    "        f\"{history.history['loss'][-1]:.4f}\"\n",
    "    ],\n",
    "    'Validation': [\n",
    "        f\"{mcc_score:.4f}\",\n",
    "        f\"{history.history['val_accuracy'][-1]:.4f}\",\n",
    "        f\"{history.history['val_precision'][-1]:.4f}\",\n",
    "        f\"{history.history['val_recall'][-1]:.4f}\",\n",
    "        f\"{history.history['val_loss'][-1]:.4f}\"\n",
    "    ]\n",
    "})\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(['Accuracy', 'Precision', 'Recall']))\n",
    "width = 0.35\n",
    "train_vals = [\n",
    "    history.history['accuracy'][-1],\n",
    "    history.history['precision'][-1],\n",
    "    history.history['recall'][-1]\n",
    "]\n",
    "val_vals = [\n",
    "    history.history['val_accuracy'][-1],\n",
    "    history.history['val_precision'][-1],\n",
    "    history.history['val_recall'][-1]\n",
    "]\n",
    "bars1 = ax.bar(x - width/2, train_vals, width, label='Training', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, val_vals, width, label='Validation', alpha=0.8)\n",
    "ax.set_xlabel('Métrica', fontweight='bold')\n",
    "ax.set_ylabel('Score', fontweight='bold')\n",
    "ax.set_title(f'Comparación Métricas - Train vs Validation\\nMCC Validation: {mcc_score:.4f}', \n",
    "             fontweight='bold', fontsize=12)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Accuracy', 'Precision', 'Recall'])\n",
    "ax.legend()\n",
    "ax.set_ylim([0, 1.1])\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_summary = pd.DataFrame({\n",
    "    'Métrica': [\n",
    "        'Matthews Correlation Coefficient',\n",
    "        'Validation Accuracy',\n",
    "        'Validation Precision',\n",
    "        'Validation Recall',\n",
    "        'Training Loss',\n",
    "        'Validation Loss',\n",
    "        'Total Parameters',\n",
    "        'Training Samples',\n",
    "        'Validation Samples',\n",
    "        'Test Samples'\n",
    "    ],\n",
    "    'Valor': [\n",
    "        f\"{mcc_score:.4f}\",\n",
    "        f\"{final_val_acc:.4f}\",\n",
    "        f\"{history.history['val_precision'][-1]:.4f}\",\n",
    "        f\"{history.history['val_recall'][-1]:.4f}\",\n",
    "        f\"{final_train_loss:.4f}\",\n",
    "        f\"{final_val_loss:.4f}\",\n",
    "        f\"{model.count_params():,}\",\n",
    "        f\"{len(X_train_final):,}\",\n",
    "        f\"{len(X_val):,}\",\n",
    "        f\"{len(test):,}\"\n",
    "    ]\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14338739,
     "sourceId": 119855,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}