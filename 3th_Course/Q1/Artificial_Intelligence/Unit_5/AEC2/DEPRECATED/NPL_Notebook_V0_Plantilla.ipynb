{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================================================#\n",
    "#                                                                                                    #\n",
    "#                                                        ██╗   ██╗   ████████╗ █████╗ ██████╗        #\n",
    "#      Competición - INAR AEC2                           ██║   ██║   ╚══██╔══╝██╔══██╗██╔══██╗       #\n",
    "#                                                        ██║   ██║█████╗██║   ███████║██║  ██║       #\n",
    "#      created:        28/11/2025  -  10:15:23           ██║   ██║╚════╝██║   ██╔══██║██║  ██║       #\n",
    "#      last change:    28/11/2025  -  12:40:10           ╚██████╔╝      ██║   ██║  ██║██████╔╝       #\n",
    "#                                                         ╚═════╝       ╚═╝   ╚═╝  ╚═╝╚═════╝        #\n",
    "#                                                                                                    #\n",
    "#      Ismael Hernandez Clemente                         ismael.hernandez@live.u-tad.com             #\n",
    "#                                                                                                    #\n",
    "#      Github:                                           https://github.com/ismaelucky342            #\n",
    "#                                                                                                    #\n",
    "#====================================================================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteración 0: Starter Notebook (Plantilla)\n",
    "**Estado: DEPRECATED**\n",
    "\n",
    "Este es el punto de partida de mi proyecto. He utilizado la plantilla proporcionada para entender el funcionamiento básico de la competición, la carga de datos y el formato de entrega. Es un modelo sencillo que sirve como base para las mejoras posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T06:06:07.216455Z",
     "iopub.status.busy": "2025-11-04T06:06:07.21624Z",
     "iopub.status.idle": "2025-11-04T06:06:10.796746Z",
     "shell.execute_reply": "2025-11-04T06:06:10.795976Z",
     "shell.execute_reply.started": "2025-11-04T06:06:07.216437Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Embedding, LSTM, Bidirectional, Dense, Dropout, \n",
    "    GlobalMaxPooling1D, Conv1D, SpatialDropout1D\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "tf.random.set_seed(seed)\n",
    "keras.utils.set_random_seed(seed)\n",
    "from sklearn.metrics import matthews_corrcoef, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_rows', 36)\n",
    "pd.set_option(\"display.max_colwidth\", 150)\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "    for gpu in gpu_devices:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 10000  \n",
    "MAX_LEN = 200  \n",
    "EMBEDDING_DIM = 100  \n",
    "LSTM_UNITS = 128  \n",
    "DENSE_UNITS = 64  \n",
    "DROPOUT_RATE = 0.5  \n",
    "SPATIAL_DROPOUT = 0.2  \n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "VALIDATION_SPLIT = 0.2\n",
    "LEARNING_RATE = 1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T06:06:10.799421Z",
     "iopub.status.busy": "2025-11-04T06:06:10.798848Z",
     "iopub.status.idle": "2025-11-04T06:06:10.983318Z",
     "shell.execute_reply": "2025-11-04T06:06:10.982344Z",
     "shell.execute_reply.started": "2025-11-04T06:06:10.799391Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/train.csv\", index_col=\"row_id\")\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text_length'] = train['text'].apply(lambda x: len(str(x).split()))\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(train['text_length'], bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribución de Longitud de Textos')\n",
    "plt.xlabel('Número de palabras')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.axvline(train['text_length'].mean(), color='red', linestyle='--', label=f'Media: {train[\"text_length\"].mean():.1f}')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.subplot(1, 3, 2)\n",
    "train.groupby('spam_label')['text_length'].hist(bins=30, alpha=0.7, label=['Not SPAM', 'SPAM'])\n",
    "plt.title('Longitud por Clase')\n",
    "plt.xlabel('Número de palabras')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(data=train, x='spam_label', y='text_length')\n",
    "plt.title('Boxplot Longitud por Clase')\n",
    "plt.xlabel('Clase (0=Not SPAM, 1=SPAM)')\n",
    "plt.ylabel('Número de palabras')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_text = train['text'].values\n",
    "y_train = train['spam_label'].values\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train_text)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_text)\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_pad, y_train, \n",
    "    test_size=VALIDATION_SPLIT, \n",
    "    random_state=seed,\n",
    "    stratify=y_train\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential([\n",
    "        Embedding(\n",
    "            input_dim=MAX_WORDS,\n",
    "            output_dim=EMBEDDING_DIM,\n",
    "            input_length=MAX_LEN,\n",
    "            name='embedding'\n",
    "        ),\n",
    "        SpatialDropout1D(SPATIAL_DROPOUT),\n",
    "        Bidirectional(LSTM(LSTM_UNITS, return_sequences=True), name='bidirectional_lstm'),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dense(DENSE_UNITS, activation='relu', name='dense_1'),\n",
    "        Dropout(DROPOUT_RATE),\n",
    "        Dense(1, activation='sigmoid', name='output')\n",
    "    ], name='spam_classifier')\n",
    "    return model\n",
    "model = build_model()\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.AdamW(learning_rate=LEARNING_RATE, weight_decay=1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc')\n",
    "    ]\n",
    ")\n",
    "model.build(input_shape=(None, MAX_LEN))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_spam_model.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "history = model.fit(\n",
    "    X_train_final, y_train_final,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict(X_val)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "mcc_score = matthews_corrcoef(y_val, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Not SPAM', 'SPAM'],\n",
    "            yticklabels=['Not SPAM', 'SPAM'])\n",
    "plt.title(f'Confusion Matrix (MCC: {mcc_score:.4f})')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history, title_prefix=\"\"):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    axes[0, 0].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "    axes[0, 0].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    axes[0, 0].set_title(f'{title_prefix} Loss', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 1].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    axes[0, 1].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "    axes[0, 1].set_title(f'{title_prefix} Accuracy', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[1, 0].plot(history.history['precision'], label='Train Precision', linewidth=2)\n",
    "    axes[1, 0].plot(history.history['val_precision'], label='Val Precision', linewidth=2)\n",
    "    axes[1, 0].set_title(f'{title_prefix} Precision', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Precision')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 1].plot(history.history['recall'], label='Train Recall', linewidth=2)\n",
    "    axes[1, 1].plot(history.history['val_recall'], label='Val Recall', linewidth=2)\n",
    "    axes[1, 1].set_title(f'{title_prefix} Recall', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Recall')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_learning_curves(history, title_prefix=\"Model\")\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "final_train_acc = history.history['accuracy'][-1]\n",
    "final_val_acc = history.history['val_accuracy'][-1]\n",
    "if abs(final_val_loss - final_train_loss) < 0.1:\n",
    "elif final_val_loss > final_train_loss:\n",
    "else:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T06:06:10.984694Z",
     "iopub.status.busy": "2025-11-04T06:06:10.984434Z",
     "iopub.status.idle": "2025-11-04T06:06:11.115096Z",
     "shell.execute_reply": "2025-11-04T06:06:11.11422Z",
     "shell.execute_reply.started": "2025-11-04T06:06:10.984674Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/test.csv\", index_col=\"row_id\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T06:06:11.116879Z",
     "iopub.status.busy": "2025-11-04T06:06:11.116104Z",
     "iopub.status.idle": "2025-11-04T06:06:11.1208Z",
     "shell.execute_reply": "2025-11-04T06:06:11.119841Z",
     "shell.execute_reply.started": "2025-11-04T06:06:11.116849Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_test_text = test['text'].values\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_text)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "y_pred_proba_test = model.predict(X_test_pad, batch_size=BATCH_SIZE)\n",
    "y_pred_test = (y_pred_proba_test > 0.5).astype(int).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T06:06:11.122392Z",
     "iopub.status.busy": "2025-11-04T06:06:11.121642Z",
     "iopub.status.idle": "2025-11-04T06:06:11.156547Z",
     "shell.execute_reply": "2025-11-04T06:06:11.155676Z",
     "shell.execute_reply.started": "2025-11-04T06:06:11.122365Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/sample_submission.csv\")\n",
    "submission[\"spam_label\"] = y_pred_test\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T06:06:11.157716Z",
     "iopub.status.busy": "2025-11-04T06:06:11.15742Z",
     "iopub.status.idle": "2025-11-04T06:06:11.164994Z",
     "shell.execute_reply": "2025-11-04T06:06:11.164202Z",
     "shell.execute_reply.started": "2025-11-04T06:06:11.157696Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero las curvas de aprendizaje para el modelo inicial.\n",
    "def plot_learning_curves(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs_range = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de la Iteración 0\n",
    "Este modelo inicial me ha permitido validar que todo el pipeline de datos funciona correctamente. El MCC obtenido es de aproximadamente 0.60, lo cual es un buen punto de partida pero claramente mejorable.\n",
    "\n",
    "**Conclusión:** El modelo es demasiado simple. En la siguiente iteración (V1), implementaré una arquitectura Bi-LSTM más robusta para intentar capturar mejor el contexto del texto."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14338739,
     "sourceId": 119855,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
