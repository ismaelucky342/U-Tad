{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be2d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================================================#\n",
    "#                                                                                                    #\n",
    "#                                                        ██╗   ██╗   ████████╗ █████╗ ██████╗        #\n",
    "#      Competición - SPAM/NOT SPAM - ITERACIÓN 5        ██║   ██║   ╚══██╔══╝██╔══██╗██╔══██╗       #\n",
    "#      HYBRID CNN + LSTM ARCHITECTURE                   ██║   ██║█████╗██║   ███████║██║  ██║       #\n",
    "#      created:        05/12/2025  -  12:00:00           ██║   ██║╚════╝██║   ██╔══██║██║  ██║       #\n",
    "#      last change:    05/12/2025  -  12:00:00           ╚██████╔╝      ██║   ██║  ██║██████╔╝       #\n",
    "#                                                         ╚═════╝       ╚═╝   ╚═╝  ╚═╝╚═════╝        #\n",
    "#                                                                                                    #\n",
    "#      Ismael Hernandez Clemente                         ismael.hernandez@live.u-tad.com             #\n",
    "#                                                                                                    #\n",
    "#      Github:                                           https://github.com/ismaelucky342            #\n",
    "#                                                                                                    #\n",
    "#      ARQUITECTURA HÍBRIDA CNN+LSTM:                                                               #\n",
    "#      - CNN: Captura n-gramas locales (patrones spam típicos)                                     #\n",
    "#      - LSTM: Captura dependencias largas (contexto)                                              #\n",
    "#      - Múltiples kernel sizes (2,3,4,5) para diferentes n-gramas                                 #\n",
    "#      - Concatenación de features CNN + LSTM                                                      #\n",
    "#      - Dropout y L2 regularization                                                                #\n",
    "#      - Basado en arquitectura exitosa V2 pero con CNN añadido                                    #\n",
    "#                                                                                                    #\n",
    "#====================================================================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046fc328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5f252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import (\n",
    "    Embedding, Dense, Dropout, LSTM, Bidirectional, \n",
    "    Conv1D, GlobalMaxPooling1D, Concatenate, Input, SpatialDropout1D\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "keras.utils.set_random_seed(seed)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_rows', 36)\n",
    "pd.set_option(\"display.max_colwidth\", 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d402f647",
   "metadata": {},
   "source": [
    "## Iteración 5 - ARQUITECTURA HÍBRIDA CNN+LSTM\n",
    "\n",
    "**Post-mortem V4:**\n",
    "- DistilBERT falló estrepitosamente (0.6456 vs 0.8885)\n",
    "- Transfer learning no siempre funciona\n",
    "- Dataset spam-specific requiere especialización\n",
    "\n",
    "**Nueva estrategia V5:**\n",
    "1. **CNN**: Detecta patrones locales (\"free money\", \"click here\", etc.)\n",
    "2. **LSTM**: Mantiene contexto largo (lo que funcionó en V2)\n",
    "3. **Híbrido**: Combina ambos → mejor de dos mundos\n",
    "4. **Base V2**: Parte de hiperparámetros exitosos de V2\n",
    "\n",
    "**Objetivo:** MCC > 0.89 (superar V2 sin el riesgo de DistilBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492ae89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters - V5 HYBRID CNN+LSTM - BALANCED REGULARIZATION\n",
    "\n",
    "# Text processing\n",
    "MAX_WORDS = 50000\n",
    "MAX_LEN = 200  # Restaurado: 250 era demasiado\n",
    "\n",
    "# Embedding\n",
    "EMBEDDING_DIM = 128  # Reducido: 150 sobreajusta\n",
    "\n",
    "# CNN branch - CAPACIDAD MODERADA\n",
    "CNN_FILTERS = 128  # Restaurado: 256 era excesivo\n",
    "CNN_KERNEL_SIZES = [2, 3, 4, 5]  # Sin 6-grams\n",
    "\n",
    "# LSTM branch - CAPACIDAD CONTROLADA\n",
    "LSTM_UNITS = 96  # Restaurado: balance capacidad/generalización\n",
    "\n",
    "# Dense classifier\n",
    "DENSE_UNITS = 64  # Restaurado: 128 causaba overfitting\n",
    "\n",
    "# Regularization - MÁS FUERTE (anti-overfitting)\n",
    "SPATIAL_DROPOUT = 0.3\n",
    "DROPOUT = 0.5  # Aumentado de nuevo\n",
    "L2_REG = 1e-4  # Aumentado: más penalización\n",
    "\n",
    "# Training - MÁS CONSERVADOR\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15  # Más epochs pero con early stopping fuerte\n",
    "LEARNING_RATE = 1e-3  # Reducido: 2e-3 converge demasiado rápido\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50924ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/train.csv\", index_col=\"row_id\")\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train['text'])\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(train['text'])\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "y_train = train['spam_label'].values\n",
    "\n",
    "# Train/val split\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_pad, y_train, test_size=VALIDATION_SPLIT, random_state=seed, stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90a1bb4",
   "metadata": {},
   "source": [
    "## Arquitectura Híbrida\n",
    "\n",
    "```\n",
    "Input → Embedding → SpatialDropout\n",
    "         ↓                ↓\n",
    "    CNN Branch      LSTM Branch\n",
    "         ↓                ↓\n",
    "  [Conv1D(2)] ← [Bi-LSTM(96)]\n",
    "  [Conv1D(3)]        ↓\n",
    "  [Conv1D(4)]    GlobalMaxPool\n",
    "  [Conv1D(5)]\n",
    "         ↓\n",
    "  [GlobalMaxPool x4]\n",
    "         ↓\n",
    "    Concatenate\n",
    "         ↓\n",
    "   Dense(64) + Dropout\n",
    "         ↓\n",
    "    Dense(1, sigmoid)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca4cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_lstm_model():\n",
    "    # Input\n",
    "    inputs = Input(shape=(MAX_LEN,))\n",
    "    \n",
    "    # Embedding\n",
    "    x = Embedding(\n",
    "        input_dim=MAX_WORDS,\n",
    "        output_dim=EMBEDDING_DIM,\n",
    "        input_length=MAX_LEN\n",
    "    )(inputs)\n",
    "    x = SpatialDropout1D(SPATIAL_DROPOUT)(x)\n",
    "    \n",
    "    # CNN Branch: CAPA ÚNICA por kernel (evitar overfitting)\n",
    "    cnn_outputs = []\n",
    "    for kernel_size in CNN_KERNEL_SIZES:\n",
    "        conv = Conv1D(\n",
    "            filters=CNN_FILTERS,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='relu',\n",
    "            kernel_regularizer=l2(L2_REG),\n",
    "            padding='same'\n",
    "        )(x)\n",
    "        pool = GlobalMaxPooling1D()(conv)\n",
    "        cnn_outputs.append(pool)\n",
    "    \n",
    "    # LSTM Branch: CAPA ÚNICA (evitar overfitting)\n",
    "    lstm_out = Bidirectional(\n",
    "        LSTM(\n",
    "            LSTM_UNITS,\n",
    "            kernel_regularizer=l2(L2_REG),\n",
    "            recurrent_regularizer=l2(L2_REG),\n",
    "            dropout=0.3,\n",
    "            recurrent_dropout=0.3\n",
    "        )\n",
    "    )(x)\n",
    "    \n",
    "    # Concatenate CNN and LSTM features\n",
    "    concatenated = Concatenate()(cnn_outputs + [lstm_out])\n",
    "    \n",
    "    # CLASIFICADOR SIMPLE (evitar overfitting)\n",
    "    dense = Dense(\n",
    "        DENSE_UNITS,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=l2(L2_REG)\n",
    "    )(concatenated)\n",
    "    dense = Dropout(DROPOUT)(dense)\n",
    "    \n",
    "    outputs = Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name='CNN_LSTM_Hybrid_V5_Balanced')\n",
    "    return model\n",
    "\n",
    "model = build_cnn_lstm_model()\n",
    "\n",
    "# Optimizer CONSERVADOR\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.AUC()]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1d9eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training - EARLY STOPPING MÁS AGRESIVO\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint('best_cnn_lstm_model.keras', monitor='val_loss', save_best_only=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_final, y_train_final,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beb9d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "y_pred_proba = model.predict(X_val, batch_size=BATCH_SIZE, verbose=0)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "mcc_score = matthews_corrcoef(y_val, y_pred)\n",
    "\n",
    "print(f\"MCC: {mcc_score:.4f}\")\n",
    "print(classification_report(y_val, y_pred, target_names=['Not SPAM', 'SPAM']))\n",
    "\n",
    "# Confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f'CNN+LSTM Hybrid (MCC: {mcc_score:.4f})')\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36f3fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions\n",
    "test = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/test.csv\", index_col=\"row_id\")\n",
    "\n",
    "X_test_seq = tokenizer.texts_to_sequences(test['text'])\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "y_pred_test = model.predict(X_test_pad, batch_size=BATCH_SIZE, verbose=0)\n",
    "y_pred_test = (y_pred_test > 0.5).astype(int).flatten()\n",
    "\n",
    "submission = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/sample_submission.csv\")\n",
    "submission[\"spam_label\"] = y_pred_test\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(f\"Submission created. Test predictions: {len(y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930abb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen comparativo\n",
    "print(\"=\"*80)\n",
    "print(\"EVOLUCIÓN COMPLETA\")\n",
    "print(\"=\"*80)\n",
    "print(\"V1 LSTM: 0.8665\")\n",
    "print(\"V2 LSTM+L2: 0.8885 ← BEST LSTM\")\n",
    "print(\"V3 LSTM+L2x5: 0.8733 (over-regularized)\")\n",
    "print(\"V4 DistilBERT: 0.6456 ← FRACASO\")\n",
    "print(f\"V5 CNN+LSTM: {mcc_score:.4f}\")\n",
    "print(\"=\"*80)\n",
    "if mcc_score > 0.8885:\n",
    "    print(f\"ÉXITO: +{(mcc_score-0.8885):.4f} sobre V2\")\n",
    "elif mcc_score > 0.88:\n",
    "    print(\"Resultado competitivo con V2\")\n",
    "else:\n",
    "    print(\"V2 sigue siendo mejor. Usar V2 para submission final.\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
