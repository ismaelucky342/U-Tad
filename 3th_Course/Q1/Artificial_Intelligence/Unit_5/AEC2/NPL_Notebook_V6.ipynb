{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c382debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================================================#\n",
    "#                                                                                                    #\n",
    "#                                                        ‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó        #\n",
    "#      Competici√≥n - SPAM/NOT SPAM - ITERACI√ìN 6        ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó       #\n",
    "#      V3 OPTIMIZED + SMART TUNING                      ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë       #\n",
    "#      created:        09/12/2025  -  17:30:00           ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ïö‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë       #\n",
    "#      last change:    09/12/2025  -  17:30:00           ‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù      ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù       #\n",
    "#                                                         ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù       ‚ïö‚ïê‚ïù   ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù        #\n",
    "#                                                                                                    #\n",
    "#      Ismael Hernandez Clemente                         ismael.hernandez@live.u-tad.com             #\n",
    "#                                                                                                    #\n",
    "#      Github:                                           https://github.com/ismaelucky342            #\n",
    "#                                                                                                    #\n",
    "#      ESTRATEGIA V6 - MEJORAS SOBRE V3 (MCC 0.8733):                                              #\n",
    "#      ‚úÖ Mantener: Arquitectura simple LSTM + regularizaci√≥n fuerte                                #\n",
    "#      üîß Optimizar: Vocabulario (10k‚Üí20k), MAX_LEN (200‚Üí250), LSTM (64‚Üí80)                        #\n",
    "#      üéØ Nuevo: Attention layer simple, threshold optimization                                     #\n",
    "#      ‚ùå Evitar: Transfer learning, CNN h√≠brido, ensemble prematuro                                #\n",
    "#                                                                                                    #\n",
    "#      LECCIONES APRENDIDAS:                                                                        #\n",
    "#      - V4 (0.64): Transfer learning fracasa en spam-specific                                     #\n",
    "#      - V5 (0.81-0.86): CNN+LSTM demasiado complejo para dataset peque√±o                          #\n",
    "#      - V6_ens (0.82): Early stopping muy agresivo, termin√≥ sin entrenar                          #\n",
    "#                                                                                                    #\n",
    "#====================================================================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9adc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153dce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, LSTM, Bidirectional, Dense, Dropout,\n",
    "    GlobalMaxPooling1D, SpatialDropout1D, Attention, Permute, Multiply\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "keras.utils.set_random_seed(seed)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_rows', 36)\n",
    "pd.set_option(\"display.max_colwidth\", 150)\n",
    "\n",
    "# Silent imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab1ad6",
   "metadata": {},
   "source": [
    "## Iteraci√≥n 6 - V3 Optimizado\n",
    "\n",
    "**Estado Actual:**\n",
    "- V1: MCC 0.8665 (overfitting)\n",
    "- V2: MCC 0.8885 (best LSTM)\n",
    "- V3: MCC 0.8733 ‚Üê BASE (regularizaci√≥n extrema)\n",
    "- V4: MCC 0.6456 (DistilBERT fracaso)\n",
    "- V5: MCC 0.81-0.86 (CNN+LSTM overfitting)\n",
    "- V6_ens: MCC 0.82 (early stop prematuro)\n",
    "\n",
    "**Estrategia V6:**\n",
    "1. **Base V3**: Arquitectura simple que funciona\n",
    "2. **Mejoras quir√∫rgicas**: \n",
    "   - Vocabulario: 10k ‚Üí 20k (m√°s informaci√≥n)\n",
    "   - MAX_LEN: 200 ‚Üí 250 (capturar m√°s contexto)\n",
    "   - LSTM: 64 ‚Üí 80 units (+25% capacidad controlada)\n",
    "   - Attention: Capa simple de atenci√≥n post-LSTM\n",
    "3. **Regularizaci√≥n ajustada**:\n",
    "   - L2: 5e-4 ‚Üí 3e-4 (menos restrictiva)\n",
    "   - Dropout: 0.7 ‚Üí 0.6 (permitir m√°s info)\n",
    "4. **Training mejorado**:\n",
    "   - Early stopping patience: 2 ‚Üí 4 (dar m√°s tiempo)\n",
    "   - LR: 5e-4 ‚Üí 7e-4 (convergencia m√°s r√°pida)\n",
    "   - Threshold optimization post-training\n",
    "\n",
    "**Objetivo:** MCC > 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5654352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters - V6 = V3 CON MICRO-OPTIMIZACIONES\n",
    "\n",
    "# Text processing - MANTENER V3\n",
    "MAX_WORDS = 10000      # Mantener V3 (20k a√±ad√≠a ruido)\n",
    "MAX_LEN = 200          # Mantener V3 (250 causaba overfitting)\n",
    "EMBEDDING_DIM = 100    # Mantener V3\n",
    "\n",
    "# Model architecture - VOLVER A V3 EXACTO\n",
    "LSTM_UNITS = 64        # EXACTO V3 (72 causaba overfitting)\n",
    "DENSE_UNITS = 32       # Mantener V3\n",
    "\n",
    "# Regularization - V3 EXACTO + M√ÅS FUERTE\n",
    "SPATIAL_DROPOUT = 0.4  # EXACTO V3\n",
    "DROPOUT_RATE = 0.7     # EXACTO V3 (0.65 era poco)\n",
    "L2_REG = 6e-4          # V3: 5e-4 ‚Üí 6e-4 (M√ÅS penalizaci√≥n vs overfitting)\n",
    "\n",
    "# Training - V3 BASE\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "VALIDATION_SPLIT = 0.2\n",
    "LEARNING_RATE = 5e-4   # EXACTO V3 (6e-4 converge demasiado r√°pido)\n",
    "CLIPNORM = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de321008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/train.csv\", index_col=\"row_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9015a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train['text'])\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(train['text'])\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "y_train = train['spam_label'].values\n",
    "\n",
    "# Train/val split\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_pad, y_train, test_size=VALIDATION_SPLIT, random_state=seed, stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e44758",
   "metadata": {},
   "source": [
    "## Arquitectura V6\n",
    "\n",
    "```\n",
    "Input (250)\n",
    "  ‚Üì\n",
    "Embedding (20k vocab, 100 dim)\n",
    "  ‚Üì\n",
    "SpatialDropout1D (0.35)\n",
    "  ‚Üì\n",
    "Bi-LSTM (80 units) + L2\n",
    "  ‚Üì\n",
    "Simple Attention (self-attention)\n",
    "  ‚Üì\n",
    "GlobalMaxPooling1D\n",
    "  ‚Üì\n",
    "Dense (32) + L2\n",
    "  ‚Üì\n",
    "Dropout (0.6)\n",
    "  ‚Üì\n",
    "Dense (1, sigmoid)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7905cea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_v6_model():\n",
    "    # ARQUITECTURA V3 PURA - SIN ATTENTION (causaba overfitting)\n",
    "    inputs = Input(shape=(MAX_LEN,))\n",
    "    \n",
    "    # Embedding\n",
    "    x = Embedding(\n",
    "        input_dim=MAX_WORDS,\n",
    "        output_dim=EMBEDDING_DIM,\n",
    "        input_length=MAX_LEN\n",
    "    )(inputs)\n",
    "    \n",
    "    # Spatial dropout\n",
    "    x = SpatialDropout1D(SPATIAL_DROPOUT)(x)\n",
    "    \n",
    "    # Bidirectional LSTM with regularization - SIN return_sequences\n",
    "    lstm_out = Bidirectional(\n",
    "        LSTM(\n",
    "            LSTM_UNITS,\n",
    "            kernel_regularizer=l2(L2_REG),\n",
    "            recurrent_regularizer=l2(L2_REG),\n",
    "            bias_regularizer=l2(L2_REG)\n",
    "        )\n",
    "    )(x)\n",
    "    \n",
    "    # SIN ATTENTION - causaba overfitting\n",
    "    # Directamente a classifier\n",
    "    \n",
    "    # Dense classifier\n",
    "    dense = Dense(\n",
    "        DENSE_UNITS,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=l2(L2_REG),\n",
    "        bias_regularizer=l2(L2_REG)\n",
    "    )(lstm_out)\n",
    "    \n",
    "    dense = Dropout(DROPOUT_RATE)(dense)\n",
    "    \n",
    "    # Output\n",
    "    outputs = Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name='V6_LSTM_Pure_Micro_Optimized')\n",
    "    return model\n",
    "\n",
    "model = build_v6_model()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=1e-4,\n",
    "    clipnorm=CLIPNORM\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.AUC()]\n",
    ")\n",
    "\n",
    "# Model built silently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91280f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks - EXACTO V3 (ultra-agresivo anti-overfitting)\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=2,  # EXACTO V3 (ultra-agresivo)\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_spam_model_v6.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=1,  # EXACTO V3 (ultra-agresivo)\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_final, y_train_final,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deec680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation + DEBUG\n",
    "y_pred_proba = model.predict(X_val, batch_size=BATCH_SIZE, verbose=0).flatten()\n",
    "\n",
    "# Threshold 0.5\n",
    "best_threshold = 0.5\n",
    "y_pred = (y_pred_proba > best_threshold).astype(int)\n",
    "mcc_val = matthews_corrcoef(y_val, y_pred)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DEBUG - ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Val MCC (threshold 0.5): {mcc_val:.4f}\")\n",
    "\n",
    "# Check training history for overfitting\n",
    "final_epoch = len(history.history['loss'])\n",
    "train_loss_final = history.history['loss'][-1]\n",
    "val_loss_final = history.history['val_loss'][-1]\n",
    "train_acc_final = history.history['accuracy'][-1]\n",
    "val_acc_final = history.history['val_accuracy'][-1]\n",
    "\n",
    "overfitting_delta = val_loss_final - train_loss_final\n",
    "\n",
    "print(f\"\\nTraining stopped at epoch: {final_epoch}\")\n",
    "print(f\"Train Loss: {train_loss_final:.4f} | Val Loss: {val_loss_final:.4f}\")\n",
    "print(f\"Train Acc:  {train_acc_final:.4f} | Val Acc:  {val_acc_final:.4f}\")\n",
    "print(f\"Overfitting Delta: {overfitting_delta:.4f}\")\n",
    "\n",
    "if overfitting_delta > 0.15:\n",
    "    print(\"‚ö†Ô∏è OVERFITTING DETECTADO (delta > 0.15)\")\n",
    "    print(\"   ‚Üí Necesita M√ÅS regularizaci√≥n\")\n",
    "elif overfitting_delta < 0.05:\n",
    "    print(\"‚úì Sin overfitting significativo (delta < 0.05)\")\n",
    "    print(\"   ‚Üí Podr√≠a permitir MENOS regularizaci√≥n\")\n",
    "else:\n",
    "    print(\"‚úì Overfitting controlado (delta 0.05-0.15)\")\n",
    "\n",
    "# Probability distribution analysis\n",
    "print(f\"\\nProbability distribution:\")\n",
    "print(f\"  Mean: {y_pred_proba.mean():.4f}\")\n",
    "print(f\"  Std:  {y_pred_proba.std():.4f}\")\n",
    "print(f\"  Min:  {y_pred_proba.min():.4f}\")\n",
    "print(f\"  Max:  {y_pred_proba.max():.4f}\")\n",
    "\n",
    "# Predictions by class\n",
    "spam_probs = y_pred_proba[y_val == 1]\n",
    "notspam_probs = y_pred_proba[y_val == 0]\n",
    "print(f\"\\nSPAM class prob mean: {spam_probs.mean():.4f} (should be > 0.5)\")\n",
    "print(f\"NOT SPAM class prob mean: {notspam_probs.mean():.4f} (should be < 0.5)\")\n",
    "\n",
    "separation = spam_probs.mean() - notspam_probs.mean()\n",
    "print(f\"Class separation: {separation:.4f} (mayor = mejor)\")\n",
    "\n",
    "if separation < 0.3:\n",
    "    print(\"‚ö†Ô∏è BAJA SEPARACI√ìN - Modelo no distingue bien clases\")\n",
    "    print(\"   ‚Üí Necesita M√ÅS capacidad o MEJORES features\")\n",
    "elif separation > 0.6:\n",
    "    print(\"‚úì BUENA SEPARACI√ìN - Modelo distingue bien clases\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_val, y_pred, target_names=['Not SPAM', 'SPAM']))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f97458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions\n",
    "test = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/test.csv\", index_col=\"row_id\")\n",
    "\n",
    "X_test_seq = tokenizer.texts_to_sequences(test['text'])\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "y_test_proba = model.predict(X_test_pad, batch_size=BATCH_SIZE, verbose=0).flatten()\n",
    "y_test_pred = (y_test_proba > best_threshold).astype(int)\n",
    "\n",
    "submission = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/sample_submission.csv\")\n",
    "submission[\"spam_label\"] = y_test_pred\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(f\"\\nSubmission: {len(y_test_pred)} predictions | Threshold: {best_threshold:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7cdeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary & Recommendations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTADOS Y RECOMENDACIONES\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Val MCC: {mcc_val:.4f} | Overfitting Œî: {overfitting_delta:.4f} | Separation: {separation:.4f}\")\n",
    "print(\"\")\n",
    "\n",
    "# Decision tree based on metrics\n",
    "if overfitting_delta > 0.15:\n",
    "    print(\"üìä DIAGN√ìSTICO: OVERFITTING SEVERO\")\n",
    "    print(\"üîß ACCI√ìN:\")\n",
    "    print(\"   1. Aumentar L2: 6e-4 ‚Üí 8e-4\")\n",
    "    print(\"   2. Aumentar Dropout: 0.7 ‚Üí 0.75\")\n",
    "    print(\"   3. Reducir LSTM: 64 ‚Üí 56 units\")\n",
    "    \n",
    "elif overfitting_delta < 0.05 and mcc_val < 0.88:\n",
    "    print(\"üìä DIAGN√ìSTICO: UNDERFIT - Demasiada regularizaci√≥n\")\n",
    "    print(\"üîß ACCI√ìN:\")\n",
    "    print(\"   1. Reducir L2: 6e-4 ‚Üí 4e-4\")\n",
    "    print(\"   2. Reducir Dropout: 0.7 ‚Üí 0.6\")\n",
    "    print(\"   3. Aumentar LSTM: 64 ‚Üí 80 units\")\n",
    "    \n",
    "elif separation < 0.3:\n",
    "    print(\"üìä DIAGN√ìSTICO: BAJA CAPACIDAD DISCRIMINATIVA\")\n",
    "    print(\"üîß ACCI√ìN:\")\n",
    "    print(\"   1. Aumentar MAX_LEN: 200 ‚Üí 220\")\n",
    "    print(\"   2. Aumentar EMBEDDING_DIM: 100 ‚Üí 128\")\n",
    "    print(\"   3. Mantener regularizaci√≥n actual\")\n",
    "    \n",
    "elif mcc_val >= 0.87 and overfitting_delta <= 0.12:\n",
    "    print(\"üìä DIAGN√ìSTICO: MODELO BALANCEADO\")\n",
    "    print(\"‚úÖ ACCI√ìN:\")\n",
    "    print(\"   1. Este es probablemente el mejor resultado alcanzable\")\n",
    "    print(\"   2. Usar ESTE modelo para submission\")\n",
    "    print(\"   3. Si test MCC < val MCC: problema es dataset, no modelo\")\n",
    "\n",
    "else:\n",
    "    print(\"üìä DIAGN√ìSTICO: AJUSTE FINO NECESARIO\")\n",
    "    print(\"üîß ACCI√ìN:\")\n",
    "    print(\"   1. Probar L2 entre 5e-4 y 7e-4\")\n",
    "    print(\"   2. Considerar LSTM 68-72 units\")\n",
    "    print(\"   3. Mantener threshold 0.5\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"\\nHIST√ìRICO:\")\n",
    "print(\"V2: 0.8885 (overfitting Œî~0.16) | V3: 0.8733 (overfitting Œî<0.08)\")\n",
    "print(f\"V6: {mcc_val:.4f} (overfitting Œî={overfitting_delta:.4f})\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
