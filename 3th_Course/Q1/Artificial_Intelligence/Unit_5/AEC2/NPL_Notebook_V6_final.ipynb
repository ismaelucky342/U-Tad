{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df5354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultado (registro): MCC público 0.87334 | MCC privado 0.86075\n",
    "# Este notebook es la versión final (V6) que usé para la submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9adc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración mínima del entorno para evitar logs excesivos de TF\n",
    "import os\n",
    "# Prefiero la implementación en python de protobuf para mensajes más limpios en consola\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "# Solo mostrar errores (0=all,1=info,2=warning,3=error) -> 2 mantiene la salida más limpia\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "# Desactivo optimizaciones que suelen generar warnings en algunas instalaciones\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153dce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías básicas\n",
    "import pandas as pd  # manejo de CSV/DFs\n",
    "import numpy as np  # operaciones numéricas\n",
    "import matplotlib.pyplot as plt  # visualización\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "# Mantengo warnings silenciosos para que las salidas sean legibles en el cuaderno\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# TensorFlow / Keras (solo lo que uso en el notebook V6)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense, Dropout, SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Semilla para TF\n",
    "tf.random.set_seed(seed)\n",
    "keras.utils.set_random_seed(seed)\n",
    "\n",
    "# sklearn: métricas y utilidades\n",
    "from sklearn.metrics import matthews_corrcoef, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pandas display\n",
    "pd.set_option('display.max_rows', 36)\n",
    "pd.set_option('display.max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5654352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparámetros elegidos tras las iteraciones\n",
    "MAX_WORDS = 10000  # vocabulario limitado a 10k palabras más frecuentes\n",
    "MAX_LEN = 200  # longitud fija de secuencias\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "LSTM_UNITS = 64\n",
    "DENSE_UNITS = 32\n",
    "\n",
    "SPATIAL_DROPOUT = 0.4\n",
    "DROPOUT_RATE = 0.7\n",
    "L2_REG = 6e-4\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "VALIDATION_SPLIT = 0.2\n",
    "LEARNING_RATE = 5e-4\n",
    "CLIPNORM = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de321008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo los datos de entrenamiento (ruta Kaggle usada en experiments)\n",
    "train = pd.read_csv('/kaggle/input/u-tad-spam-not-spam-2025-edition/train.csv', index_col='row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9015a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train['text'])\n",
    "X_train_seq = tokenizer.texts_to_sequences(train['text'])\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "y_train = train['spam_label'].values\n",
    "# División train/validation con stratify para preservar balance de clases\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_pad, y_train, test_size=VALIDATION_SPLIT, random_state=seed, stratify=y_train)\n",
    "\n",
    "def build_v6_model():\n",
    "    inputs = Input(shape=(MAX_LEN,), name='input_sequences')\n",
    "    x = Embedding(input_dim=MAX_WORDS, output_dim=EMBEDDING_DIM, input_length=MAX_LEN, name='embedding')(inputs)\n",
    "    x = SpatialDropout1D(SPATIAL_DROPOUT, name='spatial_dropout')(x)\n",
    "    lstm_out = Bidirectional(LSTM(LSTM_UNITS, kernel_regularizer=l2(L2_REG), recurrent_regularizer=l2(L2_REG), bias_regularizer=l2(L2_REG), return_sequences=False), name='bidirectional_lstm')(x)\n",
    "    dense = Dense(DENSE_UNITS, activation='relu', kernel_regularizer=l2(L2_REG), bias_regularizer=l2(L2_REG), name='dense_classifier')(lstm_out)\n",
    "    dense = Dropout(DROPOUT_RATE, name='dropout')(dense)\n",
    "    outputs = Dense(1, activation='sigmoid', name='output')(dense)\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='V6_LSTM_Final')\n",
    "    return model\n",
    "\n",
    "# Instancio y compilo el modelo\n",
    "model = build_v6_model()\n",
    "optimizer = keras.optimizers.AdamW(learning_rate=LEARNING_RATE, weight_decay=1e-4, clipnorm=CLIPNORM)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', keras.metrics.Precision(name='precision'), keras.metrics.Recall(name='recall'), keras.metrics.AUC(name='auc')])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc8dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks: EarlyStopping, ModelCheckpoint y ReduceLROnPlateau\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint('best_spam_model_v6.keras', monitor='val_loss', save_best_only=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(X_train_final, y_train_final, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_val, y_val), callbacks=callbacks, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
