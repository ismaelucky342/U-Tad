# Documentaci√≥n de Iteraciones - Competici√≥n SPAM/NOT SPAM

**Estudiante:** Ismael Hernandez Clemente  
**Email:** ismael.hernandez@live.u-tad.com  
**Competici√≥n:** [U-Tad] SPAM / NOT SPAM 2025  
**Objetivo:** Maximizar Matthews Correlation Coefficient (MCC)

---

## Iteraci√≥n #1 ‚úÖ

**Fecha:** 04/12/2025

### Descripci√≥n del Cambio
Implementaci√≥n del modelo baseline con arquitectura LSTM Bidireccional:
- Embedding layer (100 dimensiones)
- Spatial Dropout (0.2)
- Bidirectional LSTM (128 unidades, return_sequences=True)
- Global Max Pooling
- Dense layer (64 unidades) con Dropout (0.5)
- Output layer con sigmoid

Configuraci√≥n:
- Vocabulario: 10,000 palabras (46,022 palabras √∫nicas en dataset)
- Longitud de secuencia: 200 tokens
- Optimizer: AdamW (lr=1e-3, weight_decay=1e-4)
- Batch size: 32
- Epochs: 50 (detenido en √©poca 8 por EarlyStopping)
- Callbacks: EarlyStopping (patience=5), ModelCheckpoint, ReduceLROnPlateau (patience=3)
- Total par√°metros: 1,251,009

### Hip√≥tesis/Justificaci√≥n
Mi hip√≥tesis es que una arquitectura LSTM Bidireccional capturar√° mejor el contexto secuencial de los mensajes SPAM, ya que palabras clave pueden aparecer en cualquier posici√≥n del texto. El Global Max Pooling extraer√° las caracter√≠sticas m√°s discriminativas, mientras que el Dropout alto (50%) ayudar√° a prevenir overfitting dado el tama√±o del dataset.

### Resultado Obtenido
- **Validation MCC:** 0.8665 ‚≠ê
- **Validation Accuracy:** 0.9577 (95.77%)
- **Validation Precision:** 0.9109 (91.09%)
- **Validation Recall:** 0.9211 (92.11%)
- **Training Loss:** 0.0055
- **Validation Loss:** 0.1895
- **Tiempo de entrenamiento:** ~86 segundos (8 epochs)
- **Kaggle Public Score:** 0.8665 ¬± 0.02 (Top 8 üèÜ)

**An√°lisis de Performance:**
- El modelo mostr√≥ **overfitting significativo** (diferencia de 0.1840 entre train loss y val loss)
- EarlyStopping detuvo el entrenamiento en √©poca 8 tras no mejorar desde √©poca 3
- Excelente balance entre Precision (91%) y Recall (92%) para clase SPAM
- Predicciones en test: 77.64% Not SPAM, 22.36% SPAM (similar a distribuci√≥n de training: 75/25)

### Conclusiones y Pr√≥ximos Pasos

**‚úÖ Lo que funcion√≥ bien:**
1. Arquitectura LSTM Bidireccional es s√≥lida para capturar contexto secuencial
2. Global Max Pooling efectivo para extraer caracter√≠sticas discriminativas
3. EarlyStopping evit√≥ sobreentrenamiento innecesario
4. Tiempo de entrenamiento excelente (<2 minutos con GPU P100)

**‚ö†Ô∏è Problemas identificados:**
1. **Overfitting severo** - El modelo memoriza demasiado el training set
2. Train loss extremadamente baja (0.0055) sugiere capacidad excesiva
3. Diferencia de 4.14% entre train accuracy y val accuracy

**üéØ Mejoras prioritarias para Iteraci√≥n #2:**
1. **Reducir overfitting** (CR√çTICO):
   - Aumentar Spatial Dropout de 0.2 ‚Üí 0.3
   - A√±adir L2 regularization a capas Dense
   - Reducir unidades LSTM de 128 ‚Üí 96
   - Data Augmentation con sin√≥nimos o backtranslation

2. **Mejorar representaci√≥n sem√°ntica**:
   - Incorporar embeddings pre-entrenados GloVe-100d
   - Freezar embeddings durante primeras epochs

3. **Experimentar con arquitecturas**:
   - Probar CNN + LSTM h√≠brido para capturar n-gramas locales
   - TextCNN con m√∫ltiples kernel sizes (3, 4, 5)

**üìä Objetivo Iteraci√≥n #2:** MCC > 0.88 reduciendo overfitting

### Referencias
- Keras Bidirectional LSTM: https://keras.io/api/layers/recurrent_layers/bidirectional/
- Understanding LSTM: http://colah.github.io/posts/2015-08-Understanding-LSTMs/
- Matthews Correlation Coefficient: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html

---

## Iteraci√≥n #2 ‚úÖ

**Fecha:** 04/12/2025

### Descripci√≥n del Cambio
Regularizaci√≥n moderada para reducir overfitting:
- LSTM Units: 128 ‚Üí 96 (-25%)
- Dense Units: 64 ‚Üí 48 (-25%)
- Spatial Dropout: 0.2 ‚Üí 0.3 (+50%)
- Dropout: 0.5 ‚Üí 0.6 (+20%)
- L2 Regularization: None ‚Üí 1e-4 (NUEVO)
- Early Stopping Patience: 5 ‚Üí 3
- ReduceLROnPlateau Patience: 3 ‚Üí 2
- Total par√°metros: 1,160,609 (-7.2% vs V1)

### Hip√≥tesis/Justificaci√≥n
Hip√≥tesis: Reducir capacidad del modelo + aumentar regularizaci√≥n (dropout + L2) forzar√° al modelo a generalizar mejor en lugar de memorizar el training set. El overfitting severo de V1 (Delta=0.184) deber√≠a reducirse significativamente.

### Resultado Obtenido
- **Validation MCC:** 0.8885 (+0.0220 vs V1)
- **Validation Accuracy:** 95.07% (-0.70% vs V1)
- **Train Loss:** 0.0411 (vs 0.0055 en V1)
- **Val Loss:** 0.2075 (vs 0.1895 en V1)
- **Overfitting Delta:** 0.1663 (vs 0.1840 en V1)
- **Tiempo de entrenamiento:** ~73 segundos (6 epochs)
- **Kaggle Public Score:** 0.8885 (mismo que validaci√≥n)

**An√°lisis:**
- MCC mejor√≥ (+2.2%) - Objetivo cumplido
- Overfitting reducido 9.6% pero sigue alto (Delta=0.166 > 0.10)
- Train loss aument√≥ correctamente (menos memorizaci√≥n)
- Val loss empeor√≥ ligeramente
- Par√°metros reducidos 7.2%

### Conclusiones y Pr√≥ximos Pasos

**Lo que funcion√≥:**
- Aumento de MCC significativo
- Modelo menos propenso a memorizar
- Reducci√≥n de par√°metros efectiva

**Lo que NO funcion√≥:**
- Overfitting sigue siendo alto (Delta > 0.10)
- Val loss no mejor√≥
- Mejora insuficiente (9.6%)

**Decisi√≥n:** Se requiere TERAPIA DE CHOQUE en Iteraci√≥n 3
- Reducir capacidad 50% vs V1 (no solo 25%)
- Dropout extremo (0.7 en dense, 0.4 spatial)
- L2 regularization x5 m√°s fuerte (5e-4)
- Learning rate reducido (5e-4)
- Gradient clipping (norm=1.0)
- Early stopping ultra agresivo (patience=2)

**Objetivo Iteraci√≥n 3:** Overfitting Delta < 0.08 manteniendo MCC > 0.87

### Referencias
- L2 Regularization: https://keras.io/api/layers/regularizers/
- Dropout Paper: Srivastava et al. (2014)

---

## Iteraci√≥n #3 ‚úÖ

**Fecha:** 04/12/2025

### Descripci√≥n del Cambio
TERAPIA DE CHOQUE - Regularizaci√≥n extrema:
- LSTM Units: 96 ‚Üí 64 (-33% vs V2, -50% vs V1)
- Dense Units: 48 ‚Üí 32 (-33% vs V2, -50% vs V1)
- Spatial Dropout: 0.3 ‚Üí 0.4 (EXTREMO)
- Dropout: 0.6 ‚Üí 0.7 (EXTREMO)
- L2 Regularization: 1e-4 ‚Üí 5e-4 (x5 m√°s fuerte)
- Learning Rate: 1e-3 ‚Üí 5e-4 (-50%)
- Gradient Clipping: None ‚Üí 1.0 (NUEVO)
- Early Stopping Patience: 3 ‚Üí 2 (ultra agresivo)
- ReduceLROnPlateau Patience: 2 ‚Üí 1 (inmediato)
- Bias regularization: A√±adida L2 tambi√©n en bias
- Total par√°metros: ~1,000,000 estimado (-20% vs V2, -20% vs V1)

### Hip√≥tesis/Justificaci√≥n
Hip√≥tesis: V2 mostr√≥ mejora insuficiente (9.6% reducci√≥n overfitting). Se necesitan cambios radicales. Reducir capacidad 50% total vs V1 + regularizaci√≥n extrema (dropout 0.7) + L2 x5 m√°s fuerte + gradient clipping deber√≠a forzar generalizaci√≥n agresiva. Aunque pueda perder algo de capacidad predictiva, el objetivo es romper el ciclo de overfitting y establecer una base s√≥lida para mejoras futuras (GloVe, CNN+LSTM).

### Resultado Obtenido
- **Validation MCC:** ~0.87-0.88 (estimado, pendiente ejecuci√≥n completa)
- **Validation Accuracy:** TBD
- **Train Loss:** TBD (objetivo > 0.05)
- **Val Loss:** TBD (objetivo < 0.14)
- **Overfitting Delta:** TBD (objetivo < 0.08)
- **Kaggle Public Score:** 0.8733 (ligeramente peor que V2)

**An√°lisis Preliminar:**
- MCC en Kaggle: 0.8733 (-0.0152 vs V2)
- Posible p√©rdida de capacidad predictiva por regularizaci√≥n extrema
- Trade-off: menos overfitting pero posiblemente underfitting
- Necesidad de balance entre generalizaci√≥n y capacidad

### Conclusiones y Pr√≥ximos Pasos

**Estado:** Pendiente an√°lisis completo ma√±ana 05/12/2025

**Observaciones iniciales:**
- La terapia de choque puede haber sido demasiado agresiva
- Kaggle score baj√≥ ligeramente
- Posible underfitting por regularizaci√≥n extrema

**Estrategias para Iteraci√≥n 4:**

**Opci√≥n A - Balance V2+V3:**
- LSTM: 80 units (entre 96 y 64)
- Dense: 40 units (entre 48 y 32)
- Dropout: 0.65 (entre 0.6 y 0.7)
- L2: 2e-4 (entre 1e-4 y 5e-4)
- Buscar sweet spot entre V2 y V3

**Opci√≥n B - GloVe Embeddings:**
- Mantener arquitectura V2 (mejor MCC)
- Incorporar embeddings pre-entrenados GloVe-100d
- Mejora sem√°ntica sin cambiar regularizaci√≥n

**Opci√≥n C - CNN + LSTM H√≠brido:**
- Cambio arquitectural radical
- CNN para n-gramas locales + LSTM para secuencias
- Aprovechar fortalezas de ambos

**Decisi√≥n ma√±ana:** Analizar m√©tricas completas V3 y elegir estrategia

### Referencias
- Gradient Clipping: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam
- Overfitting vs Underfitting Balance: https://developers.google.com/machine-learning/crash-course/generalization/peril-of-overfitting

---

## Iteraci√≥n #4

**Fecha:** [DD/MM/2025]

### Descripci√≥n del Cambio
[Describir cambios]

### Hip√≥tesis/Justificaci√≥n
[Explicar hip√≥tesis]

### Resultado Obtenido
- **Validation MCC:**
- **Validation Accuracy:**
- **Kaggle Public Score:**

### Conclusiones y Pr√≥ximos Pasos
[An√°lisis y plan]

### Referencias
- [Referencias utilizadas]

---

## Iteraci√≥n #5

**Fecha:** [DD/MM/2025]

### Descripci√≥n del Cambio
[Describir cambios]

### Hip√≥tesis/Justificaci√≥n
[Explicar hip√≥tesis]

### Resultado Obtenido
- **Validation MCC:**
- **Validation Accuracy:**
- **Kaggle Public Score:**

### Conclusiones y Pr√≥ximos Pasos
[An√°lisis y plan]

### Referencias
- [Referencias utilizadas]

---

## Resumen Comparativo de Todas las Iteraciones

| Iteraci√≥n | Arquitectura Principal | Val MCC | Val Acc | Kaggle Score | Overfitting | Cambio Principal | Tiempo |
|-----------|------------------------|---------|---------|--------------|-------------|------------------|--------|
| 1 ‚úÖ | Bi-LSTM (128) | 0.8665 | 95.77% | 0.8665 Top 8 | Alto (Œî=0.184) | Baseline | 86s (8 epochs) |
| 2 ‚úÖ | Bi-LSTM (96) + L2 | 0.8885 | 95.07% | 0.8885 | Medio (Œî=0.166) | Regularizaci√≥n moderada | 73s (6 epochs) |
| 3 ‚ö†Ô∏è | Bi-LSTM (64) + L2x5 | ~0.87-0.88 | [TBD] | 0.8733 | [TBD] | Terapia de choque | [TBD] |
| 4 | [TBD] | [TBD] | [TBD] | [TBD] | [TBD] | [Decidir ma√±ana] | - |
| 5 | [TBD] | [TBD] | [TBD] | [TBD] | [TBD] | - | - |

**An√°lisis:**
- **Mejor MCC:** V2 (0.8885) - Regularizaci√≥n moderada
- **M√°s r√°pido:** V2 (73s, 6 epochs)
- **Menos overfitting:** V2 (Œî=0.166, mejora 9.6%)
- **Problema V3:** Posible underfitting por regularizaci√≥n extrema

**Estrategia recomendada:** Partir de V2 (mejor resultado) y a√±adir GloVe embeddings en V4

---

## Mejor Modelo Final

**Iteraci√≥n seleccionada:** [N√∫mero]  
**MCC en Validaci√≥n:** [Valor]  
**Score P√∫blico Kaggle:** [Valor]  
**Score Privado Kaggle:** [Valor - completar despu√©s del 12/12/2025]

### Justificaci√≥n de la Selecci√≥n
[Explicar por qu√© este modelo fue el mejor, haciendo referencia a los experimentos documentados]

---

## Lecciones Aprendidas

1. **Sobre Arquitecturas:**
   - [Qu√© arquitecturas funcionaron mejor y por qu√©]

2. **Sobre Hiperpar√°metros:**
   - [Qu√© configuraciones fueron m√°s efectivas]

3. **Sobre Regularizaci√≥n:**
   - [T√©cnicas que ayudaron a prevenir overfitting]

4. **Sobre el Dataset:**
   - [Insights sobre caracter√≠sticas del dataset SPAM]

---

## Referencias Generales del Proyecto

1. **Keras Documentation:** https://keras.io/
2. **NLP with Deep Learning:** https://web.stanford.edu/class/cs224n/
3. **Kaggle Learn - NLP:** https://www.kaggle.com/learn/natural-language-processing
4. **Material de la asignatura:** [Especificar unidades relevantes]
